{
  "hash": "4f55d86a7c09429d1d7e886270dba6d2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Weekly Updates\"\neditor: visual\ndate: 2024-09-04\nnumber-sections: false\nscrollable: true\n---\n\n## Week 15\n\n-   Final Project Lightning Talks\n    -   What is your project?\n    -   What does your project do really well?\n-   Asking Questions, Debugging, and Getting Help\n-   Discussion about Building Spatial Datasets\n    -   Things to keep the same\n    -   Things to drop\n    -   Things to change\n\n## Week 13\n\n-   Final project feedback\n    -   Use formatting thoughtfully to organize your writing and code (including removing the instructions from the template)\n    -   Make sure to test your code (especially if you use ChatGPT or another LLM)\n    -   Don't assume your data is good and tidy data (even if it comes from a reputable source)\n    -   A little bit of research is a good idea!\n-   More tips\n    -   Try using `mapview::mapview()`\n    -   Good folder organization! Use a `data` folder and an `R` folder\n    -   Think about the spatial units and entity model\n-   Combining multiple datasets\n    -   Make sure they share the same CRS\n    -   Make sure they share valid join columns\n-   ggplot2 (part 2) and ggplot2 extension packages\n-   interactive mapping packages\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- sf::st_read(\"path to too big dataset - email file link in Drive to Eli\")\n```\n:::\n\n\n## Week 12\n\n-   Baltimore City GIS Day (see the Discord for details!)\n-   Final Project Proposal Extension: Friday, Nov. 15\n-   Questions\n-   Lecture: Geospatial metadata and documentation\n-   Practice: Labelling variables and making data dictionaries with `{labelled}`\n-   Practice: Is this data FAIR?\n\n### Questions\n\n------------------------------------------------------------------------\n\n**Are there any tips for transforming spreadsheet data structures that might not be tidy when importing into R?**\n\nThe [Spreadsheet Munging Strategies](https://nacnudus.github.io/spreadsheet-munging-strategies/) book by Duncan Garmonsway and the related packages [tidyxl](https://nacnudus.github.io/tidyxl/) and [unpivotr](https://nacnudus.github.io/unpivotr/).\n\nThis blog post by [Sophie Bennet](https://www.sophieheloisebennett.com/posts/excel-sheet-cleaning/) is a helpful resource with tips on common issues: column names in multiple rows, variables in multiple columns, data in multiple sheets, and inconsistencies between sheets.\n\nHelpful functions for cleaning messy spreadsheet data include `dplyr::coalesce()` (combining values from muliple columns into one), `tidyr::fill()` for copying values down across rows, and `tidyr::separate_wider_delim()` for splitting columns.\n\n------------------------------------------------------------------------\n\n**Is there any way to label a subset of items (instead of everything) with ggplot2?**\n\nYou can pass a function in place of the data argument for any `geom_` function to subset your data. You can also create manual annotations with the `annotation()` function or use a dedicated package like [gghighlight](https://yutannihilation.github.io/gghighlight/). [ggrepel](https://ggrepel.slowkow.com/) is a more advanced labelling package that doesn't have dedicated `sf` friendly functions — but can still work.\n\n------------------------------------------------------------------------\n\nHow can a team decide which documents are most critical to maintain if they have limited resources for documentation?\n\n------------------------------------------------------------------------\n\n## Week 11\n\n### Questions\n\n------------------------------------------------------------------------\n\nWhat is the `source()` function and how does it work?\n\nYou can use `source()` to load and execute R code from a file. It is helpful for including combining code in multiple files as part of a single script or document.\n\n------------------------------------------------------------------------\n\nHow is osmextract different from osmdata, on a technical level?\n\nYou can use osmdata to access the [Overpass API](https://overpass-api.de/). Use osmextract to download a prepared file from a [processed OSM data provider](https://wiki.openstreetmap.org/wiki/Processed_data_providers).\n\n------------------------------------------------------------------------\n\nAre there cheat-sheets for reading in data as well, or is it simply something you have to remember for yourself depending on what data formats you are using?\n\n**Yes!** See this [Posit cheatsheet on data import](https://github.com/rstudio/cheatsheets/blob/main/data-import.pdf).\n\n## Week 10\n\n-   Reminders\n    -   Exercise 5 due next Friday, Nov. 1\n    -   Final project proposal due Wednesday, Nov. 13\n-   tidycensus\n\n## Week 9\n\n-   Reminders\n    -   Exercise 5 due next Friday, Nov. 1\n    -   Office hours on Tuesday, Oct. 29\n    -   Final project proposal due Wednesday, Nov. 13\n-   Lessons from McConchie and Boeing\n-   Open Street Map Lecture & Practice\n-   Questions\n\n## Week 9\n\n-   Exercise 5 due next Friday, Nov. 1\n-   Office hours on Tuesday, Oct. 29\n-   Final project proposal due Wednesday, Nov. 13\n-   Lessons from McConchie and Boeing\n-   Open Street Map Lecture & Practice\n\n### Lessons McConchie (2016)\n\nMcConchie introduces the concept of **map-gardening:** \"the editing tasks that keep OSM going... the things that happen after that fun trailblazing phase of mapping all the streets in your neighborhood.\"\n\nMcConchie asks: \"How do we make sure that OSM is a healthy community that has gardening, has people who enjoy maintenance?\n\n------------------------------------------------------------------------\n\n{{< video https://www.youtube.com/watch?v=7sC83j6vzjo >}}\n\n### Lessons from Boeing (2020)\n\nWhy did Boeing make OSMnx open source? Making the tool open source:\n\n-   \"makes empirical work easier to review and reproduce.\"\n-   \"allows anyone else to contribute to the tool’s ongoing development.\"\n-   \"empowers others working in urban science and planning to advance their empirical research on real-world spatial networks with a reusable, accessible, theoretically-sound tool.\"\n\n------------------------------------------------------------------------\n\nWhy did Boeing use OpenStreetMap data?\n\n-   Google Maps data is unavailable (or un-affordable)\n-   TIGER/Line roads shapefiles don't include topological details\n-   Open Street Map is free and has global coverage\n\n## Week 4\n\n-   Exercise 2 solutions\n-   Data transformation with dplyr\n-   Parsons Problems\n\n### Parsons Problems with {dplyr}\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\n  wind > 130\nstorms |>\nfilter(\nlibrary(dplyr)\n  year == 2010,\n)\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\nslice_head(n = 10)\nlibrary(dplyr)\narrange(desc(wind_load)) |>\ndistinct(year, name, .keep_all = TRUE) |>\nstorms |>\nmutate(wind_load = pressure * wind^2) |>\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\nggplot(aes(x = category, y = avg_wind)) +\nstorms |>\nsummarise(avg_wind = mean(wind)) |>\nlibrary(tidyverse)\nfilter(!is.na(category)) |>\ngeom_point()\ngroup_by(category) |>\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n------------------------------------------------------------------------\n\n## Week 3\n\n-   Exercise submission process\n-   Exercise 1 solutions\n-   Mapping with ggplot2\n-   Data transformation with dplyr\n-   Questions\n\n## Week 2\n\n-   Syllabus updates\n-   Cheat sheets\n-   Check-in on exercise 1 and GitHub Classroom\n-   Week 2 in-class quiz\n-   Visualizing spatial data with ggplot2\n\n### Syllabus updates\n\n-   In-class exercises\n-   No class on November 27\n\n## Cheat sheets\n\n-   RStudio\n-   sf\n-   ggplot2\n",
    "supporting": [
      "fall-2024_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}