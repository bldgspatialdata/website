[
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "GES 668: Course Syllabus",
    "section": "",
    "text": "Date üìÖ\n\nAugust 30 ‚Äì December 6, 2023\n\nTime ‚è∞\n\nWednesdays, 6:00‚Äì8:30 PM\n\nLocation üìç\n\nSondheim Hall 001 (Cartography Lab), University of Maryland, Baltimore County, 1099 Hilltop Road, Baltimore, MD 21250\n\nInstructor\n\nEli Pousson | eli.pousson@umbc.edu",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "GES 668: Course Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the semester, you will be able to:\n\nread and write spatial data from a wide range of file formats and web services\ntidy, transform, and visualize spatial data to understand the spatial and non-spatial distribution of attributes\nmeasure the spatial attributes or relationships between features and transform feature geometry\nuse Quarto to create presentations and reproducible reports and use GitHub for version control and collaboration.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#communication",
    "href": "course-syllabus.html#communication",
    "title": "GES 668: Course Syllabus",
    "section": "Communication",
    "text": "Communication\nThis class uses a dedicated Discord channel to share announcements and make it easy for students to share and discuss questions during and outside of in-person class sessions.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#accessibility",
    "href": "course-syllabus.html#accessibility",
    "title": "GES 668: Course Syllabus",
    "section": "Accessibility",
    "text": "Accessibility\nAccommodations for students with disabilities are provided for all students with a qualified disability under the Americans with Disabilities Act (ADA & ADAAA) and Section 504 of the Rehabilitation Act who request and are eligible for accommodations. The Office of Student Disability Services (SDS) coordinates accommodations to create equal access for students when barriers to participation exist in University courses, programs, or activities.\nIf you will be using SDS approved accommodations in this class, please let me know so we can make those accommodations. Students should contact the SDS at disAbility@umbc.edu or (410) 455-2459 to request or update accommodations as needed.\n\n\n\n\n\n\nSoftware Accessibility\n\n\n\nR is required software for this course. Please visit RStudio Accessibility Features for information about the program‚Äôs accessibility.\nUsing GitHub is also required. Find more information on managing accessibility settings for the GitHub website.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#respect",
    "href": "course-syllabus.html#respect",
    "title": "GES 668: Course Syllabus",
    "section": "Respect",
    "text": "Respect\nStudents in this class are encouraged to speak up and participate during class sessions. Because the class will include a diversity of individual beliefs, backgrounds, and experiences, every person participating in this class must show respect for every other participant both in person and when communicating online.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#readings",
    "href": "course-syllabus.html#readings",
    "title": "GES 668: Course Syllabus",
    "section": "Readings",
    "text": "Readings\nMost of the reading for this class will come from these three books:\n\nR for Data Science by Hadley Wickham, Mine √áetinkaya-Rundel, and Garret Grolemund\nGeocomputation with R by Robin Lovelace, Jakub Nowosad, and Jannes Muenchow\nAll Data Are Local: Thinking Critically in a Data-Driven Society by Yanni Alexander Loukissas\n\nAll three books are available for free online or available for purchase. Additional readings are listed on the page for each week‚Äôs session.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "GES 668: Course Syllabus",
    "section": "Assessment",
    "text": "Assessment\nAssessment for this course includes three parts:\n\nweekly check-ins,\npractice exercises,\nand a final project\n\n\nWeekly check-ins\nEach week students are expected to submit a brief written check-in based on the assigned readings and exercises. Your check-in should answer three questions:\n\nWhat did you find most interesting this week?\nWhat did you find most difficult this week?\nWhat is one question you have about the readings or exercise?\n\nYour check-in response should be submitted via Google Forms before the start of each class session. You are also encouraged but not required to post your question to the class Discord where other students are able to reply. Partial credit will be awarded for incomplete check-in responses.\nStudents are expected to submit at least 10 weekly check-in responses during the term so may skip up to 5 check-in responses without penalty. Weekly check-in assignments must be submitted before 11:59 am on the day before each class session. No late responses will be accepted for the weekly check-in.\n\n\nPractice exercises\nThese exercises give you an opportunity to practice the application of concepts and code introduced in the readings and lectures. You may discuss lab assignments with other students; however, labs should be completed and submitted individually.\nExercises are graded based on completion‚Äîso an effort to attempt all parts of the exercise will be awarded full credit. Some assignments may also include a bonus objective. An assignment with less than 80% of questions attempted will be considered incomplete. Incomplete assignments can be revised and resubmitted for full credit within a week of a student receiving my feedback.\n\n3: Assignment is submitted, complete, and includes a complete bonus objective\n2: Assignment is submitted and complete\n1: Assignment is submitted but incomplete\n0: Assignment not submitted\n\nStudents are expected to submit at least 10 exercises during the term so may skip up to 2 exercises without penalty. Practice exercises are due the Monday before each class session. For example, the first exercise is introduced on Wednesday, August 30 and should be completed by 11:59 PM on Monday, September 4.\n\n\nFinal project\nAll students will participate in a final project that can be completed independently or in collaboration with other students in the class. The project must use data from:\n\nOpenStreetMap (accessed with the {osmdata} package),\nAmerican Community Survey data (accessed with the {tidycensus} package),\nor a combination of these and other sources.\n\nThe final project is an opportunity for students to focus on the ‚Äúmodels of local practice‚Äù described in All Data Are Local‚Äîwith a special focus on how we can ‚Äúmake place part of data presentation.‚Äù\nTypically, the final project should fit into one of two categories:\n\nA data visualization or interactive that uses the data to tell a story or prompt reflection\nAn exploratory data analysis that uses the data to ask or answer questions\n\n\n\nKey dates and deliverables\nThe assessment of the project is based on four parts:\n\nA project proposal (1-2 pages in length) must be submitted by November 13 (updated).\nPeer feedback on two other proposals completed by November 22 (updated).\nAn project presentation delivered in-class on December 6 - tentative.\nA project GitHub repository completed by December 14 - tentative.\n\nEvaluation of the final project will be based on both self-assessment by the individual student or group and an instructor assessment. The instructor can also offer bonus points in recognition of exceptional work or, if necessary, adjust points awarded through the student self-assessment.\n\n\nGrading\nAssessment in this course is intended to help you focus on completing assignments and keeping up with the material‚Äînot getting everything perfect along the way.\nYou can earn up to a total of 100 points in this class by submitting at least 10 weekly check-ins (30 points), completing 10 exercises (20 points), and completing all four parts of the final project (50 points).\n\n\n\nAssessment\nPoints\n\n\n\n\nWeekly questions\n30\n\n\nPractice exercises\n20\n\n\nFinal project\n\n\n\nProject proposal\n10\n\n\nPeer feedback on two project proposals\n10\n\n\nPresentation\n10\n\n\nProject repository\n20",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#policies-resources",
    "href": "course-syllabus.html#policies-resources",
    "title": "GES 668: Course Syllabus",
    "section": "Policies & Resources",
    "text": "Policies & Resources\n\nSexual Assault, Sexual Harassment, and Gender Based Violence and Discrimination\nUMBC Policy and Federal law (Title IX) prohibit discrimination and harassment on the basis of sex, sexual orientation, and gender identity in University programs and activities. Any student who is impacted by sexual harassment, sexual assault, domestic violence, dating violence, stalking, sexual exploitation, gender discrimination, pregnancy discrimination, gender-based harassment or retaliation should contact the University‚Äôs Title IX Coordinator to make a report and/or access support and resources:\n\nJackie Moran, Title IX Coordinator and Interim Director\n410-455-1717, jmoran5@umbc.edu\n\nYou can access support and resources even if you do not want to take any further action. You will not be forced to file a formal complaint or police report. Please be aware that the University may take action on its own if essential to protect the safety of the community.\nIf you are interested in or thinking about making a report, please use the Online Reporting/Referral Form. Please note that, if you report anonymously, the University‚Äôs ability to respond will be limited.\n\n\n\n\n\n\nFaculty are Responsible Employees with Mandatory Reporting Obligations\n\n\n\nAll faculty members are considered Responsible Employees, per UMBC‚Äôs Policy on Sexual Misconduct, Sexual Harassment, and Gender Discrimination. Faculty are therefore required to report any/ all available information regarding conduct falling under the Policy and violations of the Policy to the Title IX Coordinator, even if a student discloses an experience that occurred before attending UMBC and/or an incident that only involves people not affiliated with UMBC. Reports are required regardless of the amount of detail provided and even in instances where support has already been offered or received.\nWhile faculty members want encourage you to share information related to your life experiences through discussion and written work, students should understand that faculty are required to report past and present sexual assault, domestic and interpersonal violence, stalking, and gender discrimination that is shared with them to the Title IX Coordinator so that the University can inform students of their rights, resources and support. While you are encouraged to do so, you are not obligated to respond to outreach conducted as a result of a report to the Title IX Coordinator.\nIf you need to speak with someone in confidence, who does not have an obligation to report to the Title IX Coordinator, UMBC has a number of Confidential Resources available to support you:\n\nRetriever Integrated Health¬†(Main Campus): 410-455-2472 [Monday ‚Äì Friday; 8:30 a.m. ‚Äì 5 p.m.] / After-Hours Support 410-455-3230\nCenter for Counseling and Consultation (Shady Grove Campus): 301-738-6273 (Messages checked hourly)¬† Online Appointment Request Form\nPastoral Counseling via Interfaith Center: 410-455-3657; interfaith@umbc.edu [7 days a week; Fall and Spring 7 a.m. ‚Äì 11 p.m.; Summer and Winter 8 a.m. ‚Äì 8 p.m.]\n\nOther Resources:\n\nWomen‚Äôs Center (for students of all genders): 410-455-2714; womenscenter@umbc.edu. [Monday ‚Äì Thursday 10:00am-5:30pm and Friday 10:00am-4pm]\nShady Grove Student Resources,Maryland Resources,National Resources.\n\n\n\n\n\n\n\n\n\nChild Abuse and Neglect\n\n\n\nPlease note that Maryland law and UMBC policy require that faculty report all disclosures or suspicions of child abuse or neglect to the Department of Social Services and/or the police even if the person who experienced the abuse or neglect is now over 18.\n\n\n\n\n\n\n\n\nParenting and Pregnant Students\n\n\n\nUMBC‚Äôs Policy on Sexual Misconduct, Sexual Harassment and Gender Discrimination expressly prohibits all forms of Discrimination and Harassment on the basis of sex, including pregnancy.Resources for pregnant, parenting and breastfeeding students are available through the University‚Äôs Office of Equity and Civil Rights.¬† Pregnant and parenting students are encouraged to contact the Title IX Coordinator to discuss plans and ensure ongoing access to their academic program with respect to a leave of absence or return following leave related to pregnancy, delivery, adoption, breastfeeding and/or the early months of parenting.\nPregnant students and students in the early months of parenting may be entitled to accommodations under Title IX through the Office of Equity and Civil Rights.\nIn addition, students who are pregnant and have an impairment related to their pregnancy that qualifies as disability under the ADA may be entitled to accommodations through the Student Disability Service Office.\n\n\n\n\nReligious Observances & Accommodations\nUMBC Policy provides that students should not be penalized because of observances of their religious beliefs, and that students shall be given an opportunity, whenever feasible, to make up within a reasonable time any academic assignment that is missed due to individual participation in religious observances. It is the responsibility of the student to inform the instructor of any intended absences or requested modifications for religious observances in advance, and as early as possible.\nFor questions or guidance regarding religious observance accommodations, please contact the Office of Equity and Civil Rights at ecr@umbc.edu.\n\n\nPlagiarism\nCopying or using another‚Äôs work in written or oral form‚Äîpartial or complete‚Äîwithout giving credit to the other person is a serious academic offense and is taken very seriously in this class, by the Department and by the University of Maryland, Baltimore County. UMBC specifically defines plagiarism as anyone who ‚Äúknowingly, or by carelessness or negligence, representing as one‚Äôs own in any academic exercise the words, ideas, works of art or computer-generated information and images of someone else.‚Äù\nAny student who plagiarizes will be referred to the Department Chair and will be subject to the policies of the university. In general, the consequences of plagiarism include failing an assignment, receiving a lower course grade, and even failing a course. Examples of plagiarism include:\n\nSubmit someone else‚Äôs work as your own.\nBuy a paper from a paper-mill, website or other source.\nCopy sentences, phrases, paragraphs, or ideas from someone else‚Äôs work, published or unpublished, without giving the original author credit.\nReplace select words from a passage without giving the original author credit.\nCopy any type of graphics, tables, graphs, maps, or charts from someone else‚Äôs work without giving the original author credit.\nPiece together phrases, ideas, and sentences from a variety of sources to write an essay.\nBuild on someone else‚Äôs idea or phrase without giving the original author credit.\n\nDetails about avoiding plagiarism, examples, and disciplinary policies should be reviewed to gain a clear understanding prior to working on an assignment or exam.\n\n\nHate, Bias, Discrimination and Harassment\nUMBC values safety, cultural and ethnic diversity, social responsibility, lifelong learning, equity, and civic engagement.\nConsistent with these principles, UMBC Policy prohibits discrimination and harassment in its educational programs and activities or with respect to employment terms and conditions based on race, creed, color, religion, sex, gender, pregnancy, ancestry, age, gender identity or expression, national origin, veterans status, marital status, sexual orientation, physical or mental disability, or genetic information.\nStudents (and faculty and staff) who experience discrimination, harassment, hate or bias or who have such matters reported to them should use theonline reporting/referral form to report discrimination, hate or bias incidents. You may report incidents that happen to you anonymously. Please note that, if you report anonymously, the University‚Äôs ability to respond will be limited.\n\n\nCOVID-19 Safety Protocols\nUMBC encourages all members of our community to take personal safety measures. This includes remaining up to date on your vaccinations and following CDC guidelines if you are recovering from COVID-19. See the Retriever Ready: COVID-19 Response page for UMBC‚Äôs curent COVID-19 policies and answers to frequently asked questions.\nFor the health of all in our community, please remember to Stay Home if You Are Sick.\n\n\nRetriever Essentials\nRetriever Essentials is a faculty, staff, and student-led partnership that promotes food access in the UMBC community. Retriever Essentials offers free groceries, toiletries, baby items, and meal swipes, and have opportunities to engage and volunteer:\n\nPick up items from our free store The Essential Space located in RAC 235¬†\nReceive fresh food every Thursday 2:15-2:45pm @ the Library (email or see IG for exact location)\nStop by one of our Food Zones to pick up a pre-assembled bag of non-perishable food items and personal care products\nPick up snacks and food from our Free Corner Stores at the Campus Police Station or Library Atrium\nEmail us at retrieveressentials@umbc.edu if you need free meal swipes\nTo donate food, see instructions here!\n\nEmail Retriever Essentials if you would like to join our team or volunteer.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#notes",
    "href": "course-syllabus.html#notes",
    "title": "GES 668: Course Syllabus",
    "section": "Notes",
    "text": "Notes\n\nThe respect statement is adapted from California State University Chico‚Äôs Office of Diversity and Inclusion.\nThis course website is based in part on the website for STA 210 at Duke University. Check out the repository on GitHub for more information about the site.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-1",
    "href": "course-syllabus.html#week-1",
    "title": "GES 668: Course Syllabus",
    "section": "Week 1",
    "text": "Week 1\n\nRequired readings\n\nCh. 1 Introduction in Robin Lovelace, Jakub Nowosad, and Jannes Muenchow Geocomputation with R, 2nd (WIP)., 2022, https://geocompr.robinlovelace.net/.\nCh. 2 Geographic data in R in Lovelace, Nowosad, and Muenchow Geocomputation with R.\nChris Brunsdon and Alexis Comber ‚ÄúOpening Practice: Supporting Reproducibility and Critical Spatial Data Science,‚Äù Journal of Geographical Systems 23, no. 4 (October 1, 2021): 477‚Äì496, doi:10.1007/s10109-020-00334-2.\nJennifer Bryan ‚ÄúHow to Name Files,‚Äù May 14, 2015, https://speakerdeck.com/jennybc/how-to-name-files. (or more recent How to name files talk for NormConf 2022)\n\n\n\nOptional readings\n\nIntroduction to Geospatial Concepts (Data Carpentry)\nIntroduction to R for Geospatial Data (Data Carpentry)\nCh. 3 Geometries in Edzer Pebesma and Roger Bivand Spatial Data Science (CRC Press, 2023), https://r-spatial.org/book/.\nGreg Wilson et al. ‚ÄúGood Enough Practices in Scientific Computing,‚Äù PLOS Computational Biology 13, no. 6 (June 22, 2017): e1005510, doi:10.1371/journal.pcbi.1005510.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-2",
    "href": "course-syllabus.html#week-2",
    "title": "GES 668: Course Syllabus",
    "section": "Week 2",
    "text": "Week 2\n\nRequired readings\n\nCh. 6 Maps in Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen Ggplot2: Elegant Graphics for Data Analysis, 3rd (WIP)., Use R! (Springer, 2023), https://ggplot2-book.org/index.html.\nCh. 3 Workflow: basics in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\nCh. 1 Local Origins in Yanni Alexander Loukissas All Data Are Local: Thinking Critically in a Data-Driven Society, 2019, doi:10.7551/mitpress/11543.001.0001.\n\n\n\nOptional readings\n\nCatherine D‚ÄôIgnazio and Lauren Klein ‚ÄúWho Collects the Data? A Tale of Three Maps,‚Äù MIT Case Studies in Social and Ethical Responsibilities of Computing (February 5, 2021), doi:10.21428/2c646de5.fc6a97cc.\nCh. 2 Data visualization in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-3",
    "href": "course-syllabus.html#week-3",
    "title": "GES 668: Course Syllabus",
    "section": "Week 3",
    "text": "Week 3\n\nRequired readings\n\nCh. 5 Data transformation in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\nCh. 2 A Place for Plant Data in Loukissas All Data Are Local.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-4",
    "href": "course-syllabus.html#week-4",
    "title": "GES 668: Course Syllabus",
    "section": "Week 4",
    "text": "Week 4\n\nRequired readings\n\nCh. 3 Attribute data operations in Lovelace, Nowosad, and Muenchow Geocomputation with R.\nCh. 3 Collecting Infrastructures in Loukissas All Data Are Local.\n\n\n\nOptional readings\n\nCh. 5 Attributes and Support in Pebesma and Bivand Spatial Data Science.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-5",
    "href": "course-syllabus.html#week-5",
    "title": "GES 668: Course Syllabus",
    "section": "Week 5",
    "text": "Week 5\n\nRequired readings\n\nCh. 4 Spatial data operations in Lovelace, Nowosad, and Muenchow Geocomputation with R.\nCh. 5 Geometry operations in Lovelace, Nowosad, and Muenchow Geocomputation with R.\n\n\n\nOptional readings\n\nEdzer Pebesma ‚Äú3. Manipulating Simple Feature Geometries‚Äù (sf, November 28, 2016), https://r-spatial.github.io/sf/articles/sf3.html.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-6",
    "href": "course-syllabus.html#week-6",
    "title": "GES 668: Course Syllabus",
    "section": "Week 6",
    "text": "Week 6\n\nRequired reading\n\nCh. 6 Data tidying in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\nCh. 20 Joins in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\nKarl W. Broman and Kara H. Woo ‚ÄúData Organization in Spreadsheets,‚Äù The American Statistician 72, no. 1 (January 2, 2018): 2‚Äì10, doi:10.1080/00031305.2017.1375989.\n\n\n\nOptional reading\n\n‚ÄúThe Quartz Guide to Bad Data‚Äù (Quartz, August 31, 2022), https://github.com/Quartz/bad-data-guide.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-7",
    "href": "course-syllabus.html#week-7",
    "title": "GES 668: Course Syllabus",
    "section": "Week 7",
    "text": "Week 7\n\nRequired readings\n\nCh. 26 Functions in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\nCh. 11 Scripts, algorithms and functions in Lovelace, Nowosad, and Muenchow Geocomputation with R.\nCh. 29 Quarto in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\n\n\n\nOptional readings\n\nSam Leon ‚ÄúAccounting for Methods: Spreadsheets, Scripts and Programming Notebooks,‚Äù in The Data Journalism Handbook: Towards A Critical Data Practice, ed. Liliana Bounegru and Jonathan Gray, 2nd ed. (Amsterdam University Press, 2021), 128‚Äì137, doi:10.2307/j.ctv1qr6smr.\nWelcome to Quarto Workshop! (Posit PBC, 2022), https://www.youtube.com/watch?v=yvi5uXQMvu4.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-8",
    "href": "course-syllabus.html#week-8",
    "title": "GES 668: Course Syllabus",
    "section": "Week 8",
    "text": "Week 8\n\nRequired readings\n\nCh. 5 Market, Place, Interface in Loukissas All Data Are Local.\nCh. 11 Exploratory Data Analysis in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\nNatalia Mazotte ‚ÄúWorking Openly in Data Journalism,‚Äù in The Data Journalism Handbook: Towards A Critical Data Practice, ed. Liliana Bounegru and Jonathan Gray, 2nd ed. (Amsterdam University Press, 2021), 138‚Äì142, doi:10.2307/j.ctv1qr6smr.\n\n\n\nOptional readings\n\nCh. 12 Communication in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-9",
    "href": "course-syllabus.html#week-9",
    "title": "GES 668: Course Syllabus",
    "section": "Week 9",
    "text": "Week 9\n\nRequired readings\n\nMark Padgham and Robin Lovelace ‚Äú1. Osmdata‚Äù (osmdata, August 15, 2023), https://docs.ropensci.org/osmdata/articles/osmdata.html.\nAlan McConchie ‚ÄúOpenStreetMap Pasts, OpenStreetMap Futures,‚Äù July 27, 2016, https://www.youtube.com/watch?v=KNTSZGnQVRw.\n\n\n\nOptional readings\n\nGeoff Boeing ‚ÄúThe Right Tools for the Job: The Case for Spatial Science Tool-Building,‚Äù Transactions in GIS 24, no. 5 (October 2020): 1299‚Äì1314, doi:10.1111/tgis.12678.\nDani Arribas-Bel and Jon Reades ‚ÄúGeography and Computers: Past, Present, and Future,‚Äù Geography Compass 12, no. 10 (2018): e12403, doi:10.1111/gec3.12403.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-10",
    "href": "course-syllabus.html#week-10",
    "title": "GES 668: Course Syllabus",
    "section": "Week 10",
    "text": "Week 10\n\nRequired readings\n\nCh. 5 Census Geographic Data and Applications in R in Kyle E. Walker Analyzing US Census Data: Methods, Maps, and Models in R (CRC Press, 2022), https://walker-data.com/census-r/census-geographic-data-and-applications-in-r.html.\nDan Bouk, Kevin Ackermann, and danah boyd A Primer on Powerful Numbers: Selected Readings in the Social Study of Public Data and Official Numbers (Data & Society, March 23, 2022), https://datasociety.net/library/a-primer-on-powerful-numbers-selected-readings-in-the-social-study-of-public-data-and-official-numbers/.\nSpatial Analysis of US Census Data in R (Social Science Data Analysis Network, 2021), https://www.youtube.com/watch?v=GqC1HjAKui4.\n\n\n\nOptional readings\n\nDan Bouk ‚ÄúHow Does Queerness Fit Into the US Census?‚Äù Wired, August 23, 2022, https://www.wired.com/story/us-census-queerness-data/.\nAccessing and Analyzing U.S. Census Data in R (Social Science Data Analysis Network, 2021), https://www.youtube.com/watch?v=PnFJfuJ83NI.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-11",
    "href": "course-syllabus.html#week-11",
    "title": "GES 668: Course Syllabus",
    "section": "Week 11",
    "text": "Week 11\n\nRequired readings\n\nCh. 8 Geographic data I/O in Lovelace, Nowosad, and Muenchow Geocomputation with R.\nCh. 21 Spreadsheets in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\n\n\n\nOptional readings\n\nTom MacWright ‚ÄúMore Than You Ever Wanted to Know about GeoJSON‚Äù (Tom MacWright, March 23, 2015), https://macwright.com/2015/03/23/geojson-second-bite.html.\nOpenGeoLabs ‚ÄúSwitch from Shapefile,‚Äù October 5, 2017, http://switchfromshapefile.org/.\nSpatial Data on the Web Working Group ‚ÄúSpatial Data on the Web Best Practices,‚Äù September 28, 2017, https://www.w3.org/TR/sdw-bp/.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-12",
    "href": "course-syllabus.html#week-12",
    "title": "GES 668: Course Syllabus",
    "section": "Week 12",
    "text": "Week 12\n\nRequired readings\n\nCh. 7 Show Your Work in Catherine D‚ÄôIgnazio and Lauren F. Klein Data Feminism (The MIT Press, 2020), https://data-feminism.mitpress.mit.edu/.\nShannon Pileggi ‚ÄúThe Case for Variable Labels in R‚Äù (Piping Hot Data, September 13, 2022), https://www.pipinghotdata.com/posts/2022-09-13-the-case-for-variable-labels-in-r/.\n‚ÄúData-Primers‚Äù (DataCurationNetwork, 2019), https://github.com/DataCurationNetwork/data-primers/tree/c6ec438e76fea49eaaf2806bc79ec2c8c12de7f3.\n\n\n\nOptional readngs\n\n‚ÄúGuide to Writing \"Readme\" Style Metadata‚Äù (Research Data Management Service Group), accessed August 27, 2022, https://data.research.cornell.edu/content/readme.\nEmily Riederer ‚ÄúColumn Names as Contracts‚Äù (Emily Riederer, September 6, 2020), https://emilyriederer.netlify.app/post/column-name-contracts/.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-13",
    "href": "course-syllabus.html#week-13",
    "title": "GES 668: Course Syllabus",
    "section": "Week 13",
    "text": "Week 13\n\nRequired readings\n\nCh. 6 Models of Local Practice in Loukissas All Data Are Local.\nCh. 7 Local Ends in Loukissas All Data Are Local.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-14",
    "href": "course-syllabus.html#week-14",
    "title": "GES 668: Course Syllabus",
    "section": "Week 14",
    "text": "Week 14\nNo readings for this week.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#week-15",
    "href": "course-syllabus.html#week-15",
    "title": "GES 668: Course Syllabus",
    "section": "Week 15",
    "text": "Week 15\nNo readings for this week.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "exercises/exercise_04-sol.html",
    "href": "exercises/exercise_04-sol.html",
    "title": "Exercise 04 (Solutions)",
    "section": "",
    "text": "This exercise uses the sf and tidyverse packages:\n\nlibrary(tidyverse)\nlibrary(sf)\n\nWe are also going to use the us_states and us_states_df data from the {spData} package:\n\nlibrary(spData)\n\nNote that the us_states loaded for this exercise is different than the us_states we created during class with the tigris::states() function. For this exercise, the bonus exercises are mixed in with the other questions but you are welcome to skip them if you do not want go for the bonus part of the exercise."
  },
  {
    "objectID": "exercises/exercise_04-sol.html#setup",
    "href": "exercises/exercise_04-sol.html#setup",
    "title": "Exercise 04 (Solutions)",
    "section": "",
    "text": "This exercise uses the sf and tidyverse packages:\n\nlibrary(tidyverse)\nlibrary(sf)\n\nWe are also going to use the us_states and us_states_df data from the {spData} package:\n\nlibrary(spData)\n\nNote that the us_states loaded for this exercise is different than the us_states we created during class with the tigris::states() function. For this exercise, the bonus exercises are mixed in with the other questions but you are welcome to skip them if you do not want go for the bonus part of the exercise."
  },
  {
    "objectID": "exercises/exercise_04-sol.html#exercises",
    "href": "exercises/exercise_04-sol.html#exercises",
    "title": "Exercise 04 (Solutions)",
    "section": "2 Exercises",
    "text": "2 Exercises\n\n2.1 Filtering data\nFind all states that belong to the West region, have an area below 250,000 km2 and in 2015 a population greater than 5,000,000 residents (Hint: you may need to use the function units::set_units() or as.numeric()).\n\nus_states |&gt; \n  filter(\n    as.numeric(AREA) &lt; 250000,\n    total_pop_15 &gt; 5000000\n    )\n\nFind all states that belong to the South region, had an area larger than 150,000 km2 or a total population in 2015 larger than 7,000,000 residents.\n\nus_states |&gt; \n  filter(\n    REGION == \"South\" |\n    as.numeric(AREA) &gt; 150000 |\n    total_pop_15 &gt; 7000000\n  )\n\n\n\n2.2 Joining and summarizing data\nWhat was the total population in 2015 in the us_states dataset? What was the minimum and maximum total population in 2015?\n\nus_states |&gt;\n  st_drop_geometry() |&gt; \n  summarise(\n    total_state_pop_15 = sum(total_pop_15),\n    min_state_pop_15 = min(total_pop_15),\n    max_state_pop_15 = max(total_pop_15)\n  )\n\nAdd variables from us_states_df to us_states, and create a new object called us_states_stats.\n\nWhat function did you use and why?\nWhich variable is the key in both datasets?\nWhat is the class of the new object?\n\nTip: we are covering joins in more detail next week‚Äîcheck out the R for Data Science chapter on Joins for more information.\n\nus_states_stats &lt;- us_states |&gt; \n  left_join(\n    us_states_df,\n    by = join_by(NAME == state)\n    )\n\nus_states_stats\n\nus_states_df has two more rows than us_states. How can you find them? Hint: try to use the dplyr::anti_join() function.\n\nanti_join(\n  us_states_df,\n  us_states,\n  by = join_by(state == NAME)\n)\n\nHow much has population density changed between 2010 and 2015 in each state?\nCalculate the change in percentages and map them with plot() or geom_sf():\n\nus_states_density &lt;- us_states |&gt; \n  mutate(\n    AREA_sq_km = as.numeric(AREA),\n    pop_density_10 = total_pop_10 / AREA_sq_km,\n    pop_density_15 = total_pop_15 / AREA_sq_km,\n    pop_density_change = round(pop_density_15 / pop_density_10, digits = 2) - 1\n  )\n\n\nus_states_density |&gt; \n  ggplot() +\n  geom_sf(aes(fill = pop_density_change)) +\n  scale_fill_continuous(labels = scales::label_percent()) +\n  labs(\n    fill = \"% change in pop. density (2010-2015)\"\n  ) +\n  theme_void()\n\n\nplot(us_states_density[, 11])\n\nCalculate the change in the number of residents living below the poverty level between 2010 and 2015 for each state. Hint: See ?us_states_df for documentation on the poverty level columns.\n\nus_states_poverty_level &lt;- us_states_stats |&gt; \n  mutate(\n    poverty_level_change = poverty_level_15 - poverty_level_10,\n    .after = NAME\n  )\n\nus_states_poverty_level\n\nBonus: Calculate the change in the percentage of residents living below the poverty level in each state.\n\nus_states_stats |&gt; \n  mutate(\n    pct_poverty_level_10 = poverty_level_10 / total_pop_10,\n    pct_poverty_level_15 = poverty_level_15 / total_pop_15,\n    pct_poverty_level_change = pct_poverty_level_15 - pct_poverty_level_10\n  )\n\nWhat was the minimum, average and maximum state‚Äôs number of people living below the poverty line in 2015 for each region?\n\nus_states_stats |&gt; \n  group_by(REGION) |&gt; \n  summarise(\n    min_poverty_level_15 = min(poverty_level_15),\n    max_poverty_level_15 = max(poverty_level_15),\n    mean_poverty_level_15 = mean(poverty_level_15)\n  )\n\nBonus: What is the region with the largest increase in people living below the poverty line?\n\nus_states_stats |&gt; \n  st_drop_geometry() |&gt; \n  group_by(REGION) |&gt; \n  summarise(\n   poverty_level_change = sum(poverty_level_15) - sum(poverty_level_10)\n  ) |&gt; \n  slice_max(n = 1, order_by = poverty_level_change)\n\n\n\n2.3 Spatial operations\nSection 4.2 (in Geocomputation with R) established that Canterbury was the region of New Zealand containing most of the 100 highest points in the country. How many of these high points does the Canterbury region contain?\n\ncanterbury &lt;- nz |&gt;\n  filter(Name == \"Canterbury\")\n\ncanterbury_height &lt;- nz_height |&gt; \n  slice_max(order_by = elevation, n = 100) |&gt; \n  st_filter(canterbury)\n\nnrow(canterbury_height)\n\nBonus: plot the result using the ggplot2::geom_sf() function to show all of New Zealand, canterbury region highlighted in yellow, high points in Canterbury represented by red crosses (Hint: try using shape = 7) and high points in other parts of New Zealand represented by blue circles.\nSee the help page ?ggplot2::shape and run the examples to see an illustration of different shape values.\n\nggplot() +\n  geom_sf(data = nz) +\n  geom_sf(data = canterbury, fill = \"yellow\") +\n  geom_sf(data = st_filter(nz_height, canterbury), shape = 7, color = \"red\") +\n  geom_sf(data =  st_filter(nz_height, canterbury, .predicate = st_disjoint), shape = 1, color = \"blue\")\n\nWhich region has the second highest number of nz_height points, and how many does it have?\n\nnz_height |&gt; \n  st_intersection(nz) |&gt; \n  st_drop_geometry() |&gt; \n  count(Name) |&gt; \n  slice_max(n = 2, order_by = n)\n\nGeneralizing the question to all regions: how many of New Zealand‚Äôs 16 regions contain points which belong to the top 100 highest points in the country? Which regions?\n\nnz_height |&gt; \n  slice_max(n = 100, order_by = elevation) |&gt; \n  st_intersection(nz) |&gt; \n  st_drop_geometry() |&gt; \n  count(Name)\n\nBonus: create a table listing these regions in order of the number of points and their name. Hint: use dplyr::slice_max() and gt::gt().\n\nnz_height |&gt; \n  slice_max(n = 100, order_by = elevation) |&gt; \n  st_intersection(nz) |&gt; \n  st_drop_geometry() |&gt; \n  count(Name, sort = TRUE) |&gt; \n  gt::gt() |&gt; \n  gt::tab_header(\n    \"Regions with any of the 100 highest points in New Zealand\"\n  )\n\nUsing st_buffer(), how many points in nz_height are within 100 km of Canterbury?\n\ncanterbury_buffered &lt;- st_buffer(canterbury, dist = units::as_units(100, \"km\"))\n\nnz_height |&gt; \n  st_filter(\n    canterbury_buffered\n  ) |&gt; \n  nrow()\n\n\n\n2.4 Spatial predicates\nTest your knowledge of spatial predicates by finding out and plotting how US states relate to each other and other spatial objects.\nThe starting point of this part of the exercise is to create an object representing Maryland state in the USA using the filter() function and plot the resulting object in the context of US states.\n\nmaryland &lt;- filter(us_states, NAME == \"Maryland\")\n\nggplot() +\n  geom_sf(data = us_states) +\n  geom_sf(data = maryland, fill = \"orange\")\n\nCreate a new object representing all the states that geographically intersect with Maryland and plot the result (hint: the most concise way to do this is with the subsetting method [ but you can also use sf::st_filter()).\n\nstates_intersecting_md &lt;- us_states[maryland, ]\n\nCreate another object representing all the objects that touch (have a shared boundary with) Maryland and plot the result (hint: remember you can use the argument op = st_intersects when subsetting with base R or .predicate = st_intersects when using st_filter()).\n\nstates_touching_md &lt;- us_states[maryland, , op = st_touches]\n\nstates_touching_md_alt &lt;- st_filter(us_states, maryland, .predicate = st_touches)\n\nBonus: create a straight line from the centroid of Maryland to the centroid of California near the West coast of the USA (hint: functions st_centroid(), st_union() and st_cast() described in Chapter 5 may help) and identify which states this long East-West line crosses.\n\nmd_centroid &lt;- st_centroid(maryland)\n\ncalifornia &lt;- filter(us_states, NAME == \"California\")\n\nca_centroid &lt;- st_centroid(california)\n\nmd_and_ca &lt;- st_union(md_centroid, ca_centroid)\n\nmd_to_ca_line &lt;- st_cast(md_and_ca, to = \"LINESTRING\")\n\nst_filter(us_states, md_to_ca_line, .predicate = st_crosses)\n\nHow far is the geographic centroid of Maryland from the geographic centroid of Canterbury, New Zealand?\n\ncanterbury_centroid &lt;- st_centroid(canterbury)\ncanterbury_centroid &lt;- st_transform(canterbury_centroid, crs = st_crs(md_centroid))\n\nst_distance(md_centroid, canterbury_centroid)\n\nCalculate the length of the boundary lines of US states in meters. Which state has the longest border and which has the shortest? Hint: The st_length function computes the length of a LINESTRING or MULTILINESTRING geometry.\n\nus_states_borders &lt;- us_states |&gt; \n  st_cast(\n    to = \"MULTILINESTRING\"\n  ) |&gt; \n  mutate(\n    border_length = st_length(geometry)\n  ) |&gt; \n  st_drop_geometry()\n  \n\nslice_max(us_states_borders, order_by = border_length, n = 1)\n\nslice_min(us_states_borders, order_by = border_length, n = 1)"
  },
  {
    "objectID": "exercises/exercise_05.html",
    "href": "exercises/exercise_05.html",
    "title": "Exercise 05",
    "section": "",
    "text": "Exercise due on 2023-10-06\n\n\n\n‚ÑπÔ∏è See week 5 for related slides and readings",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 05"
    ]
  },
  {
    "objectID": "exercises/exercise_06.html",
    "href": "exercises/exercise_06.html",
    "title": "Exercise 06",
    "section": "",
    "text": "Exercise due on 2023-10-13\n\n\n\n‚ÑπÔ∏è See week 6 for related slides and readings\nThis week‚Äôs exercise has five parts and a bonus:\n\nSearch online for a dataset that interests you (maybe even related to your final project idea) that isn‚Äôt ‚Äútidy‚Äù. Open Baltimore and Maryland iMap are two good sources for local data and have plenty of untidy datasets. Make sure you are using vector data with both spatial geometry and attributes.\nCreate a Quarto document named exerise_06.qmd in the exercise folder of your repository. Write a brief description of the data and the ways in which it is or is not ‚Äútidy‚Äù. Make sure to start the description with a link to the data source and a brief description of who collected the data and for what purpose. Is there a legal requirement to collect this data? Is there a standard for how the attributes are collected or organized? You may need to do some additional searching online to answer these questions so make sure to include links or references to any sources used in writing the description.\nAdd a code chunk to your document reading the document into R using sf::read_sf(). I strongly recommend using a URL as your data source if you can (for example you can use a GeoJSON link on the page for an individual dataset on Maryland iMap or Open Baltimore). If you need to use a file create a new folder within exercises titled files and place the file in the folder. Note: your file must be less than 50MB in size or your changes to the repository can‚Äôt be committed to GitHub. If your file is not a spatial data file (e.g.¬†a CSV file) you should convert the object into a sf object using sf::st_as_sf().\n\n\n\nIn a new code chunk, use ggplot2 to try to make a plot or map of the untidy data. Think about what you can‚Äôt do with the data in this format (and write out those observations following the code chunk).\nIn a new code chunk, try using pivot_wider and other tidyr functions to try to tidy the data to resolve the issues you identified in your description. Write a brief description explaining what issues with the data you have been able to ‚Äútidy‚Äù and flag any issues that you noticed but can‚Äôt figure out how to fix.\nBonus: Find a related dataset that shares an attribute with your dataset. Use a join function from dplyr to connect the two datasets. Explore different ways you can create new variables or summarize the data using the combination of your original dataset and the new dataset. For example if your original data set has count by attribute by county, you could join the data to county boundaries from {tigris} and try normalizing your data by population or physical area.",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 06"
    ]
  },
  {
    "objectID": "exercises/exercise_03.html",
    "href": "exercises/exercise_03.html",
    "title": "Exercise 03",
    "section": "",
    "text": "Exercise due on 2023-09-18\n‚ÑπÔ∏è See week 3 for related slides and readings",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 03"
    ]
  },
  {
    "objectID": "exercises/exercise_03.html#overview",
    "href": "exercises/exercise_03.html#overview",
    "title": "Exercise 03",
    "section": "1 Overview",
    "text": "1 Overview\nThis week‚Äôs exercise comes directly from the data transformation chapter of R for Data Science. More typically, our exercises will always include spatial data but I wanted to use a more tried and tested exercise for this week‚Äôs material.",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 03"
    ]
  },
  {
    "objectID": "exercises/exercise_03.html#setup",
    "href": "exercises/exercise_03.html#setup",
    "title": "Exercise 03",
    "section": "2 Setup",
    "text": "2 Setup\nIf you don‚Äôt already have the {nycflights13} package installed, go ahead and install it then restart before continuing with the exercise.\n\npak::pkg_install(\"nycflights13\")\n\nIn addition to nycflights13, you will also need {dplyr} and {ggplot2}. Load the tidyverse library to make sure you have everything you need:\n\nlibrary(nycflights13)\nlibrary(tidyverse)",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 03"
    ]
  },
  {
    "objectID": "exercises/exercise_03.html#exercises",
    "href": "exercises/exercise_03.html#exercises",
    "title": "Exercise 03",
    "section": "3 Exercises",
    "text": "3 Exercises\n\n3.1 Working with rows\nIn a single pipeline for each condition, find all flights that meet the condition:\n\nHad an arrival delay of two or more hours\nFlew to Houston (IAH or HOU)\nWere operated by United, American, or Delta\nDeparted in summer (July, August, and September)\nArrived more than two hours late, but didn‚Äôt leave late\nWere delayed by at least an hour, but made up over 30 minutes in flight\n\n\nflights |&gt; \n  ____\n\nSort flights to find the flights with longest departure delays. Find the flights that left earliest in the morning.\n\nflights |&gt; \n  arrange(____)\n\nSort flights to find the fastest flights. (Hint: Try including a math calculation inside of your function.)\n\nflights |&gt; \n  ____\n\nWas there a flight on every day of 2013?\n\nflights |&gt; \n  ____\n\nWhich flights traveled the farthest distance? Which traveled the least distance?\n\nflights |&gt; \n  ____\n\nDoes it matter what order you used filter() and arrange() if you‚Äôre using both? Why/why not? Think about the results and how much work the functions would have to do.\n____\n\n\n3.2 Working with columns\nCompare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?\n____\nBrainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.\n\nselect(flights, ____)\n\nWhat happens if you specify the name of the same variable multiple times in a select() call?\n\nselect(flights, ____)\n\nWhat does the any_of() function do? Why might it be helpful in conjunction with this vector?\n\nvariables &lt;- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\n\nDoes the result of running the following code surprise you? How do the select helpers deal with upper and lower case by default? How can you change that default?\n\nflights |&gt; select(contains(\"TIME\"))\n\nRename air_time to air_time_min to indicate units of measurement and move it to the beginning of the data frame.\n\nflights |&gt; \n  rename(____)\n\nWhy doesn‚Äôt the following work, and what does the error mean?\n\nflights |&gt; \n  select(tailnum) |&gt; \n  arrange(arr_delay)\n\n\n\n3.3 Working with groups\nWhich carrier has the worst average delays? Challenge: can you disentangle the effects of bad airports vs.¬†bad carriers? Why/why not? (Hint: think about flights |&gt; group_by(carrier, dest) |&gt; summarize(n()))\n\nflights |&gt; \n  ____\n\nFind the flights that are most delayed upon departure from each destination.\n\nflights |&gt; \n  ____\n\nHow do delays vary over the course of the day. Illustrate your answer with a plot.\nWhat happens if you supply a negative n to slice_min() and friends?\n\nslice_min(flights, ____)\n\nExplain what count() does in terms of the dplyr verbs you just learned. What does the sort argument to count() do?\n\ncount(flights, ____)\n\ncount(flights, ____, sort = ____)",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 03"
    ]
  },
  {
    "objectID": "exercises/exercise_02-sol.html",
    "href": "exercises/exercise_02-sol.html",
    "title": "Exercise 02 (Solutions - Incomplete)",
    "section": "",
    "text": "Incomplete solutions."
  },
  {
    "objectID": "exercises/exercise_02-sol.html#setup",
    "href": "exercises/exercise_02-sol.html#setup",
    "title": "Exercise 02 (Solutions - Incomplete)",
    "section": "1 Setup",
    "text": "1 Setup\nThis exercises uses the {ggplot2} and {dplyr} packages (both from the tidyverse family of packages) and the {sf} package:\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(sf)\n\nFor this week‚Äôs exercise, we are also going to use data from the {rnaturalearth} package. Make sure to install those packages and re-start your session if these packages are not installed already:\n\n# pak::pkg_install(c(\"rnaturalearth\", \"rnaturalearthdata\"))\nlibrary(rnaturalearth)\n\nWe are going to use ne_download() to download the countries dataset and then use st_centroid() to make a version of this dataset where the features show the center of each country instead of the boundaries:\n\ncountries &lt;- ne_download(scale = \"medium\", type = \"countries\", returnclass = \"sf\")\n\ncountries &lt;- filter(countries, REGION_UN != \"Antarctica\")\ncountries &lt;- st_transform(countries, crs = 3857)\n\ncountries_center &lt;- st_centroid(countries)\n\nglimpse(countries)\n\nSome of the following exercises don‚Äôt require a sf object. You can also use the mpg or storms dataset we looked at during this week‚Äôs lecture:\n\nglimpse(mpg)\n\nglimpse(storms)\n\nOne advantage of using {ggplot2} over a map-making focused package like {tmap} is the wide variety of extension packages created by the large community of users and developers making data visualizations (including maps) with {ggplot2}.\nWe aren‚Äôt going to use some of these extension packages (and others) but we won‚Äôt load them yet. Run the following code to install (and don‚Äôt forget to restart your session afterwards):\n\npak::pkg_install(c(\"patchwork\", \"plotly\", \"smoothr\"))\n\nIf you finish this exercise but still want more practice, you can download this RMarkdown document with exercises shared by Thomas Lin Pedersen for his two-part 2020 online workshop on {ggplot2} (part 1 and part 2 are both available on YouTube)."
  },
  {
    "objectID": "exercises/exercise_02-sol.html#exercises",
    "href": "exercises/exercise_02-sol.html#exercises",
    "title": "Exercise 02 (Solutions - Incomplete)",
    "section": "2 Exercises",
    "text": "2 Exercises\n\n2.1 Plotting a single variable\nFind a discrete variable in countries and then create a plot with geom_bar():\n\nggplot(data = countries) +\n  geom_bar(mapping = aes(y = SUBREGION))\n\nNext, find a continuous variable and make a plot with geom_histogram():\n\nggplot(data = countries) +\n  geom_histogram(mapping = aes(x = POP_EST))\n\nNow, let‚Äôs make a map! Use countries_center and geom_sf() to make a map with a continuous variable mapped to size:\n\nggplot(data = countries_center) +\n  geom_sf(aes(size = POP_EST))\n\n\nNext, make a map with geom_sf() with one discrete variable mapped to color:\n\nggplot(data = countries) +\n  geom_sf(aes(color = REGION_UN))\n\nIs that the map you expected? Try it again with the discrete variable mapped to fill:\n\nggplot(data = countries) +\n  geom_sf(aes(fill = REGION_UN))\n\n\nNow, make a plot using any geom function of your choice:\n\nggplot(data = countries) +\n  geom_jitter(aes(REGION_UN, POP_EST, color = REGION_UN))\n\nExplain in plain language. What does your plot show? ____\n\n\n2.2 Plotting two variables\nFor this next section, you can continue to use countries as your dataset or load a different dataset using {rnaturaleath}. You can see what vector data is available using rnaturalearth::ne_find_vector_data() then find the function you need to load the data into a new object:\n\nrnaturalearth::ne_find_vector_data()\n\npopulated_places &lt;- rnaturalearth::ne_download(type = \"populated_places\", returnclass = \"sf\")\n\nFirst, find two continuous variables and create a scatter plot with geom_point():\n\nggplot(data = populated_places) +\n  geom_point(aes(MAX_AREAKM, POP_MAX))\n\nNext, look in your data for one discrete and one continuous variable then use aes() to set those variables for geom_col(). The geom_col() function is similar to geom_bar() but you must provide both an x and a y variable:\n\nnorth_central_america &lt;- filter(countries, SUBREGION %in% c(\"Northern America\", \"Central America\"))\n\nggplot(data = north_central_america) +\n  geom_col(aes(POP_EST, NAME))\n\nNow, use geom_sf() mapping your continuous variable to fill or color and your discrete variable to facet_wrap():\n\nggplot(data = countries) +\n  geom_sf(aes(fill = POP_EST), color = NA) +\n  facet_wrap(~ TYPE)\n\nFinally, create a map using a different aesthetic that we haven‚Äôt tried yet. Options could include linewidth, size, alpha, or linetype:\n\nggplot(data = populated_places) +\n  geom_sf(aes(size = POP1950))\n\nIs this aesthetic mapping an effective way of visualizing the variable? ____\nIf so, why do you think it works well? If not, why does it not work well? ____\n\n\n2.3 Using scales and colors\n{ggplot2} uses naming conventions to organize the scale functions. This isn‚Äôt the same for every function but they look something like: ‚Äúscale_‚Äù. So, scale_fill_viridis_d() applies the Viridis color scale to a discrete variable mapped to the fill aesthetic.\nUse the data to create a plot and take a look at the colors set when you use scale_color_viridis_c():\n\nggplot(data = populated_places) +\n  geom_point(aes(LATITUDE, LONGITUDE, color = POP2015)) +\n  scale_color_viridis_c()\n\nThe ColorBrewer scales are designed for use with thematic maps. Use ?scale_color_brewer() to pull up the documentation for this function and review the information on the type and palette parameters.\nNow, map a variable to the color aesthetic for geom_sf() and assign an appropriate type and palette value:\n\nggplot(data = countries_center) +\n  geom_sf(aes(color = REGION_UN)) +\n  scale_color_brewer(type = \"qual\", palette = \"Accent\")\n\nSwitching from color to fill, try it again with a different type and palette value:\n\nggplot(data = countries) +\n  geom_sf(aes(fill = INCOME_GRP)) +\n  scale_fill_brewer(type = \"seq\", palette = \"GnBu\")\n\nOne last time, but we‚Äôre using scale_fill_distiller():\n\nggplot(data = countries) +\n  geom_sf(aes(fill = GDP_MD)) +\n  scale_fill_distiller(type = \"seq\", palette = \"GnBu\")\n\nNote that this scale_fill_distiller() scale only works with continuous values. If you get an error, you may need to map a different variable to fill.\n\n\n2.4 Adding labels, legends, and themes\nSet the data for ggplot() and then use the labs() function to apply a title and caption that make sense:\n\nggplot(data = north_central_america) +\n  geom_sf(color = \"black\", fill = NA) +\n  labs(\n    title = \"North and Central American Countries\",\n    caption = \"Data from the rnaturalearth package\"\n  )\n\nNow, map fill to a variable in your data using aes() and then use labs() to assign a label for fill:\n\nggplot(data = north_central_america) +\n  geom_sf(aes(fill = GDP_MD)) +\n  labs(\n    fill = \"GDP\"\n  )\n\nFinally, put all of these elements together with a theme function. theme_minimal() and theme_void() are good themes to use for maps but you can explore all of the options in the ggplot2 documentation:\n\nggplot(data = north_central_america) +\n  geom_sf(mapping = aes(fill = GDP_MD)) +\n  labs(\n    title = \"North and Central American countries by GDP\",\n    caption = \"Data from the rnaturalearth package\",\n    fill = \"GDP\"\n  ) +\n  theme_void()\n\n\n\n2.5 Interactive plots with {plotly}\nWe aren‚Äôt doing much with interactivity in this class (or exercise) but I did want to give you a chance to try it out using the ggplotly() function from the {plotly} package:\n\np &lt;- ggplot(data = countries) +\n  geom_point(aes(POP_EST, GDP_MD, color = REGION_UN))\n  \nplotly::ggplotly(\n  p = p\n)\n\nA directory of {ggplot2} extensions is available through the tidyverse website if you want to try more tools for animation or interactivity including {gganimate} or {ggiraph}.\n\n\n2.6 Map making with {ggplot2}\nBy default, any map created with geom_sf() will show the graticulates on the map and axis labels with the coordinate values. Add data to this map and then hide these graticules by adding theme_void():\n\nggplot(data = countries) +\n  geom_sf(color = \"black\", fill = NA) +\n  theme_void()\n\nYou can also hide or change graticules by using theme(). Try setting the panel.grid argument to element_blank() to hide the grid:\n\nggplot(data = countries) +\n  geom_sf(color = \"black\", fill = NA) +\n  theme(\n    panel.grid = element_blank()\n    )\n\nNow, try ‚Äúzooming‚Äù into a selected area of your map using the xlim and ylim arguments for coord_sf():\n\nggplot(data = countries) +\n  geom_sf(color = \"black\", fill = NA) +\n  coord_sf(\n    xlim = c(-19836524, 20013016),\n    ylim = c(2150688, 18394384)\n  )\n\nIf you have difficulty with this one, look back at our week 2 slides for an example showing how to use sf::st_bbox() to get xmin, xmax, ymin, and ymax values for the xlim and ylim parameter.\n\nUsing an inset map or ‚Äúlocator map‚Äù with a larger area and a zoomed in map showing a featured area is a common cartographic approach. You can use patchwork::inset_element() from the {patchwork} package to set this up:\n\narea_map &lt;- ggplot(data = north_central_america) +\n  geom_sf(color = \"black\", fill = NA) +\n  coord_sf(\n    xlim = c(-19836524, 20013016),\n    ylim = c(2150688, 18394384)\n  ) +\n  theme_void()\n\ninset_map &lt;- ggplot(data = countries) +\n  geom_sf(color = \"black\", fill = NA) +\n  theme_void()\n\narea_map +\n  patchwork::inset_element(\n    p = inset_map,\n    left = 0.1,\n    bottom = 0.1,\n    top = 0.3,\n    right = 0.3\n  )\n\nRemember, this format of calling functions (&lt;package name&gt;::&lt;function name&gt;) is just a shortcut for using functions from packages that are installed but not loaded into your environment. If you have any difficulty with this part of the exercise, make sure you have {patchwork} installed.\n\nThere are some cases when you need to modify the geometry of your data as part of the process of making a map. The st_simplify() function is one way to do that. Try setting dTolerance to a low value, e.g.¬†dTolerance = 10, and run the code block. Then try to run it again with dTolerance = 100000.\n\nusa &lt;- filter(countries, NAME == \"United States of America\")\n\nsimple_usa &lt;- st_simplify(x = usa, dTolerance = 100000)\n\nggplot() +\n  geom_sf(\n    data = usa,\n    color = \"orange\"\n    ) +\n  geom_sf(\n    data = simple_usa,\n    color = \"purple\"\n  ) +\n  theme_void()\n\nWhat happens when you increase the value of dTolerance? ____\nNow, let‚Äôs try to same thing but smoothing features with smoothr::smooth() instead of simplifying with sf::st_simplify(). Start by setting smoothness to a small number, smoothness = 0.5, and then run again with higher and higher numbers:\n\nsmooth_usa &lt;- smoothr::smooth(x = usa, method = \"ksmooth\", smoothness = 100)\n\nggplot() +\n  geom_sf(\n    data = usa,\n    color = \"orange\"\n    ) +\n  geom_sf(\n    data = smooth_usa,\n    color = \"purple\",\n    fill = NA\n  ) +\n  theme_void()\n\nWhat happens when you increase the value of smoothness? ____\nCheck the documentation for st_simplify() or smoothr::smooth() for more information on how these functions work to modify the geometry."
  },
  {
    "objectID": "exercises/exercise_02-sol.html#bonus-exercise",
    "href": "exercises/exercise_02-sol.html#bonus-exercise",
    "title": "Exercise 02 (Solutions - Incomplete)",
    "section": "3 Bonus exercise",
    "text": "3 Bonus exercise\n\n3.1 Creating maps with {tmap}\nPick one of the maps you created in the prior questions of this exercise and create a similar version using the {tmap} package.\nYou can install {tmap} the same as any other package:\n\n# pak::pkg_install(\"tmap\")\n\nThen load the library:\n\nlibrary(tmap)\n\nAnd make a map using data from {rnaturalearth} or another source of your choice:\n\n____\n\nWhat is the same about making a map with {tmap} compared to {ggplot2}? ____\nWhat is different about making a map with {tmap} compared to {ggplot2}? ____\nDo you have any preference between the two? ____"
  },
  {
    "objectID": "final-project.html",
    "href": "final-project.html",
    "title": "Final Project",
    "section": "",
    "text": "The final project is an opportunity for you to practice the spatial data skills we‚Äôve been working on in this course while also exploring your interests and the potential for spatial data to support real-world goals.\nYour project should focus on a topic area or dataset that is relevant to your personal and professional interests. Typically, the final project should fit into one of two categories:\n\nA data visualization or interactive that uses the data to tell a story or prompt reflection\nAn exploratory data analysis that uses the data to ask or answer questions\n\nThis project has three parts:\n\nA project proposal (due November 13 - updated)\nAn short presentation about your project (due December 6 - tentative)\nA project GitHub repository including code, data, output files, and a README (due December 14 - tentative)\n\nYou are also expected to share peer feedback on two other proposals completed by November 22 (updated).",
    "crumbs": [
      "Course information",
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#overview",
    "href": "final-project.html#overview",
    "title": "Final Project",
    "section": "",
    "text": "The final project is an opportunity for you to practice the spatial data skills we‚Äôve been working on in this course while also exploring your interests and the potential for spatial data to support real-world goals.\nYour project should focus on a topic area or dataset that is relevant to your personal and professional interests. Typically, the final project should fit into one of two categories:\n\nA data visualization or interactive that uses the data to tell a story or prompt reflection\nAn exploratory data analysis that uses the data to ask or answer questions\n\nThis project has three parts:\n\nA project proposal (due November 13 - updated)\nAn short presentation about your project (due December 6 - tentative)\nA project GitHub repository including code, data, output files, and a README (due December 14 - tentative)\n\nYou are also expected to share peer feedback on two other proposals completed by November 22 (updated).",
    "crumbs": [
      "Course information",
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#project-proposal",
    "href": "final-project.html#project-proposal",
    "title": "Final Project",
    "section": "Project proposal",
    "text": "Project proposal\nYour project proposal needs to answer identify a data source and answer three main questions:\n\nWhat are your goals for the project?\nWhat data can you use to support your goal?\nWhat is your approach to using data to support your goal?\n\nYou should answer each question with a brief but considered response. If it helps to have a word count, try to answer all three questions in something between 700 and 1000 words.\nFormat your proposal as Quarto document with citations within the project folder of your class respository. Your proposal should include:\n\nlinks to any published data or related resources\nreproducible code blocks for any preliminary data analysis you completed to support your proposal\n\nDon‚Äôt forget to cite your sources! While an extensive literature review is unnecessary, reviewing how other researching and practitioners have used the same or similar spatial data may give you ideas for your own project.\n\nIdentifying a data source\nStudents are strongly encouraged to build a project using data from:\n\nOpenStreetMap (accessed with the {osmdata} package),\nor American Community Survey data (accessed with the {tidycensus} package)\n\nSee the readings and materials from week 9 or week 10 for more background information on these sources.\n\n\n\n\n\n\nA caution about using different data source\n\n\n\nIf you do not using {tidycensus} or {osmdata}, I may not be able to provide the same level of assistance with trouble-shooting your code for the final project. Consider opportunities to use OpenStreetMap and American Community Survey data in combination with other sources.\n\n\nIf you are interested in working with some other data source, your project proposal should explain your reason for selecting the source and make sure to confirm that:\n\nyou know the data and goals are related (e.g.¬†you have a question that can be answered using the data),\nyou have permission to use the data (e.g.¬†the data is published under an open license),\nyou know the data is in an accessible format (e.g.¬†CSV, ArcGIS Feature Server, GeoPackage file),\nand you know there are no major data quality issues (e.g.¬†location accuracy, completeness) that you can‚Äôt address as part of the project.\n\n\n\nWhat are your goals for the project?\nYour goals could include answering a research question, making the case for a public policy change, or building an interface to help people better understand an issue in their community.\nYour goals could also include developing your own ability to analyze a specific type of data or exploring an academic interest.\nAsk yourself: Who might benefit from your proposed project? How can your project can avoid causing people harm?\nIn framing your project, look for opportunities to apply one or more of the six models of local practice described in Loukissas (2019):\n\nLook at the data setting, not just the data set\nMake place part of data presentation\nTake a comparative approach to data analysis\nCreate counterdata to challenge normative algorithms\nCreate interfaces that cause friction\nUse data to build relationships\n\nIs your project designed around what Loukissas calls the common ‚Äúambitions‚Äù for working data‚Äîorientation, access, analysis, and optimization? Or, are you trying to promote critical reflection on the local conditions of data using strategies such as place making, restraint, reflexivity, or contestation?\nYour goals may change between your initial proposal and the completion of your project but your final presentation should include both an explanation of your goals and how your goals do or do not engage with critical approaches to spatial data.\n\n\nWhat data can you use to support your goal?\nYour data could include any public spatial data or data that has a spatial attribute. You can even create data from scratch or collect your own data.\nAsk yourself: What is the ‚Äúsetting‚Äù for the data? Whose local knowledge does it represent? What communities participate in collecting or maintaining the data?\n\n\nWhat is your approach to using data to support your goal?\nYour approach could include mapping, exploratory analysis, documentation, visualization, or a combination of multiple approaches.\nYou don‚Äôt need to reinvent the wheel. You can adapt an existing approach (reproducing an existing using new data or geography) or propose a few options you hope to try and compare.\nAsk yourself: Is your proposed approach feasible in the time you have available this semester? What challenges do you anticipate in using this data?\n\n\n\n\n\n\nCiting sources with RStudio and Zotero\n\n\n\nCiting sources in RStudio is a little different than Microsoft Word so I strongly recommend using the Zotero citation manager in combination with the Better Bibtex extension. If a single R package is a big part of your proposed approach, make sure to also include a citation for the package. Read How to Cite R and R Packages by Steffi LaZerte for more background on how and why you should cite R packages.",
    "crumbs": [
      "Course information",
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#project-presentation",
    "href": "final-project.html#project-presentation",
    "title": "Final Project",
    "section": "Project presentation",
    "text": "Project presentation\nYour in-class presentation should be around five minutes and address these key questions:\n\nWhat were your initial goals for the project? How did they change or develop as you worked on your project?\nWhat data sources did you use? How, why, and where were they created?\nWhat packages, templates, or other resources did you use in creating your final project?\nWhat challenges did you encounter in making use of these resources and this data?\nWhat do you think your project does well?\n\n\n\n\n\n\n\nCreating presentations with Quarto and reveal.js\n\n\n\nUse the Quarto reveal.js presentation format for your presentation. This format can be tricky to learn but allows you to easily incorporate data visualizations or other materials from your project into your presentation.",
    "crumbs": [
      "Course information",
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#final-project-repository",
    "href": "final-project.html#final-project-repository",
    "title": "Final Project",
    "section": "Final project repository",
    "text": "Final project repository\nYour final project should be submitted as a GitHub repository. A private repository can be provided to you as part of the course organization or you can set up your own repository on your personal GitHub account.\nThe repository must include:\n\nproject data (if needed): including the source files or, if files exceed the 50MB maximum size allowed on GitHub, a script used for importing and processing the data before visualization or analysis. Students who are using {osmdata} or {tidycensus} should include scripts for downloading data but do not include the source data.\nproject code: including any R scripts, RMarkdown, or Quarto files used to read, tidy, transform, analyze, visualize or map the selected data.\noutput files: including any processed data files or rendered PDF or HTML documents.\nREADME: a public-facing summary of the project explaining your process for processing the data and any relevant information another person may need to work with the data or your code.\nadditional materials: including any data collection materials (e.g.¬†survey forms), reference data used by the project code, or other related materials.",
    "crumbs": [
      "Course information",
      "Final Project"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-12-agenda",
    "href": "slides/fall-2023.html#week-12-agenda",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 12 Agenda",
    "text": "Week 12 Agenda\n\nQuestions about the final project\nCheck-in on difficult + interesting things\nExercise 2 and 4 review (forgot this last week)\n\nLecture + practice: Reading and writing spatial data with R (continued)",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-11-agenda",
    "href": "slides/fall-2023.html#week-11-agenda",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 11 Agenda",
    "text": "Week 11 Agenda\n\nQuestions about the final project\nCheck-in on difficult + interesting things\nExercise 2 and 4 review\n\nLecture + practice: Editing OpenStreetMap and exploring OpenStreetMap data with the osmdata package\n\nLecture + practice: Reading and writing spatial data with R",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-10-agenda",
    "href": "slides/fall-2023.html#week-10-agenda",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 10 Agenda",
    "text": "Week 10 Agenda\n\nCheck-in on difficult + interesting things\nErrors of the week\n\nLecture + practice: Editing OpenStreetMap and exploring OpenStreetMap data with the osmdata package\n\nLecture + practice: Exploring American Community Survey data with the tidycensus package\nWeekly questions",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-9-agenda",
    "href": "slides/fall-2023.html#week-9-agenda",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 9 Agenda",
    "text": "Week 9 Agenda\n\nCheck-in on difficult + interesting things\nErrors of the week\n\nLecture + practice (continued): Exploratory data analysis with sf and the tidyverse\n\nLecture + practice: Editing OpenStreetMap and exploring OpenStreetMap data with the osmdata package\nWeekly questions",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-8-agenda",
    "href": "slides/fall-2023.html#week-8-agenda",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 8 Agenda",
    "text": "Week 8 Agenda\n\nCheck-in on difficult + interesting things\nFeedback on course experience (things to change, add, or keep)\nErrors of the week\n\nLecture + practice: Exploratory data analysis with sf and the tidyverse\nWeekly questions",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-7-october-11-2023",
    "href": "slides/fall-2023.html#week-7-october-11-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 7: October 11, 2023",
    "text": "Week 7: October 11, 2023\nThese past updates are in reverse chronological order.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-6-october-4-2023",
    "href": "slides/fall-2023.html#week-6-october-4-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 6: October 4, 2023",
    "text": "Week 6: October 4, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#weekly-questions",
    "href": "slides/fall-2023.html#weekly-questions",
    "title": "Fall 2023 Weekly Updates",
    "section": "Weekly questions",
    "text": "Weekly questions",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-5-september-27-2023",
    "href": "slides/fall-2023.html#week-5-september-27-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 5: September 27, 2023",
    "text": "Week 5: September 27, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-4-september-20-2023",
    "href": "slides/fall-2023.html#week-4-september-20-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 4: September 20, 2023",
    "text": "Week 4: September 20, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-3-september-13-2023",
    "href": "slides/fall-2023.html#week-3-september-13-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 3: September 13, 2023",
    "text": "Week 3: September 13, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-2-september-6-2023",
    "href": "slides/fall-2023.html#week-2-september-6-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 2: September 6, 2023",
    "text": "Week 2: September 6, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-1-september-6-2023",
    "href": "slides/fall-2023.html#week-1-september-6-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 1: September 6, 2023",
    "text": "Week 1: September 6, 2023\n\nWelcome!",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-8-october-18-2023",
    "href": "slides/fall-2023.html#week-8-october-18-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 8: October 18, 2023",
    "text": "Week 8: October 18, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-9-october-25-2023",
    "href": "slides/fall-2023.html#week-9-october-25-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 9: October 25, 2023",
    "text": "Week 9: October 25, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-10-november-1-2023",
    "href": "slides/fall-2023.html#week-10-november-1-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 10: November 1, 2023",
    "text": "Week 10: November 1, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-11-november-8-2023",
    "href": "slides/fall-2023.html#week-11-november-8-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 11: November 8, 2023",
    "text": "Week 11: November 8, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-12-november-15-2023",
    "href": "slides/fall-2023.html#week-12-november-15-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 12: November 15, 2023",
    "text": "Week 12: November 15, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-13-november-22-2023",
    "href": "slides/fall-2023.html#week-13-november-22-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 13: November 22, 2023",
    "text": "Week 13: November 22, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-14-november-29-2023",
    "href": "slides/fall-2023.html#week-14-november-29-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 14: November 29, 2023",
    "text": "Week 14: November 29, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/fall-2023.html#week-15-december-6-2023",
    "href": "slides/fall-2023.html#week-15-december-6-2023",
    "title": "Fall 2023 Weekly Updates",
    "section": "Week 15: December 6, 2023",
    "text": "Week 15: December 6, 2023",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Weekly Updates"
    ]
  },
  {
    "objectID": "slides/data-transformation.html#load-dplyr",
    "href": "slides/data-transformation.html#load-dplyr",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "1.1 Load {dplyr}",
    "text": "1.1 Load {dplyr}\n\nlibrary(dplyr)"
  },
  {
    "objectID": "slides/data-transformation.html#how-can-you-transform-your-data-using-dplyr",
    "href": "slides/data-transformation.html#how-can-you-transform-your-data-using-dplyr",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "1.2 How can you transform your data using {dplyr}?",
    "text": "1.2 How can you transform your data using {dplyr}?\n\nManipulate cases (rows)\nManipulate variables (columns)\nManipulate groups"
  },
  {
    "objectID": "slides/data-transformation.html#manipulate-cases",
    "href": "slides/data-transformation.html#manipulate-cases",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "1.3 Manipulate cases",
    "text": "1.3 Manipulate cases\n\nfilter(), which changes which rows are present without changing their order, and\narrange(), which changes the order of the rows without changing which are present.\ndistinct() which finds rows with unique values but unlike arrange() and filter() it can also optionally modify the columns."
  },
  {
    "objectID": "slides/data-transformation.html#manipulate-variables",
    "href": "slides/data-transformation.html#manipulate-variables",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "1.4 Manipulate variables",
    "text": "1.4 Manipulate variables\n\nmutate() creates new columns that are derived from the existing columns,\nselect() changes which columns are present,\nrename() changes the names of the columns, and\nrelocate() changes the positions of the columns."
  },
  {
    "objectID": "slides/data-transformation.html#manipulate-groups",
    "href": "slides/data-transformation.html#manipulate-groups",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "1.5 Manipulate groups",
    "text": "1.5 Manipulate groups\n\ngroup_by(),\nsummarize(), and\nthe slice_() family of functions."
  },
  {
    "objectID": "slides/data-transformation.html#the-pipe",
    "href": "slides/data-transformation.html#the-pipe",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "1.6 The pipe",
    "text": "1.6 The pipe"
  },
  {
    "objectID": "slides/data-transformation.html#take-a-minute",
    "href": "slides/data-transformation.html#take-a-minute",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "2.1 Take a minute ‚è∞",
    "text": "2.1 Take a minute ‚è∞"
  },
  {
    "objectID": "slides/data-transformation.html#take-a-minute-1",
    "href": "slides/data-transformation.html#take-a-minute-1",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "3.1 Take a minute ‚è∞",
    "text": "3.1 Take a minute ‚è∞"
  },
  {
    "objectID": "slides/data-transformation.html#mutate",
    "href": "slides/data-transformation.html#mutate",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "3.2 mutate()",
    "text": "3.2 mutate()\nmutate() creates new columns that are functions of existing variables.\nIt can also modify (if the name is the same as an existing column) and delete columns (by setting their value to NULL)."
  },
  {
    "objectID": "slides/data-transformation.html#summarise",
    "href": "slides/data-transformation.html#summarise",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "4.1 summarise()",
    "text": "4.1 summarise()\nsummarise() creates a new data frame with:\n\none row for each combination of grouping variables; if there are no grouping variables, the output will have a single row summarising all observations in the input.\none column for each grouping variable\none column for each of the summary statistics that you have specified."
  },
  {
    "objectID": "slides/data-transformation.html#using-filter-with-sf-objects",
    "href": "slides/data-transformation.html#using-filter-with-sf-objects",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "5.1 Using filter with sf objects",
    "text": "5.1 Using filter with sf objects\nIf you are just working with attributes (variables), sf objects work just like any other data frame:\n\nfilter(\n  storms_sf,\n  wind &gt; 50\n)\n\nBut, you can use a special set of predicate functions that work with sf objects to return a logical vector that also works with filter:\n\nfilter(\n  storms_sf,\n  as.logical(st_intersects(geometry, st_union(us_states), sparse = FALSE))\n)"
  },
  {
    "objectID": "slides/data-transformation.html#using-mutate-with-sf-objects",
    "href": "slides/data-transformation.html#using-mutate-with-sf-objects",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "5.2 Using mutate with sf objects",
    "text": "5.2 Using mutate with sf objects\n\nstorms_usa &lt;- storms_sf |&gt;\n  mutate(\n    usa_observation = as.logical(\n      st_intersects(\n        geometry,\n        st_union(us_states),\n        sparse = FALSE\n      )\n    )\n  )"
  },
  {
    "objectID": "slides/data-transformation.html#using-summarise-with-sf-objects",
    "href": "slides/data-transformation.html#using-summarise-with-sf-objects",
    "title": "Session 3: Transforming data with {dplyr} and {tidyr}",
    "section": "5.3 Using summarise with sf objects",
    "text": "5.3 Using summarise with sf objects\nYou can use summarise to combine geometry by grouping variables:\n\nstorms_categories &lt;- storms_sf |&gt;\n  group_by(category) |&gt;\n  summarise()\n\nstorms_categories"
  },
  {
    "objectID": "slides/welcome.html#what-is-this-class-about",
    "href": "slides/welcome.html#what-is-this-class-about",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "What is this class about?",
    "text": "What is this class about?"
  },
  {
    "objectID": "slides/welcome.html#what-is-this-class-about-1",
    "href": "slides/welcome.html#what-is-this-class-about-1",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "What is this class about?",
    "text": "What is this class about?\n\nWorking with data using R"
  },
  {
    "objectID": "slides/welcome.html#what-is-this-class-about-2",
    "href": "slides/welcome.html#what-is-this-class-about-2",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "What is this class about?",
    "text": "What is this class about?\n\nWorking with data spatial data using R"
  },
  {
    "objectID": "slides/welcome.html#what-is-this-class-about-3",
    "href": "slides/welcome.html#what-is-this-class-about-3",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "What is this class about?",
    "text": "What is this class about?\n\nWorking with spatial data about places"
  },
  {
    "objectID": "slides/welcome.html#what-is-this-class-about-4",
    "href": "slides/welcome.html#what-is-this-class-about-4",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "What is this class about?",
    "text": "What is this class about?\n\nWorking with spatial data about people and places"
  },
  {
    "objectID": "slides/welcome.html#what-is-this-class-about-5",
    "href": "slides/welcome.html#what-is-this-class-about-5",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "What is this class about?",
    "text": "What is this class about?\n\nWorking with spatial data local knowledge about people and places"
  },
  {
    "objectID": "slides/welcome.html#why-are-you-here",
    "href": "slides/welcome.html#why-are-you-here",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "Why are you here?",
    "text": "Why are you here?"
  },
  {
    "objectID": "slides/welcome.html#how-did-you-get-here",
    "href": "slides/welcome.html#how-did-you-get-here",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "How did you get here?",
    "text": "How did you get here?\nThis isn‚Äôt a metaphorical question.\nLet‚Äôs make a map:\n\nOpen this Felt map and trace a route for your commute to campus today\nStart as close or far from home as you like\nUse the ‚ÄúDetails‚Äù tab to add a ‚Äúname‚Äù attribute (with your name) and a ‚Äúmode‚Äù attribute (e.g.¬†UMBC Shuttle, Car or truck, Bike, etc.)"
  },
  {
    "objectID": "slides/welcome.html#what-experiences-do-you-bring-with-you-today",
    "href": "slides/welcome.html#what-experiences-do-you-bring-with-you-today",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "What experiences do you bring with you today?",
    "text": "What experiences do you bring with you today?"
  },
  {
    "objectID": "slides/welcome.html#why-am-i-here",
    "href": "slides/welcome.html#why-am-i-here",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "Why am I here?",
    "text": "Why am I here?\nA few things about me:\n\nI first started using GIS tools as a student studying anthropology and historic preservation at the University of Maryland College Park around 2007\nI started learning R as a student at the John Hopkins University School of Public Health in 2019\nI started developing R packages while working at the Neighborhood Design Center in 2020\nI work as a community planner at the Baltimore City Department of Planning (since June 2022)\n\n\nI believe in the potential of data to build power, inform collective action, and make change in the world"
  },
  {
    "objectID": "slides/welcome.html#communication",
    "href": "slides/welcome.html#communication",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "Communication üì¨",
    "text": "Communication üì¨\n\nI am not always on top of my email.\nPlease post questions to the Discord if you think other students could help (or others may share your question).\nIf you don‚Äôt get a timely response by email, message me on Discord."
  },
  {
    "objectID": "slides/welcome.html#assignments",
    "href": "slides/welcome.html#assignments",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "Assignments",
    "text": "Assignments\n\nWeekly check-in\nPractice exercises\nFinal project"
  },
  {
    "objectID": "slides/welcome.html#readings",
    "href": "slides/welcome.html#readings",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "Readings üìö",
    "text": "Readings üìö\n\nWhat are the readings?\nHow can you get the most out of the readings?"
  },
  {
    "objectID": "slides/welcome.html#miscellaneous",
    "href": "slides/welcome.html#miscellaneous",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "Miscellaneous",
    "text": "Miscellaneous"
  },
  {
    "objectID": "slides/welcome.html#welcome-again",
    "href": "slides/welcome.html#welcome-again",
    "title": "Welcome to GES 668: Building Spatial Datasets",
    "section": "Welcome again!",
    "text": "Welcome again!"
  },
  {
    "objectID": "slides/feature-geometry.html#getting-started",
    "href": "slides/feature-geometry.html#getting-started",
    "title": "Session 5: Working with spatial and geometric operations in {sf}\n",
    "section": "\n1 Getting started",
    "text": "1 Getting started\n\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tigris)\noptions(tigris_use_cache = TRUE)"
  },
  {
    "objectID": "slides/feature-geometry.html#converting-objects-between-types",
    "href": "slides/feature-geometry.html#converting-objects-between-types",
    "title": "Session 5: Working with spatial and geometric operations in {sf}\n",
    "section": "\n2 Converting objects between types",
    "text": "2 Converting objects between types"
  },
  {
    "objectID": "slides/feature-geometry.html#types-of-spatial-operations",
    "href": "slides/feature-geometry.html#types-of-spatial-operations",
    "title": "Session 5: Working with spatial and geometric operations in {sf}\n",
    "section": "\n3 Types of spatial operations",
    "text": "3 Types of spatial operations\n\nSpatial filtering and topological relations\nSpatial joins and non-overlapping joins\nSpatial aggregation"
  },
  {
    "objectID": "slides/feature-geometry.html#types-of-geometric-operations",
    "href": "slides/feature-geometry.html#types-of-geometric-operations",
    "title": "Session 5: Working with spatial and geometric operations in {sf}\n",
    "section": "\n4 Types of geometric operations",
    "text": "4 Types of geometric operations\n\nSimplification\nCentroids\nBuffers\nClipping (with or without subsetting)\nUnions\nType transformations"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#setup",
    "href": "slides/spatial-data-attributes.html#setup",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "1 Setup",
    "text": "1 Setup\nToday, we are going to use the {tidyverse} along with {sf} and two related packages: {lwgeom} and {units}.\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(lwgeom)\nlibrary(units)"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#getting-started",
    "href": "slides/spatial-data-attributes.html#getting-started",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "2 Getting started",
    "text": "2 Getting started\nFor this session, we also need some data to look at. We are going to load data from the U.S. Census Bureau using the {tigris} package:\n\nlibrary(tigris)\noptions(tigris_use_cache = TRUE)"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#things-to-remember-about-spatial-data",
    "href": "slides/spatial-data-attributes.html#things-to-remember-about-spatial-data",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "3 Things to remember about spatial data",
    "text": "3 Things to remember about spatial data\n\nFields\nObjects\n\nCheck out the Wikipedia article on data models in GIS for more background on this topic."
  },
  {
    "objectID": "slides/spatial-data-attributes.html#things-to-remember-about-sf-and-sfc-objects",
    "href": "slides/spatial-data-attributes.html#things-to-remember-about-sf-and-sfc-objects",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "4 Things to remember about sf and sfc objects",
    "text": "4 Things to remember about sf and sfc objects\nA sf object is a data frame with a sfc list-column.\n\nus_states$geometry\n\nGeometry set for 56 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: -14.60181 xmax: 179.8597 ymax: 71.43979\nGeodetic CRS:  NAD83\nFirst 5 geometries:"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#things-to-remember-about-sf-and-sfc-objects-1",
    "href": "slides/spatial-data-attributes.html#things-to-remember-about-sf-and-sfc-objects-1",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "5 Things to remember about sf and sfc objects",
    "text": "5 Things to remember about sf and sfc objects\n\na sf object is a data frame with a sfc list-column\na sf object has a sf_column attribute (it isn‚Äôt always named geometry‚Äîuse attributes() to take a look)"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#things-to-remember-about-sf-and-sfc-objects-2",
    "href": "slides/spatial-data-attributes.html#things-to-remember-about-sf-and-sfc-objects-2",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "6 Things to remember about sf and sfc objects",
    "text": "6 Things to remember about sf and sfc objects\n\na sf object is a data frame with a sfc list-column\na sf object has a sf_column attribute (it isn‚Äôt always named geometry‚Äîuse attributes() to take a look)\nsf and sfc objects use a coordinate reference system"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#things-to-remember-about-sf-and-sfc-objects-3",
    "href": "slides/spatial-data-attributes.html#things-to-remember-about-sf-and-sfc-objects-3",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "7 Things to remember about sf and sfc objects",
    "text": "7 Things to remember about sf and sfc objects\n\na sf object is a data frame with a sfc list-column\na sf object has a sf_column attribute (it isn‚Äôt always named geometry‚Äîuse attributes() to take a look)\nsf and sfc objects use a coordinate reference system\nworking with sf objects is slower than working with data frames‚Äîso drop the geometry if you don‚Äôt need it"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#things-to-remember-about-coordinate-reference-systems",
    "href": "slides/spatial-data-attributes.html#things-to-remember-about-coordinate-reference-systems",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "8 Things to remember about coordinate reference systems",
    "text": "8 Things to remember about coordinate reference systems\n\nobjects must share the same coordinate reference system if you are using them together\ncoordinate reference systems are stored as attributes for sfc and sf objects (sfg objects don‚Äôt have a CRS)\ncoordinate reference systems have units\ngeographic and projected coordinate reference systems are not the same\ncoordinate reference systems can be missing and they can be wrong"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#things-to-think-about",
    "href": "slides/spatial-data-attributes.html#things-to-think-about",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "9 Things to think about",
    "text": "9 Things to think about\n\nsf objects are not the only way to represent spatial data in R\nIf you are working with more than one sf or sfc, the objects must use the same coordinate reference system to use them together.\n\n\n# state"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#what-is-an-attribute-in-gis",
    "href": "slides/spatial-data-attributes.html#what-is-an-attribute-in-gis",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "10 What is an ‚Äúattribute‚Äù in GIS?",
    "text": "10 What is an ‚Äúattribute‚Äù in GIS?\nWithin a GIS desktop application, an attribute may be known as a field.\nWhen we talk about tidy data frames, an attribute is equivalent to a variable which is represented as a column in a data frame.\n\nhttps://support.esri.com/en-us/gis-dictionary/attribute\n\n[data models] Nonspatial information about a geographic feature in a GIS, usually stored in a table and linked to the feature by a unique identifier. For example, attributes of a river might include its name, length, and sediment load at a gauging station.\n[data models] In raster datasets, information associated with each unique value of a raster cell.\n[graphics (map display)] Information that specifies how features are displayed and labeled on a map; for example, the graphic attributes of a river might include line thickness, line length, color, and font for labeling."
  },
  {
    "objectID": "slides/spatial-data-attributes.html#what-is-an-attribute",
    "href": "slides/spatial-data-attributes.html#what-is-an-attribute",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "11 What is an attribute?",
    "text": "11 What is an attribute?\nSo (to recap) an attribute in GIS can also be called a‚Ä¶\n\n‚Ä¶field in a desktop GIS application\n‚Ä¶variable in tidy data\n‚Ä¶column in a data frame"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#what-types-of-attributes-exist",
    "href": "slides/spatial-data-attributes.html#what-types-of-attributes-exist",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "12 What types of attributes exist?",
    "text": "12 What types of attributes exist?\nAttributes are ‚Äúproperties of features (‚Äòthings‚Äô) that do not describe the feature‚Äôs geometry‚Äù.\nHere are the attributes for us_states:\n\nglimpse(st_drop_geometry(us_states))\n\nRows: 56\nColumns: 14\n$ REGION   &lt;chr&gt; \"3\", \"3\", \"2\", \"2\", \"3\", \"1\", \"4\", \"1\", \"3\", \"1\", \"1\", \"3\", \"‚Ä¶\n$ DIVISION &lt;chr&gt; \"5\", \"5\", \"3\", \"4\", \"5\", \"1\", \"8\", \"1\", \"5\", \"1\", \"1\", \"5\", \"‚Ä¶\n$ STATEFP  &lt;chr&gt; \"54\", \"12\", \"17\", \"27\", \"24\", \"44\", \"16\", \"33\", \"37\", \"50\", \"‚Ä¶\n$ STATENS  &lt;chr&gt; \"01779805\", \"00294478\", \"01779784\", \"00662849\", \"01714934\", \"‚Ä¶\n$ GEOID    &lt;chr&gt; \"54\", \"12\", \"17\", \"27\", \"24\", \"44\", \"16\", \"33\", \"37\", \"50\", \"‚Ä¶\n$ STUSPS   &lt;chr&gt; \"WV\", \"FL\", \"IL\", \"MN\", \"MD\", \"RI\", \"ID\", \"NH\", \"NC\", \"VT\", \"‚Ä¶\n$ NAME     &lt;chr&gt; \"West Virginia\", \"Florida\", \"Illinois\", \"Minnesota\", \"Marylan‚Ä¶\n$ LSAD     &lt;chr&gt; \"00\", \"00\", \"00\", \"00\", \"00\", \"00\", \"00\", \"00\", \"00\", \"00\", \"‚Ä¶\n$ MTFCC    &lt;chr&gt; \"G4000\", \"G4000\", \"G4000\", \"G4000\", \"G4000\", \"G4000\", \"G4000\"‚Ä¶\n$ FUNCSTAT &lt;chr&gt; \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"‚Ä¶\n$ ALAND    &lt;dbl&gt; 62266298634, 138961722096, 143778561906, 206232627084, 251519‚Ä¶\n$ AWATER   &lt;dbl&gt; 489204185, 45972570361, 6216493488, 18949394733, 6979074857, ‚Ä¶\n$ INTPTLAT &lt;chr&gt; \"+38.6472854\", \"+28.3989775\", \"+40.1028754\", \"+46.3159573\", \"‚Ä¶\n$ INTPTLON &lt;chr&gt; \"-080.6183274\", \"-082.5143005\", \"-089.1526108\", \"-094.1996043‚Ä¶"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#what-is-an-attribute-domain",
    "href": "slides/spatial-data-attributes.html#what-is-an-attribute-domain",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "13 What is an ‚Äúattribute domain‚Äù?",
    "text": "13 What is an ‚Äúattribute domain‚Äù?\n\n\n[data structures] In a geodatabase, a mechanism for enforcing data integrity. Attribute domains define what values are allowed in a field in a feature class or nonspatial attribute table. If the features or nonspatial objects have been grouped into subtypes, different attribute domains can be assigned to each of the subtypes."
  },
  {
    "objectID": "slides/spatial-data-attributes.html#what-are-we-working-with",
    "href": "slides/spatial-data-attributes.html#what-are-we-working-with",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "14 What are we working with?",
    "text": "14 What are we working with?\nWhen we do data analysis using {dplyr}, there are three types of functions we use most often:\n\nBoolean operators or predicates\nWindow or vector functions\nSummary or analysis functions\n\nThere are similar"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#predicate-functions-for-geometries-with-sf",
    "href": "slides/spatial-data-attributes.html#predicate-functions-for-geometries-with-sf",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "15 Predicate functions for geometries with {sf}",
    "text": "15 Predicate functions for geometries with {sf}\n{sf} includes ‚Äúvectorized‚Äù logical operators or tests that work with geometry including:\n\nst_is()\nst_is_valid()\nst_is_empty()"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#predicate-functions-for-geometries-with-sf-1",
    "href": "slides/spatial-data-attributes.html#predicate-functions-for-geometries-with-sf-1",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "16 Predicate functions for geometries with {sf}",
    "text": "16 Predicate functions for geometries with {sf}\n{sf} also includes more than a dozen predicate functions for working with pairs of simple geometries including:\n\nst_intersects\nst_disjoint\nst_contains\nst_covers\nst_is_within_distance"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#using-predicate-functions-for-spatial-joins-and-filters",
    "href": "slides/spatial-data-attributes.html#using-predicate-functions-for-spatial-joins-and-filters",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "17 Using predicate functions for spatial joins and filters",
    "text": "17 Using predicate functions for spatial joins and filters\nst_filter() and st_join() are two functions that rely on these predicate functions to work."
  },
  {
    "objectID": "slides/spatial-data-attributes.html#creating-new-variables-with-geometry",
    "href": "slides/spatial-data-attributes.html#creating-new-variables-with-geometry",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "18 Creating new variables with geometry",
    "text": "18 Creating new variables with geometry\n\nMeasuring feature geometries\nComparing feature geometries\nJoining data based on feature geometries\n\n\nmaryland &lt;- filter(us_states, NAME == \"Maryland\")"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#measuring-geometries-with-sf",
    "href": "slides/spatial-data-attributes.html#measuring-geometries-with-sf",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "19 Measuring geometries with {sf}",
    "text": "19 Measuring geometries with {sf}"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-1",
    "href": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-1",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "20 Measuring geometries with {sf}",
    "text": "20 Measuring geometries with {sf}\n{sf} includes a few different functions for measuring geometries:\n\nst_area() (only works with POLYGON and MULTIPOLYGON geometries)\nst_length() (only wrks with LINESTRING and MULTILINSTRING geometries)\nst_distance() (requires a pair of objects)"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-2",
    "href": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-2",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "21 Measuring geometries with {sf}",
    "text": "21 Measuring geometries with {sf}\nAll of these functions are vectorized meaning that they can operate independently on each feature in a sf or sfc object.\nThey support both sf inputs (data frames) and sfc inputs (lists)‚Äîbut they always return a vector:\n\nst_area(maryland)\n\n53204014221 [m^2]\n\nst_area(maryland$geometry)\n\n53204014221 [m^2]"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-3",
    "href": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-3",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "22 Measuring geometries with {sf}",
    "text": "22 Measuring geometries with {sf}\nBut, remember, dplyr::mutate() is designed to work with vectorized functions so you can do us a measurement function inside mutate():\n\nmaryland |&gt; \n  mutate(\n    area = st_area(geometry)\n  )\n\nSimple feature collection with 1 feature and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -8848525 ymin: 4563419 xmax: -8347435 ymax: 4825776\nProjected CRS: WGS 84 / Pseudo-Mercator\n  REGION DIVISION STATEFP  STATENS GEOID STUSPS     NAME LSAD MTFCC FUNCSTAT\n1      3        5      24 01714934    24     MD Maryland   00 G4000        A\n        ALAND     AWATER    INTPTLAT     INTPTLON\n1 25151992308 6979074857 +38.9466584 -076.6744939\n                        geometry              area\n1 MULTIPOLYGON (((-8434299 47... 53204014221 [m^2]"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-4",
    "href": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-4",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "23 Measuring geometries with {sf}",
    "text": "23 Measuring geometries with {sf}\nYou can even work with multiple geometries using this same approach:\n\nus_states |&gt; \n  mutate(\n    area = st_area(geometry),\n    distance_to_maryland = st_distance(geometry, maryland)\n  )\n\nSimple feature collection with 56 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -19951910 ymin: -1643353 xmax: 20021890 ymax: 11554350\nProjected CRS: WGS 84 / Pseudo-Mercator\nFirst 10 features:\n   REGION DIVISION STATEFP  STATENS GEOID STUSPS           NAME LSAD MTFCC\n1       3        5      54 01779805    54     WV  West Virginia   00 G4000\n2       3        5      12 00294478    12     FL        Florida   00 G4000\n3       2        3      17 01779784    17     IL       Illinois   00 G4000\n4       2        4      27 00662849    27     MN      Minnesota   00 G4000\n5       3        5      24 01714934    24     MD       Maryland   00 G4000\n6       1        1      44 01219835    44     RI   Rhode Island   00 G4000\n7       4        8      16 01779783    16     ID          Idaho   00 G4000\n8       1        1      33 01779794    33     NH  New Hampshire   00 G4000\n9       3        5      37 01027616    37     NC North Carolina   00 G4000\n10      1        1      50 01779802    50     VT        Vermont   00 G4000\n   FUNCSTAT        ALAND      AWATER    INTPTLAT     INTPTLON\n1         A  62266298634   489204185 +38.6472854 -080.6183274\n2         A 138961722096 45972570361 +28.3989775 -082.5143005\n3         A 143778561906  6216493488 +40.1028754 -089.1526108\n4         A 206232627084 18949394733 +46.3159573 -094.1996043\n5         A  25151992308  6979074857 +38.9466584 -076.6744939\n6         A   2677763359  1323686988 +41.5964850 -071.5264901\n7         A 214049931578  2391569647 +44.3484222 -114.5588538\n8         A  23190115212  1025971768 +43.6726907 -071.5843145\n9         A 125933327733 13456093195 +35.5397100 -079.1308636\n10        A  23872569964  1030754609 +44.0589536 -072.6710173\n                         geometry               area distance_to_maryland\n1  MULTIPOLYGON (((-9001123 44... 103045932411 [m^2]              0.0 [m]\n2  MULTIPOLYGON (((-9251622 28... 240290408316 [m^2]        1122737.0 [m]\n3  MULTIPOLYGON (((-9926591 44... 257089838319 [m^2]         893538.7 [m]\n4  MULTIPOLYGON (((-10324402 5... 473223859874 [m^2]        1423100.6 [m]\n5  MULTIPOLYGON (((-8434299 47...  53204014221 [m^2]              0.0 [m]\n6  MULTIPOLYGON (((-7979248 50...   7160497121 [m^2]         490274.7 [m]\n7  MULTIPOLYGON (((-12361526 5... 424675068451 [m^2]        3530363.1 [m]\n8  MULTIPOLYGON (((-7931011 52...  46326405218 [m^2]         579065.3 [m]\n9  MULTIPOLYGON (((-8562247 43... 210941928191 [m^2]         186785.1 [m]\n10 MULTIPOLYGON (((-8063385 53...  48271922011 [m^2]         527897.6 [m]\n\n\nThis works to aggregate features by division:\n\nus_states |&gt; \n  group_by(DIVISION) |&gt; \n  summarise(\n    n_states = n_distinct(NAME)\n  ) \n\nSimple feature collection with 10 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -19951910 ymin: -1643353 xmax: 20021890 ymax: 11554350\nProjected CRS: WGS 84 / Pseudo-Mercator\n# A tibble: 10 √ó 3\n   DIVISION n_states                                                    geometry\n   &lt;chr&gt;       &lt;int&gt;                                              &lt;GEOMETRY [m]&gt;\n 1 0               5 MULTIPOLYGON (((-18726019 -1633065, -18725998 -1633025, -1‚Ä¶\n 2 1               6 MULTIPOLYGON (((-7978692 5038758, -7978581 5039616, -79783‚Ä¶\n 3 2               3 POLYGON ((-8290777 4763109, -8291389 4762454, -8291849 476‚Ä¶\n 4 3               5 POLYGON ((-9926785 4448353, -9926789 4448327, -9926792 444‚Ä¶\n 5 4               7 POLYGON ((-10176807 4921011, -10176847 4920961, -10177047 ‚Ä¶\n 6 5               9 MULTIPOLYGON (((-9250560 2835330, -9249947 2836819, -92493‚Ä¶\n 7 6               4 POLYGON ((-9840190 3523448, -9841106 3523126, -9842801 352‚Ä¶\n 8 7               4 POLYGON ((-9958183 3524892, -9957969 3524935, -9957739 352‚Ä¶\n 9 8               8 POLYGON ((-11671608 3763365, -11671634 3763365, -11672322 ‚Ä¶\n10 9               5 MULTIPOLYGON (((-19000283 2939831, -19000200 2940106, -190‚Ä¶"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-5",
    "href": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-5",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "24 Measuring geometries with {sf}",
    "text": "24 Measuring geometries with {sf}\nNot all functions work with all geometry types!\n\nst_area() only works with POLYGON and MULTIPOLYGON geometries\nst_length() only works with LINESTRING and MULTILINSTRING geometries"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-6",
    "href": "slides/spatial-data-attributes.html#measuring-geometries-with-sf-6",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "25 Measuring geometries with {sf}",
    "text": "25 Measuring geometries with {sf}\n\nst_distance() requires at least two objects"
  },
  {
    "objectID": "slides/spatial-data-attributes.html#measuring-geometries-with-lwgeom-and-geosphere",
    "href": "slides/spatial-data-attributes.html#measuring-geometries-with-lwgeom-and-geosphere",
    "title": "Creating and manipulating attributes for spatial data",
    "section": "26 Measuring geometries with {lwgeom} and {geosphere}",
    "text": "26 Measuring geometries with {lwgeom} and {geosphere}\n\nlwgeom::st_perimeter()\ngeosphere::bearing()"
  },
  {
    "objectID": "slides/exploratory-analysis.html#why-open-your-work",
    "href": "slides/exploratory-analysis.html#why-open-your-work",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n1.1 Why open your work?",
    "text": "1.1 Why open your work?\n\nImprove the quality of your work: ‚Äúbe more organized, more accurate, less likely to miss errors‚Äù\nBroaden reach and impact\nFoster data literacy: ‚Äúothers can follow and learn‚Äîwhich can enrich and diversify data ecosystems, practices, and communities‚Äù"
  },
  {
    "objectID": "slides/exploratory-analysis.html#how-to-open-your-work",
    "href": "slides/exploratory-analysis.html#how-to-open-your-work",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n1.2 How to open your work?",
    "text": "1.2 How to open your work?\nConsider:\n\nwhen is transparency valuable?\nwhen is transparency a lower priority?\nwhen is transparency potentially harmful?"
  },
  {
    "objectID": "slides/exploratory-analysis.html#what-do-you-do-when-you-do-exploratory-data-analysis",
    "href": "slides/exploratory-analysis.html#what-do-you-do-when-you-do-exploratory-data-analysis",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.1 What do you do when you do exploratory data analysis?",
    "text": "2.1 What do you do when you do exploratory data analysis?\n\nGenerate questions about your data.\nSearch for answers by visualizing, transforming, and modelling your data.\nUse what you learn to refine your questions and/or generate new questions.\n\n‚ÄúMore than anything, EDA is a state of mind.‚Äù"
  },
  {
    "objectID": "slides/exploratory-analysis.html#use-questions-as-tools-to-guide-your-investigation",
    "href": "slides/exploratory-analysis.html#use-questions-as-tools-to-guide-your-investigation",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.2 Use questions as tools to guide your investigation",
    "text": "2.2 Use questions as tools to guide your investigation\nWhen you ask a question‚Ä¶\n\nthe question focuses your attention on a specific part of your dataset\nthis helps you decide which graphs, models, or transformations to make.\nthe¬†key to asking¬†quality¬†questions is to generate a large¬†quantity¬†of questions\n\n\nYour goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which graphs, models, or transformations to make."
  },
  {
    "objectID": "slides/exploratory-analysis.html#two-useful-questions-to-start",
    "href": "slides/exploratory-analysis.html#two-useful-questions-to-start",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.3 Two useful questions to start",
    "text": "2.3 Two useful questions to start\n\nWhat type of variation occurs within my variables?\nWhat type of covariation occurs between my variables?"
  },
  {
    "objectID": "slides/exploratory-analysis.html#what-are-you-exploring-when-you-do-exploratory-data-analysis",
    "href": "slides/exploratory-analysis.html#what-are-you-exploring-when-you-do-exploratory-data-analysis",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.4 What are you ‚Äúexploring‚Äù when you do exploratory data analysis?",
    "text": "2.4 What are you ‚Äúexploring‚Äù when you do exploratory data analysis?"
  },
  {
    "objectID": "slides/exploratory-analysis.html#variation",
    "href": "slides/exploratory-analysis.html#variation",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.5 Variation",
    "text": "2.5 Variation"
  },
  {
    "objectID": "slides/exploratory-analysis.html#covariation",
    "href": "slides/exploratory-analysis.html#covariation",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.6 Covariation",
    "text": "2.6 Covariation\n\nCovariation¬†is the tendency for the values of two or more variables to vary together in a related way. The best way to spot covariation is to visualize the relationship between two or more variables."
  },
  {
    "objectID": "slides/exploratory-analysis.html#patterns-and-models",
    "href": "slides/exploratory-analysis.html#patterns-and-models",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.7 Patterns and models",
    "text": "2.7 Patterns and models\nIf a systematic relationship exists between two variables it will appear as a pattern in the data. If you spot a pattern, ask yourself:\n\nCould this pattern be due to coincidence (i.e.¬†random chance)?\n\nHow can you describe the relationship implied by the pattern?\nHow strong is the relationship implied by the pattern?\nWhat other variables might affect the relationship?\nDoes the relationship change if you look at individual subgroups of the data?"
  },
  {
    "objectID": "slides/exploratory-analysis.html#tools-for-data-exploration",
    "href": "slides/exploratory-analysis.html#tools-for-data-exploration",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.8 Tools for data exploration",
    "text": "2.8 Tools for data exploration"
  },
  {
    "objectID": "slides/exploratory-analysis.html#communicating",
    "href": "slides/exploratory-analysis.html#communicating",
    "title": "Session 8: Exploratory data analysis",
    "section": "\n2.9 Communicating",
    "text": "2.9 Communicating"
  },
  {
    "objectID": "slides/open-street-map.html#overview",
    "href": "slides/open-street-map.html#overview",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "1 Overview",
    "text": "1 Overview\n\nWhat is OpenStreetMap?\nHow do you contribute to OpenStreetMap?\nHow do you download data from OpenStreetMap?\n\nThese slides on OpenStreetMap and exploring OSM data with the {osmdata} package are based on a March 10, 2020 presentation by Jonathan Dandois for MaptimeBmore and the CCBC GIS Capstone."
  },
  {
    "objectID": "slides/open-street-map.html#what-is-openstreetmap",
    "href": "slides/open-street-map.html#what-is-openstreetmap",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "2 What is OpenStreetMap?",
    "text": "2 What is OpenStreetMap?\n\nCreated in 2004 in response to restrictive data sharing by the UK Ordnance Survey\nGrew as the ‚ÄúWikipedia of maps‚Äù in response to increasing cost of commercial services like Google Maps after 2011 price hikes"
  },
  {
    "objectID": "slides/open-street-map.html#using-openstreetmap",
    "href": "slides/open-street-map.html#using-openstreetmap",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "3 Using OpenStreetMap",
    "text": "3 Using OpenStreetMap\n\nOpenStreetMap isn‚Äôt just a map‚Äîit is a¬†‚Äúglobal geodatabase¬†of everything¬†and¬†anything¬†that people add to the map‚Äù:\n\nroads, crosswalks, speed bumps, stop lights\nrestaurants, daycares, playgrounds, cannons\nforests, central business districts, boundaries\nland cover, gravestones, utility ROWs"
  },
  {
    "objectID": "slides/open-street-map.html#who-is-using-openstreetmap",
    "href": "slides/open-street-map.html#who-is-using-openstreetmap",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "4 Who is using OpenStreetMap?",
    "text": "4 Who is using OpenStreetMap?\nIndividual users, developers, and researchers:\n\nApps and websites\nGames\nAdvocacy and policy"
  },
  {
    "objectID": "slides/open-street-map.html#who-is-using-openstreetmap-1",
    "href": "slides/open-street-map.html#who-is-using-openstreetmap-1",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "5 Who is using OpenStreetMap?",
    "text": "5 Who is using OpenStreetMap?"
  },
  {
    "objectID": "slides/open-street-map.html#contributing-to-open-street-map",
    "href": "slides/open-street-map.html#contributing-to-open-street-map",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "6 Contributing to Open Street Map",
    "text": "6 Contributing to Open Street Map\nDifferent editors have different reasons for contributing and contribute in different ways:\n\nIndividuals\nPublic agencies\nNon-profit organizations\nCorporations\n\n\nDifferent editors use different tools, focus on editing different resources.\nOther options include:\n\nArcGIS Editor for OpenStreetMap"
  },
  {
    "objectID": "slides/open-street-map.html#tracing-and-digitizing-imagery",
    "href": "slides/open-street-map.html#tracing-and-digitizing-imagery",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "7 Tracing and digitizing imagery",
    "text": "7 Tracing and digitizing imagery\nMost editors for OpenStreetMap use high-resolution aerial, satellite, and drone-based imagery to trace or digitize:\n\nPOIs, addresses (points)\nRoads, sidewalks, paths (lines)\nSchool areas, central business districts, parks, lakes, playgrounds (polygons)\n\nLearn more in Getting Started with OSM."
  },
  {
    "objectID": "slides/open-street-map.html#what-is-good-editing",
    "href": "slides/open-street-map.html#what-is-good-editing",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "8 What is ‚Äúgood‚Äù editing?",
    "text": "8 What is ‚Äúgood‚Äù editing?\nLearn more in the Good practice section of the OpenStreetMap Wiki."
  },
  {
    "objectID": "slides/open-street-map.html#downloading-data-with-overpass-turbo",
    "href": "slides/open-street-map.html#downloading-data-with-overpass-turbo",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "9 Downloading data with overpass turbo",
    "text": "9 Downloading data with overpass turbo\n overpass turbo, a web-based data filtering tool for¬†OpenStreetMap, can run¬†Overpass API¬†queries and analyze the resulting OSM data interactively on a map."
  },
  {
    "objectID": "slides/open-street-map.html#open-historical-map",
    "href": "slides/open-street-map.html#open-historical-map",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "10 Open Historical Map",
    "text": "10 Open Historical Map"
  },
  {
    "objectID": "slides/open-street-map.html#section",
    "href": "slides/open-street-map.html#section",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "11 ",
    "text": "11"
  },
  {
    "objectID": "slides/open-street-map.html#downloading-data-with-osmdata",
    "href": "slides/open-street-map.html#downloading-data-with-osmdata",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "12 Downloading data with {osmdata}",
    "text": "12 Downloading data with {osmdata}\n\nosmdata is an R package for accessing the data underlying OpenStreetMap (OSM), delivered via the Overpass API.\nThe package is designed to allow access to small-to-medium-sized OSM datasets (see osmextract for an approach for reading-in bulk OSM data extracts)."
  },
  {
    "objectID": "slides/open-street-map.html#resources",
    "href": "slides/open-street-map.html#resources",
    "title": "Session 9: Editing OpenStreetMap and exploring OpenStreetMap data with the {osmdata} package",
    "section": "13 Resources",
    "text": "13 Resources\n\nOSM Wiki\nLearnOSM\nTeachOSM"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "GES668: Building Spatial Datasets",
    "section": "",
    "text": "In this course, students learn how to access and understand spatial data using the R programming language and the sf and tidyverse family of R packages. Working with open-source tools, reproducible methods, and real world data, students develop skills in the fundamentals of reading and wrangling spatial data.\nReadings and practical exercise prepare students to build and maintain data sets about local places and navigate critical issues including data ownership, accuracy, and privacy considerations.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "weeks/week_09.html",
    "href": "weeks/week_09.html",
    "title": "Week 9",
    "section": "",
    "text": "Mark Padgham and Robin Lovelace ‚Äú1. Osmdata‚Äù (osmdata, August 15, 2023), https://docs.ropensci.org/osmdata/articles/osmdata.html.\nAlan McConchie ‚ÄúOpenStreetMap Pasts, OpenStreetMap Futures,‚Äù July 27, 2016, https://www.youtube.com/watch?v=KNTSZGnQVRw.\n\n\n\n\n\nGeoff Boeing ‚ÄúThe Right Tools for the Job: The Case for Spatial Science Tool-Building,‚Äù Transactions in GIS 24, no. 5 (October 2020): 1299‚Äì1314, doi:10.1111/tgis.12678.\nDani Arribas-Bel and Jon Reades ‚ÄúGeography and Computers: Past, Present, and Future,‚Äù Geography Compass 12, no. 10 (2018): e12403, doi:10.1111/gec3.12403.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week_09.html#prepare",
    "href": "weeks/week_09.html#prepare",
    "title": "Week 9",
    "section": "",
    "text": "Mark Padgham and Robin Lovelace ‚Äú1. Osmdata‚Äù (osmdata, August 15, 2023), https://docs.ropensci.org/osmdata/articles/osmdata.html.\nAlan McConchie ‚ÄúOpenStreetMap Pasts, OpenStreetMap Futures,‚Äù July 27, 2016, https://www.youtube.com/watch?v=KNTSZGnQVRw.\n\n\n\n\n\nGeoff Boeing ‚ÄúThe Right Tools for the Job: The Case for Spatial Science Tool-Building,‚Äù Transactions in GIS 24, no. 5 (October 2020): 1299‚Äì1314, doi:10.1111/tgis.12678.\nDani Arribas-Bel and Jon Reades ‚ÄúGeography and Computers: Past, Present, and Future,‚Äù Geography Compass 12, no. 10 (2018): e12403, doi:10.1111/gec3.12403.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week_11.html",
    "href": "weeks/week_11.html",
    "title": "Week 11",
    "section": "",
    "text": "Reminder! Your project proposal is due by 2023-11-13.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week_11.html#overview",
    "href": "weeks/week_11.html#overview",
    "title": "Week 11",
    "section": "Overview",
    "text": "Overview\n\nReview uses of common data file formats and web services\nDownloading data from Socrata open data portals with {RSocrata}",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week_11.html#prepare",
    "href": "weeks/week_11.html#prepare",
    "title": "Week 11",
    "section": "Prepare",
    "text": "Prepare\n\nRequired readings\n\nCh. 8 Geographic data I/O in Robin Lovelace, Jakub Nowosad, and Jannes Muenchow Geocomputation with R, 2nd (WIP)., 2022, https://geocompr.robinlovelace.net/.\nCh. 21 Spreadsheets in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\n\n\n\nOptional readings\n\nTom MacWright ‚ÄúMore Than You Ever Wanted to Know about GeoJSON‚Äù (Tom MacWright, March 23, 2015), https://macwright.com/2015/03/23/geojson-second-bite.html.\nOpenGeoLabs ‚ÄúSwitch from Shapefile,‚Äù October 5, 2017, http://switchfromshapefile.org/.\nSpatial Data on the Web Working Group ‚ÄúSpatial Data on the Web Best Practices,‚Äù September 28, 2017, https://www.w3.org/TR/sdw-bp/.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week_11.html#participate",
    "href": "weeks/week_11.html#participate",
    "title": "Week 11",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Creating and managing spatial metadata",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week_04.html",
    "href": "weeks/week_04.html",
    "title": "Week 4",
    "section": "",
    "text": "Summarizing features with dplyr::summarize()",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#overview",
    "href": "weeks/week_04.html#overview",
    "title": "Week 4",
    "section": "",
    "text": "Summarizing features with dplyr::summarize()",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#prepare",
    "href": "weeks/week_04.html#prepare",
    "title": "Week 4",
    "section": "Prepare",
    "text": "Prepare\n\nRequired readings\n\nCh. 3 Attribute data operations in Robin Lovelace, Jakub Nowosad, and Jannes Muenchow Geocomputation with R, 2nd (WIP)., 2022, https://geocompr.robinlovelace.net/.\nCh. 3 Collecting Infrastructures in Yanni Alexander Loukissas All Data Are Local: Thinking Critically in a Data-Driven Society, 2019, doi:10.7551/mitpress/11543.001.0001.\n\n\n\nOptional readings\n\nCh. 5 Attributes and Support in Edzer Pebesma and Roger Bivand Spatial Data Science (CRC Press, 2023), https://r-spatial.org/book/.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#participate",
    "href": "weeks/week_04.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Creating and manipulating attributes for spatial data",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_04.html#practice",
    "href": "weeks/week_04.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\nüõ† Look out for a combined exercise for week 4 and 5.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week_06.html",
    "href": "weeks/week_06.html",
    "title": "Week 6",
    "section": "",
    "text": "Joining tables by attribute with {dplyr}\nUsing {stringr} functions to tidy messy address data\nRecoding categorical attribute data with {forcats}\nConverting between wide and long data formats with dplyr::pivot_longer() and dplyr::pivot_wider()\nWorking with date-time attributes using {lubridate}",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#overview",
    "href": "weeks/week_06.html#overview",
    "title": "Week 6",
    "section": "",
    "text": "Joining tables by attribute with {dplyr}\nUsing {stringr} functions to tidy messy address data\nRecoding categorical attribute data with {forcats}\nConverting between wide and long data formats with dplyr::pivot_longer() and dplyr::pivot_wider()\nWorking with date-time attributes using {lubridate}",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#prepare",
    "href": "weeks/week_06.html#prepare",
    "title": "Week 6",
    "section": "Prepare",
    "text": "Prepare\n\nRequired reading\n\nCh. 6 Data tidying in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\nCh. 20 Joins in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\nKarl W. Broman and Kara H. Woo ‚ÄúData Organization in Spreadsheets,‚Äù The American Statistician 72, no. 1 (January 2, 2018): 2‚Äì10, doi:10.1080/00031305.2017.1375989.\n\n\n\nOptional reading\n\n‚ÄúThe Quartz Guide to Bad Data‚Äù (Quartz, August 31, 2022), https://github.com/Quartz/bad-data-guide.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#participate",
    "href": "weeks/week_06.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Tidying and joining data",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_06.html#practice",
    "href": "weeks/week_06.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\nüõ†Ô∏èÔ∏è Exercise 06",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week_13.html",
    "href": "weeks/week_13.html",
    "title": "Week 13",
    "section": "",
    "text": "Reminder! Peer feedback on project proposals is due by 2023-11-22.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week_13.html#prepare",
    "href": "weeks/week_13.html#prepare",
    "title": "Week 13",
    "section": "Prepare",
    "text": "Prepare\n\nRequired readings\n\nCh. 6 Models of Local Practice in Yanni Alexander Loukissas All Data Are Local: Thinking Critically in a Data-Driven Society, 2019, doi:10.7551/mitpress/11543.001.0001.\nCh. 7 Local Ends in Loukissas All Data Are Local.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week_13.html#practice",
    "href": "weeks/week_13.html#practice",
    "title": "Week 13",
    "section": "Practice",
    "text": "Practice\nThere are no more practice exercises!",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week_03.html",
    "href": "weeks/week_03.html",
    "title": "Week 3",
    "section": "",
    "text": "Week 3 updates\nMapping with {ggplot} review\nIntroduction to data transformation with {dplyr}\nUsing {dplyr} with sf objects\n\n\n\n\n\n\n\nKey Objectives\n\n\n\n\nIntroduction to the concept of ‚Äútidy data‚Äù\nLearn to subset data with dplyr::filter()\nLearn to create new variables with dplyr::mutate()",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#overview",
    "href": "weeks/week_03.html#overview",
    "title": "Week 3",
    "section": "",
    "text": "Week 3 updates\nMapping with {ggplot} review\nIntroduction to data transformation with {dplyr}\nUsing {dplyr} with sf objects\n\n\n\n\n\n\n\nKey Objectives\n\n\n\n\nIntroduction to the concept of ‚Äútidy data‚Äù\nLearn to subset data with dplyr::filter()\nLearn to create new variables with dplyr::mutate()",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#prepare",
    "href": "weeks/week_03.html#prepare",
    "title": "Week 3",
    "section": "Prepare",
    "text": "Prepare\n\nRequired readings\n\nCh. 5 Data transformation in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\nCh. 2 A Place for Plant Data in Yanni Alexander Loukissas All Data Are Local: Thinking Critically in a Data-Driven Society, 2019, doi:10.7551/mitpress/11543.001.0001.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#participate",
    "href": "weeks/week_03.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Transforming data with {dplyr} and {tidyr}",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_03.html#practice",
    "href": "weeks/week_03.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\nüõ†Ô∏èÔ∏è Exercise 03",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week_14.html",
    "href": "weeks/week_14.html",
    "title": "Week 14",
    "section": "",
    "text": "Reminder! Your final project presentation is due on 2023-12-06",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 14"
    ]
  },
  {
    "objectID": "weeks/week_15.html",
    "href": "weeks/week_15.html",
    "title": "Week 15",
    "section": "",
    "text": "Reminder! Your final project repository is due on 2023-12-14",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 15"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "MIT License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2023 Eli Pousson\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "course-exercises.html",
    "href": "course-exercises.html",
    "title": "Completing and submitting practice exercises",
    "section": "",
    "text": "You must sign up for a GitHub user account and share your GitHub username with me before I can create an exercise repository for you.\nNote that you must have installed R and RStudio to complete exercises and installed GitHub Desktop to submit exercises.\nSoon after I get your username, you should expect an email asking you to accept an invitation to the ‚Äú2023_Students‚Äù Team in the class GitHub organization.\nThis is a private repository just for your exercise assignments so the repository will be named: &lt;your first name&gt;_&lt;your last name&gt; and can be accessed at: https://github.com/bldgspatialdata/&lt;your first name&gt;_&lt;your last name&gt;. Don‚Äôt forget to replace the placeholder with your first and last name in lower case. You can also go to the course repository list and, if you are logged in and have access, you should find your repository there.\n\n\n\n\n\n\n\nWhat is a repository?\n\n\n\n\n\nA repository is a collection of files where changes can be tracked and managed using a version control system. Git is a version control system. GitHub is a web service that makes it easier to manage version-controlled repositories and collaborate with others. For more background, read Ch. 1 Why Git? Why GitHub? from Happy Git and GitHub for the useR by Jenny Bryan.\n\n\n\n\n\n\nIf you are using RStudio instead of GitHub Desktop to update your repository, you also need to set up some local credentials so GitHub knows that RStudio is allowed to make changes to your repositories. You\nThe {usethis} documentation includes detailed article on connecting GitHub and R but it is more detail than you may need. First, install the {usethis} package (if you don‚Äôt have it installed already):\n\n# pak::pkg_install(\"usethis\")\n\nNow, there are four steps (the first step is optional):\n\nSet up two-factor authentication. This is optional but recommended.\nRun usethis::create_github_token() to get a personal access token and copy the token to your clipboard. Make sure you are signed in to GitHub in your browser first! I also suggest setting the expiration to 90 days so you won‚Äôt need to refresh the token until after the end of this course.\nRun gitcreds::gitcreds_set() to put your PAT in your Git credential store\nRestart your session and run usethis::gh_token_help() to double-check that the token is saved in the right place.\n\nIf you run into any trouble, you can also run usethis::git_sitrep() for more feedback on what is set up correctly and what (if anything) might need to be fixed.",
    "crumbs": [
      "Course information",
      "Exercise How-to"
    ]
  },
  {
    "objectID": "course-exercises.html#access-your-exercise-repository",
    "href": "course-exercises.html#access-your-exercise-repository",
    "title": "Completing and submitting practice exercises",
    "section": "",
    "text": "You must sign up for a GitHub user account and share your GitHub username with me before I can create an exercise repository for you.\nNote that you must have installed R and RStudio to complete exercises and installed GitHub Desktop to submit exercises.\nSoon after I get your username, you should expect an email asking you to accept an invitation to the ‚Äú2023_Students‚Äù Team in the class GitHub organization.\nThis is a private repository just for your exercise assignments so the repository will be named: &lt;your first name&gt;_&lt;your last name&gt; and can be accessed at: https://github.com/bldgspatialdata/&lt;your first name&gt;_&lt;your last name&gt;. Don‚Äôt forget to replace the placeholder with your first and last name in lower case. You can also go to the course repository list and, if you are logged in and have access, you should find your repository there.\n\n\n\n\n\n\n\nWhat is a repository?\n\n\n\n\n\nA repository is a collection of files where changes can be tracked and managed using a version control system. Git is a version control system. GitHub is a web service that makes it easier to manage version-controlled repositories and collaborate with others. For more background, read Ch. 1 Why Git? Why GitHub? from Happy Git and GitHub for the useR by Jenny Bryan.\n\n\n\n\n\n\nIf you are using RStudio instead of GitHub Desktop to update your repository, you also need to set up some local credentials so GitHub knows that RStudio is allowed to make changes to your repositories. You\nThe {usethis} documentation includes detailed article on connecting GitHub and R but it is more detail than you may need. First, install the {usethis} package (if you don‚Äôt have it installed already):\n\n# pak::pkg_install(\"usethis\")\n\nNow, there are four steps (the first step is optional):\n\nSet up two-factor authentication. This is optional but recommended.\nRun usethis::create_github_token() to get a personal access token and copy the token to your clipboard. Make sure you are signed in to GitHub in your browser first! I also suggest setting the expiration to 90 days so you won‚Äôt need to refresh the token until after the end of this course.\nRun gitcreds::gitcreds_set() to put your PAT in your Git credential store\nRestart your session and run usethis::gh_token_help() to double-check that the token is saved in the right place.\n\nIf you run into any trouble, you can also run usethis::git_sitrep() for more feedback on what is set up correctly and what (if anything) might need to be fixed.",
    "crumbs": [
      "Course information",
      "Exercise How-to"
    ]
  },
  {
    "objectID": "course-exercises.html#download-or-update-your-exercise-repository",
    "href": "course-exercises.html#download-or-update-your-exercise-repository",
    "title": "Completing and submitting practice exercises",
    "section": "2 Download or update your exercise repository",
    "text": "2 Download or update your exercise repository\n\n2.1 Downloading (a.k.a ‚Äúcloning‚Äù) your exercise repository\n\nClone the repository to your computer using GitHub Desktop or using the GitHub website. Review the GitHub documentation on cloning a repository with GitHub Desktop or the GitHub website for more detailed instructions.\nFind and open folder where you downloaded the local copy of the exercise repository. By default, this folder should have the same name as the repository itself.\nAs long as you keep this folder on your computer, you should do not need to clone the repository again. If you delete your local files or switch computers, you need to repeat this step.\n\n\n\n2.2 Updating (a.k.a ‚Äúsyncing‚Äù) your exercise repository\n\nI will be adding new exercises to your repository each week using GitHub. You should ‚Äúsync‚Äù the changes to the GitHub repository with your local copy of the project each week. Read the GitHub documentation on Syncing your branch in GitHub Desktop for more detailed instructions.",
    "crumbs": [
      "Course information",
      "Exercise How-to"
    ]
  },
  {
    "objectID": "course-exercises.html#complete-the-weeks-exercise",
    "href": "course-exercises.html#complete-the-weeks-exercise",
    "title": "Completing and submitting practice exercises",
    "section": "3 Complete the week‚Äôs exercise",
    "text": "3 Complete the week‚Äôs exercise\nThe process for completing will be mostly the same for each week of the class.\n\n3.1 Locating the week‚Äôs exercise file\n\nLocate the &lt;your first name&gt;_&lt;your last name&gt;/exercises folder on your computer.\nOpen the exercises.RProj file in RStudio. Review the documentation on managing projects in RStudio or the R for Data Science chapter on working with projects for more background on why projects are useful.\nUsing the ‚ÄúFiles‚Äù tab pane, locate the exercise_01.qmd file (or the number exercise file for this week) and open it. The file extension (.qmd) is short for Quarto Markdown document.\nIf you can‚Äôt find this week‚Äôs exercise file, you may have forgotten to update the repository. Go back and check Section¬†2.2\n\n\n\n\n\n\n\nWhat is a Quarto document?\n\n\n\n\n\nA Quarto document is a format that lets you mix blocks (also known as ‚Äúchunks‚Äù) of R code with sections of text formatted using Markdown formatting. This format is similar to an older format known as RMarkdown (.Rmd). Quarto comes installed with RStudio but it is a separate command line application that can turn a qmd document into a standalone website, a formatted PDF, a presentation, and more. This course website, for example, is built with Quarto.\nYou can see that a front matter section at the top of each document. This front matter (also known as YAML) controls the format, appearance, and content of the rendered document.\nThe Hello, Quarto tutorial is a great place to learn how to render Quarto documents, run code blocks interactively, and format text using the markdown syntax.\n\n\n\n\nComplete the project by filling in the blank spaces, fixing any ‚Äúbroken‚Äù code in the document, or adding new code in the code blocks that look like this:\n\n\n1 + 1 # example code\n\n[1] 2\n\n\n\n\n3.2 Running code and writing responses to the exercise prompts\n\nTry executing the code in each block as you work through the practice exercise. The results from the code appear right below the block. If you get an error or a warning, try to use that information as a clue to figure out what you need to change.\nWhen you are done with the exercise, there should be no more blank spaces like this one: ____. The bonus exercises are optional but otherwise any code block that started empty should now have code inside.\nSome questions require short written responses which should be completed as Markdown formatted text above or below the related code block‚Äînot as a comment inside the code block!\nIf all of your code blocks run smoothly, you should be able to ‚Äúrender‚Äù the .qmd document to create a new HTML document. When I review completed assignments, trying to render the document will always be my first step.\nWhen you done with the exercise, please change the front matter for the document from status: Available to status: Complete.\nRemember, you don‚Äôt need to get everything right and it is OK if your document won‚Äôt render. Just try your best with each part of the exercise.\n\n\n\n\n\n\n\nTips for completing exercises\n\n\n\n\n\n\nComplete this exercise from top to bottom. Blocks of code at the end of the document may depend on blocks from the beginning or middle so avoid skipping around.\nIf you get an error message, read it. If it doesn‚Äôt make sense, try looking it up. R for Data Science reminds readers that Google is your friend.\nRead the documentation!",
    "crumbs": [
      "Course information",
      "Exercise How-to"
    ]
  },
  {
    "objectID": "course-exercises.html#committing-your-completed-exercise-to-the-repository",
    "href": "course-exercises.html#committing-your-completed-exercise-to-the-repository",
    "title": "Completing and submitting practice exercises",
    "section": "4 Committing your completed exercise to the repository",
    "text": "4 Committing your completed exercise to the repository\nYou may have saved your updated document to your computer but the last step is to save or ‚Äúcommit‚Äù those changes to the exercise repository.\n‚ÄúCommitting‚Äù your changes and syncing the changes with the remote version of your repository on GitHub allows me to see your completed exercise and share feedback on your work.\n\n4.1 Commit changes with GitHub Desktop\nThe first and easiest way to commit changes is using GitHub Desktop.\n\nReview the GitHub documentation on Committing and reviewing changes to your project in GitHub Desktop for more detailed instructions.\n\n\n\n4.2 Commit changes with RStudio\nThe second way to commit changes is using the Git tab within RStudio. The interface for Git within RStudio is a little less friendly but is a convenient option since you don‚Äôt need to leave RStudio to commit your changes.\nHere is the step-by-step process (adapted from Connect RStudio to Git and GitHub in Happy Git and GitHub for the useR):\n\nClick the ‚ÄúGit‚Äù tab in upper right pane.\nCheck ‚ÄúStaged‚Äù box for exercise_01.qmd.\nIf you‚Äôre not already in the Git pop-up, click ‚ÄúCommit‚Äù.\nType a message in ‚ÄúCommit message‚Äù, such as ‚ÄúCommit from RStudio‚Äù.\nClick ‚ÄúCommit‚Äù.\nFinally, click the green ‚ÄúPush‚Äù button to send your local changes to GitHub.\n\n\n\n\n\n\n\nWhen should you commit your changes?\n\n\n\n\n\nYou don‚Äôt need to wait until you are 100% finished with the exercise to commit your changes. You may want to commit the changes every time you work on the exercise. Please make sure to change the ‚Äústatus‚Äù for the exercise from ‚ÄúAvailable‚Äù to ‚ÄúComplete‚Äù when your exercise is complete and ready for evaluation. I will typically evaluate the last week‚Äôs exercises on the Tuesday before each class session. Committing changes as you go can also avoid conflicts if I need to make corrections or additions to some part of the assignment after you started working on it.",
    "crumbs": [
      "Course information",
      "Exercise How-to"
    ]
  },
  {
    "objectID": "weeks/week_01.html",
    "href": "weeks/week_01.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to GES668!\nIntroduction to R for spatial data\nIntroduction to reproducible data analysis\n\n\n\n\n\n\n\nKey Objectives\n\n\n\n\nExplore key functions from the {sf} package and {tidyverse} family of packages\nCreate a self-contained project in RStudio\nPractice creating files with a consistent naming convention\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow does R support reproducible spatial data analysis?\nWhy use R for working with spatial data?",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#overview",
    "href": "weeks/week_01.html#overview",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to GES668!\nIntroduction to R for spatial data\nIntroduction to reproducible data analysis\n\n\n\n\n\n\n\nKey Objectives\n\n\n\n\nExplore key functions from the {sf} package and {tidyverse} family of packages\nCreate a self-contained project in RStudio\nPractice creating files with a consistent naming convention\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow does R support reproducible spatial data analysis?\nWhy use R for working with spatial data?",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#prepare",
    "href": "weeks/week_01.html#prepare",
    "title": "Week 1",
    "section": "Prepare",
    "text": "Prepare\n\nGetting ready for the first class\n\nInstall R and RStudio on your computer. Review these instructions if needed.\nIf you don‚Äôt already have a GitHub account, register for a GitHub user account. Review these instructions if needed.\nInstall the GitHub Desktop application (the installer will also install Git on your computer).\nUse this Google form to share your GitHub username (and a little background)\nJoin the class Discord.\nBring a computer to class (if you can).\nüìñ Read the syllabus\n\n\n\nRequired readings\n\nCh. 1 Introduction in Robin Lovelace, Jakub Nowosad, and Jannes Muenchow Geocomputation with R, 2nd (WIP)., 2022, https://geocompr.robinlovelace.net/.\nCh. 2 Geographic data in R in Lovelace, Nowosad, and Muenchow Geocomputation with R.\nChris Brunsdon and Alexis Comber ‚ÄúOpening Practice: Supporting Reproducibility and Critical Spatial Data Science,‚Äù Journal of Geographical Systems 23, no. 4 (October 1, 2021): 477‚Äì496, doi:10.1007/s10109-020-00334-2.\nJennifer Bryan ‚ÄúHow to Name Files,‚Äù May 14, 2015, https://speakerdeck.com/jennybc/how-to-name-files. (or more recent How to name files talk for NormConf 2022)\n\n\n\nOptional readings\n\nIntroduction to Geospatial Concepts (Data Carpentry)\nIntroduction to R for Geospatial Data (Data Carpentry)\nCh. 3 Geometries in Edzer Pebesma and Roger Bivand Spatial Data Science (CRC Press, 2023), https://r-spatial.org/book/.\nGreg Wilson et al. ‚ÄúGood Enough Practices in Scientific Computing,‚Äù PLOS Computational Biology 13, no. 6 (June 22, 2017): e1005510, doi:10.1371/journal.pcbi.1005510.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#participate",
    "href": "weeks/week_01.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Welcome to GES 668\nüñ•Ô∏è Introduction to Spatial Data with R",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#practice",
    "href": "weeks/week_01.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\nüõ†Ô∏èÔ∏è Exercise 01",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_01.html#notes",
    "href": "weeks/week_01.html#notes",
    "title": "Week 1",
    "section": "Notes",
    "text": "Notes\n\nWhat skills did we introduce this week\n\nInstalling packages with install.packages()\nLoading packages with library()\nUsing the ? operator to look up function documentation\nUsing sf::st_read() to read a sf object from a file path\nUsing an assignment operator (&lt;- or =) to save function output in a new object\nUsing View() and mapview::mapview() to interactively explore spatial data\n\n\n\nWhat concepts did we discuss this week\n\nHow the RStudio IDE interface is organized around a console, help pane, source pane, and environment pane (check out the RStudio IDE Cheatsheet for a quick reference)\nHow functions start with inputs (also known as arguments or parameters), produce side effects (e.g.¬†informational messages), and return outputs (e.g.¬†a character string or a sf object)\nHow sf objects are structured around attributes and geometries\nHow R code is executed within a development environment where packages or objects are loaded\nHow and when to restart an R session to reset the environment",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week_02.html",
    "href": "weeks/week_02.html",
    "title": "Week 2",
    "section": "",
    "text": "Week 2 Updates\nYour week 1 questions\nIntroduction to visualizing spatial data in R\n\n\n\n\n\n\n\nKey Objectives\n\n\n\n\nExplore the ‚Äúgrammar of graphics‚Äù as a way of structuring plots and maps\nExplore the concept of ‚Äútidy‚Äù data\nPractice creating plots and maps with the {ggplot2} package\nLearn how the pipe function (%&gt;% or |&gt;) works and when it may be useful",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#overview",
    "href": "weeks/week_02.html#overview",
    "title": "Week 2",
    "section": "",
    "text": "Week 2 Updates\nYour week 1 questions\nIntroduction to visualizing spatial data in R\n\n\n\n\n\n\n\nKey Objectives\n\n\n\n\nExplore the ‚Äúgrammar of graphics‚Äù as a way of structuring plots and maps\nExplore the concept of ‚Äútidy‚Äù data\nPractice creating plots and maps with the {ggplot2} package\nLearn how the pipe function (%&gt;% or |&gt;) works and when it may be useful",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#prepare",
    "href": "weeks/week_02.html#prepare",
    "title": "Week 2",
    "section": "Prepare",
    "text": "Prepare\n\nRequired readings\n\nCh. 6 Maps in Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen Ggplot2: Elegant Graphics for Data Analysis, 3rd (WIP)., Use R! (Springer, 2023), https://ggplot2-book.org/index.html.\nCh. 3 Workflow: basics in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\nCh. 1 Local Origins in Yanni Alexander Loukissas All Data Are Local: Thinking Critically in a Data-Driven Society, 2019, doi:10.7551/mitpress/11543.001.0001.\n\n\n\nOptional readings\n\nCatherine D‚ÄôIgnazio and Lauren Klein ‚ÄúWho Collects the Data? A Tale of Three Maps,‚Äù MIT Case Studies in Social and Ethical Responsibilities of Computing (February 5, 2021), doi:10.21428/2c646de5.fc6a97cc.\nCh. 2 Data visualization in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#participate",
    "href": "weeks/week_02.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Visualizing spatial data with {ggplot2}",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#practice",
    "href": "weeks/week_02.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\nüõ†Ô∏èÔ∏è Exercise 02",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_02.html#notes",
    "href": "weeks/week_02.html#notes",
    "title": "Week 2",
    "section": "Notes",
    "text": "Notes\nWe didn‚Äôt quite finish the in-class lecture and practice this week so week 3 may include some review.\n\nWhat skills did we practice\n\nBuilding plots using ggplot() and geom_() functions\nCreating aesthetic mappings using the aes() function\n\n\n\nWhat concepts did we discuss\n\nHow the ‚Äúgrammar of graphics‚Äù inform the {ggplot} interface",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week_07.html",
    "href": "weeks/week_07.html",
    "title": "Week 7",
    "section": "",
    "text": "Ch. 26 Functions in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\nCh. 11 Scripts, algorithms and functions in Robin Lovelace, Jakub Nowosad, and Jannes Muenchow Geocomputation with R, 2nd (WIP)., 2022, https://geocompr.robinlovelace.net/.\nCh. 29 Quarto in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\n\n\n\n\n\nSam Leon ‚ÄúAccounting for Methods: Spreadsheets, Scripts and Programming Notebooks,‚Äù in The Data Journalism Handbook: Towards A Critical Data Practice, ed. Liliana Bounegru and Jonathan Gray, 2nd ed. (Amsterdam University Press, 2021), 128‚Äì137, doi:10.2307/j.ctv1qr6smr.\nWelcome to Quarto Workshop! (Posit PBC, 2022), https://www.youtube.com/watch?v=yvi5uXQMvu4.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week_07.html#prepare",
    "href": "weeks/week_07.html#prepare",
    "title": "Week 7",
    "section": "",
    "text": "Ch. 26 Functions in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\nCh. 11 Scripts, algorithms and functions in Robin Lovelace, Jakub Nowosad, and Jannes Muenchow Geocomputation with R, 2nd (WIP)., 2022, https://geocompr.robinlovelace.net/.\nCh. 29 Quarto in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.\n\n\n\n\n\nSam Leon ‚ÄúAccounting for Methods: Spreadsheets, Scripts and Programming Notebooks,‚Äù in The Data Journalism Handbook: Towards A Critical Data Practice, ed. Liliana Bounegru and Jonathan Gray, 2nd ed. (Amsterdam University Press, 2021), 128‚Äì137, doi:10.2307/j.ctv1qr6smr.\nWelcome to Quarto Workshop! (Posit PBC, 2022), https://www.youtube.com/watch?v=yvi5uXQMvu4.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week_07.html#participate",
    "href": "weeks/week_07.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Working with scripts, functions, and Quarto\nCode sample from week 8",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week_07.html#practice",
    "href": "weeks/week_07.html#practice",
    "title": "Week 7",
    "section": "Practice",
    "text": "Practice\nüõ†Ô∏èÔ∏è Exercise 07",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week_12.html",
    "href": "weeks/week_12.html",
    "title": "Week 12",
    "section": "",
    "text": "Introduction to metadata and spatial metadata standards\nWriting metadata, READMEs, and documentation for projects, workflows, and data\nWorking with data dictionaries and the {labelled} package",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week_12.html#overview",
    "href": "weeks/week_12.html#overview",
    "title": "Week 12",
    "section": "",
    "text": "Introduction to metadata and spatial metadata standards\nWriting metadata, READMEs, and documentation for projects, workflows, and data\nWorking with data dictionaries and the {labelled} package",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week_12.html#prepare",
    "href": "weeks/week_12.html#prepare",
    "title": "Week 12",
    "section": "Prepare",
    "text": "Prepare\n\nRequired readings\n\nCh. 7 Show Your Work in Catherine D‚ÄôIgnazio and Lauren F. Klein Data Feminism (The MIT Press, 2020), https://data-feminism.mitpress.mit.edu/.\nShannon Pileggi ‚ÄúThe Case for Variable Labels in R‚Äù (Piping Hot Data, September 13, 2022), https://www.pipinghotdata.com/posts/2022-09-13-the-case-for-variable-labels-in-r/.\n‚ÄúData-Primers‚Äù (DataCurationNetwork, 2019), https://github.com/DataCurationNetwork/data-primers/tree/c6ec438e76fea49eaaf2806bc79ec2c8c12de7f3.\n\n\n\nOptional readngs\n\n‚ÄúGuide to Writing \"Readme\" Style Metadata‚Äù (Research Data Management Service Group), accessed August 27, 2022, https://data.research.cornell.edu/content/readme.\nEmily Riederer ‚ÄúColumn Names as Contracts‚Äù (Emily Riederer, September 6, 2020), https://emilyriederer.netlify.app/post/column-name-contracts/.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week_12.html#participate",
    "href": "weeks/week_12.html#participate",
    "title": "Week 12",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Creating and managing spatial metadata",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week_10.html",
    "href": "weeks/week_10.html",
    "title": "Week 10",
    "section": "",
    "text": "Ch. 5 Census Geographic Data and Applications in R in Kyle E. Walker Analyzing US Census Data: Methods, Maps, and Models in R (CRC Press, 2022), https://walker-data.com/census-r/census-geographic-data-and-applications-in-r.html.\nDan Bouk, Kevin Ackermann, and danah boyd A Primer on Powerful Numbers: Selected Readings in the Social Study of Public Data and Official Numbers (Data & Society, March 23, 2022), https://datasociety.net/library/a-primer-on-powerful-numbers-selected-readings-in-the-social-study-of-public-data-and-official-numbers/.\nSpatial Analysis of US Census Data in R (Social Science Data Analysis Network, 2021), https://www.youtube.com/watch?v=GqC1HjAKui4.\n\n\n\n\n\nDan Bouk ‚ÄúHow Does Queerness Fit Into the US Census?‚Äù Wired, August 23, 2022, https://www.wired.com/story/us-census-queerness-data/.\nAccessing and Analyzing U.S. Census Data in R (Social Science Data Analysis Network, 2021), https://www.youtube.com/watch?v=PnFJfuJ83NI.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week_10.html#prepare",
    "href": "weeks/week_10.html#prepare",
    "title": "Week 10",
    "section": "",
    "text": "Ch. 5 Census Geographic Data and Applications in R in Kyle E. Walker Analyzing US Census Data: Methods, Maps, and Models in R (CRC Press, 2022), https://walker-data.com/census-r/census-geographic-data-and-applications-in-r.html.\nDan Bouk, Kevin Ackermann, and danah boyd A Primer on Powerful Numbers: Selected Readings in the Social Study of Public Data and Official Numbers (Data & Society, March 23, 2022), https://datasociety.net/library/a-primer-on-powerful-numbers-selected-readings-in-the-social-study-of-public-data-and-official-numbers/.\nSpatial Analysis of US Census Data in R (Social Science Data Analysis Network, 2021), https://www.youtube.com/watch?v=GqC1HjAKui4.\n\n\n\n\n\nDan Bouk ‚ÄúHow Does Queerness Fit Into the US Census?‚Äù Wired, August 23, 2022, https://www.wired.com/story/us-census-queerness-data/.\nAccessing and Analyzing U.S. Census Data in R (Social Science Data Analysis Network, 2021), https://www.youtube.com/watch?v=PnFJfuJ83NI.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week_10.html#participate",
    "href": "weeks/week_10.html#participate",
    "title": "Week 10",
    "section": "Participate",
    "text": "Participate\nDuring class, we will review this sample code as an exercise.\n\n\nPractice exercise\n# Load libraries\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(osmdata)\nlibrary(tidyverse)\n\n# Set option for tigris\noptions(tigris_use_cache = TRUE)\n\n# Get American Community Survey tract level data on population by race/ethnicity\n# Make sure to include a summary variable with total population\nbaltcity_pop &lt;- get_acs(\n  geography = ____,\n  variables = ____,\n  summary_var = ____,\n  cache_table = TRUE,\n  year = 2021,\n  state = \"MD\",\n  county = \"Baltimore city\",\n  geometry = TRUE,\n  survey = \"acs5\"\n)\n\n# If you are unsure what variables to use, use the `load_variables()` function\n# to get a data frame with all of the variables\nacs_vars &lt;- load_variables(year = ____, dataset = ____)\n\n# Use `tidycensus::as_dot_density()` to convert the geometry of your data into a\n# dot density format and scale the values based on the values_per_dot parameter\nbaltcity_pop_dots &lt;- as_dot_density(\n  input_data = ____,\n  value = ____,\n  values_per_dot = 100,\n  group = \"variable\"\n)\n\n# Use tigris to get a basemap layer with the tract geometry\nbaltcity_tracts &lt;- tracts(\n  state = ____,\n  county = ____\n)\n\n# Use geom_sf to make a map using the `baltimore_dots` data that is color-coded\n# by race/ethnicity\nggplot() +\n  geom_sf(data = ____) +\n  geom_sf(data = ____, aes(color = ____)) +\n  theme_void()\n\n# Now try to improve the map:\n#\n# - Change the size and transparency of the dots to address over-plotting\n# - Change the color scale to a color-blind friendly palette (I recommend `scale_color_brewer()`)\n# - Change the values of the attribute mapped to color to reflect the categories used by the U.S. Census Bureau\n\nggplot() +\n  geom_sf(data = ____) +\n  geom_sf(data = ____, aes(color = ____)) +\n  theme_void()\n\n\nSolutions for this sample code are now available here.\n\n\nPractice solutions\n# Load libraries\n\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(osmdata)\nlibrary(tidyverse)\n\n# Set option for tigris\n\noptions(tigris_use_cache = TRUE)\n\n# Get American Community Survey data on population by race/ethnicity\n\nbaltcity_pop &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(\"B03002_003\", \"B03002_004\", \"B03002_012\"),\n  summary_var = \"B03002_001\",\n  cache_table = TRUE,\n  year = 2021,\n  state = \"MD\",\n  county = \"Baltimore city\",\n  geometry = TRUE,\n  survey = \"acs5\"\n)\n\n# If you are unsure what variables to use, use the `load_variables()` function\n# to get a data frame with all of the variables\n\nacs_vars &lt;- load_variables(year = 2021, dataset = \"acs5\")\n\n# You can visualize the estimate using fill and split variables into different\n# panels of the plot\n\nggplot() +\n  geom_sf(data = baltcity_pop, aes(fill = estimate)) +\n  facet_wrap(~variable) +\n  theme_void()\n\n\n# Use `tidycensus::as_dot_density()` to convert the geometry of your data into a\n# dot density format and scale the values based on the values_per_dot parameter\n\nbaltcity_pop_dots &lt;- as_dot_density(\n  input_data = baltcity_pop,\n  value = \"estimate\",\n  values_per_dot = 100,\n  group = \"variable\"\n)\n\nbaltcity_tracts &lt;- tracts(\n  state = \"MD\",\n  county = \"Baltimore city\"\n)\n\n# Use geom_sf to make a map using the `baltimore_dots` data that is color-coded\n# by race/ethnicity\n\nggplot() +\n  geom_sf(data = baltcity_tracts) +\n  geom_sf(\n    data = baltcity_pop_dots,\n    aes(color = variable)\n  ) +\n  theme_void()\n\n# Now try to improve the map:\n#\n# - Change the size and transparency of the dots to address over-plotting\n# - Change the color scale to a color-blind friendly palette (I recommend `scale_color_brewer()`)\n# - Change the values of the attribute mapped to color to reflect the categories used by the U.S. Census Bureau\n\nggplot() +\n  geom_sf(data = baltcity_tracts, fill = NA) +\n  geom_sf(\n    data = baltcity_pop_dots,\n    aes(color = variable),\n    alpha = 0.5,\n    size = 0.35\n  ) +\n  scale_color_brewer(palette = \"Accent\", direction = -1) +\n  theme_void() +\n  theme(\n    legend.position = \"bottom\"\n  ) +\n  labs(\n    color = \"Race/ethnicity\"\n  )",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week_05.html",
    "href": "weeks/week_05.html",
    "title": "Week 5",
    "section": "",
    "text": "Weekly 5 Updates and Questions\nComplete discussion on working with attribute data (continued from week 4)\nIntroduction to spatial, geometry, and geometric operations in {sf}\n\n\n\n\n\n\n\nKey Objectives\n\n\n\n\nUsing geometry operations for buffering or simplifying features\nUsing geometric operations like union, intersection, and difference\nUsing related functions including spatial joins and filters",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#overview",
    "href": "weeks/week_05.html#overview",
    "title": "Week 5",
    "section": "",
    "text": "Weekly 5 Updates and Questions\nComplete discussion on working with attribute data (continued from week 4)\nIntroduction to spatial, geometry, and geometric operations in {sf}\n\n\n\n\n\n\n\nKey Objectives\n\n\n\n\nUsing geometry operations for buffering or simplifying features\nUsing geometric operations like union, intersection, and difference\nUsing related functions including spatial joins and filters",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#prepare",
    "href": "weeks/week_05.html#prepare",
    "title": "Week 5",
    "section": "Prepare",
    "text": "Prepare\n\nRequired readings\n\nCh. 4 Spatial data operations in Robin Lovelace, Jakub Nowosad, and Jannes Muenchow Geocomputation with R, 2nd (WIP)., 2022, https://geocompr.robinlovelace.net/.\nCh. 5 Geometry operations in Lovelace, Nowosad, and Muenchow Geocomputation with R.\n\n\n\nOptional readings\n\nEdzer Pebesma ‚Äú3. Manipulating Simple Feature Geometries‚Äù (sf, November 28, 2016), https://r-spatial.github.io/sf/articles/sf3.html.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#participate",
    "href": "weeks/week_05.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Getting started with spatial data using sf and the tidyverse",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_05.html#practice",
    "href": "weeks/week_05.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\nüõ†Ô∏èÔ∏è Exercise 05",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week_08.html",
    "href": "weeks/week_08.html",
    "title": "Week 8",
    "section": "",
    "text": "Ch. 5 Market, Place, Interface in Yanni Alexander Loukissas All Data Are Local: Thinking Critically in a Data-Driven Society, 2019, doi:10.7551/mitpress/11543.001.0001.\nCh. 11 Exploratory Data Analysis in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\nNatalia Mazotte ‚ÄúWorking Openly in Data Journalism,‚Äù in The Data Journalism Handbook: Towards A Critical Data Practice, ed. Liliana Bounegru and Jonathan Gray, 2nd ed. (Amsterdam University Press, 2021), 138‚Äì142, doi:10.2307/j.ctv1qr6smr.\n\n\n\n\n\nCh. 12 Communication in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week_08.html#prepare",
    "href": "weeks/week_08.html#prepare",
    "title": "Week 8",
    "section": "",
    "text": "Ch. 5 Market, Place, Interface in Yanni Alexander Loukissas All Data Are Local: Thinking Critically in a Data-Driven Society, 2019, doi:10.7551/mitpress/11543.001.0001.\nCh. 11 Exploratory Data Analysis in Hadley Wickham, Garrett Grolemund, and Mine √áetinkaya-Rundel R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition (WIP). (Sebastopol, CA: O‚ÄôReilly Media, 2023), https://r4ds.hadley.nz/.\nNatalia Mazotte ‚ÄúWorking Openly in Data Journalism,‚Äù in The Data Journalism Handbook: Towards A Critical Data Practice, ed. Liliana Bounegru and Jonathan Gray, 2nd ed. (Amsterdam University Press, 2021), 138‚Äì142, doi:10.2307/j.ctv1qr6smr.\n\n\n\n\n\nCh. 12 Communication in Wickham, Grolemund, and √áetinkaya-Rundel R for Data Science.",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Week 8"
    ]
  },
  {
    "objectID": "resources/data-sources.html",
    "href": "resources/data-sources.html",
    "title": "Data sources",
    "section": "",
    "text": "Spatial data is available in a wide range of formats at the local, national, and international levels. Data is often published through larger data portals where you can find links to access data through a web service or options to download part of all of the data.",
    "crumbs": [
      "Resources üìãÔ∏è",
      "Data Sources"
    ]
  },
  {
    "objectID": "resources/data-sources.html#local-data-sources-for-baltimore-and-maryland",
    "href": "resources/data-sources.html#local-data-sources-for-baltimore-and-maryland",
    "title": "Data sources",
    "section": "Local data sources for Baltimore and Maryland ü¶Ä",
    "text": "Local data sources for Baltimore and Maryland ü¶Ä\n\nBaltimore City Open Data Hub\nBaltimore County GIS Open Data Portal\nBMC Regional GIS Data Center - Baltimore Metropolitan Council\nChesapeake Bay Open Data Portal\nMaryland‚Äôs GIS Data Catalog\nMaryland Open Data\nVital Signs Open Data Portal\nMaryland Food Systems Open Data Portal\nMaryland ArcGIS REST API Services Index",
    "crumbs": [
      "Resources üìãÔ∏è",
      "Data Sources"
    ]
  },
  {
    "objectID": "resources/data-sources.html#national-data-sources-for-the-u.s.",
    "href": "resources/data-sources.html#national-data-sources-for-the-u.s.",
    "title": "Data sources",
    "section": "National data sources for the U.S. üá∫üá∏",
    "text": "National data sources for the U.S. üá∫üá∏\n\nData.gov (Aggregates local, state, and federal open data catalogs)\nU.S. Department of Housing and Urban Development Geospatial Data Storefront\nGeospatial at BTS (Bureau of Transportation Statistics), U.S. Department of Transportation\nBTS Data Inventory (Bureau of Transportation Statistics), U.S. Department of Transportation\nEDGE Geodata (Education Demographic and Geographic Estimates), U.S. Department of Education, National Center for Education Statistics\nU.S. Geological Survey Science Data Catalog\nGeoPlatform.gov\nNational Ecological Observatory Network (NEON) Data Portal\nOpen Data Network (Socrata/Tyler Technologies)\nUrban Institute Data Catalog",
    "crumbs": [
      "Resources üìãÔ∏è",
      "Data Sources"
    ]
  },
  {
    "objectID": "resources/data-sources.html#global-data-sources",
    "href": "resources/data-sources.html#global-data-sources",
    "title": "Data sources",
    "section": "Global data sources üåè",
    "text": "Global data sources üåè\n\nNatural Earth\nOpenStreetMap (see the OSM Wiki for more on how data is organized on OSM)\nArcGIS Living Atlas of the World\nNASA Open Data Portal\nNOAA Data Discovery Portal\nWorld Bank Open Data\nHumanitarian Data Exchange\nData Portals (Open Knowledge Foundation)\nRegistry of Open Data on AWS",
    "crumbs": [
      "Resources üìãÔ∏è",
      "Data Sources"
    ]
  },
  {
    "objectID": "resources/data-sources.html#r-packages-for-data-access",
    "href": "resources/data-sources.html#r-packages-for-data-access",
    "title": "Data sources",
    "section": "R packages for data access",
    "text": "R packages for data access\n\nGeneral data access packages\nGeneral data access packages include:\n\n{arcgislayers} üì¶ to access ArcGIS FeatureServer data\n{RSocrata} to access Socrata data portals\n{ckanr} to access CKAN data portals\n\n\n\nDomain-specific data access packages\nThere are many different data access R packages for interacting with APIs and web services relevant to specific domains of research or practice.\nA few broadly useful packages include:\n\n{tigris}: Download and use Census TIGER/Line shapefiles.\n{tidycensus}: Get US Census boundary and attribute data.\n{rnaturalearth}: Get Natural Earth data.\n{osmdata}: Get OpenStreetMap data.\n{geodata}: Get climate, elevation, soil, crop, species occurrence, and administrative boundary data.\n{dataRetrieval}: Get USGS or EPA water quality sample data, streamflow data, and metadata directly from web services.\n\nExplore the Data Access category on ROpenSci or search for packages on R-universe or CRAN to find the right package for your project or exercise.\n\n\nLocal data access packages\nI also maintain a few R packages for open data access in Baltimore and Maryland that students working on local projects may find helpful:\n\n{mapbaltimore}\n{bcpss}\n{mapmaryland}\n{marylandedu}",
    "crumbs": [
      "Resources üìãÔ∏è",
      "Data Sources"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GES 668: Building Spatial Datasets (Fall 2023)",
    "section": "",
    "text": "Warning: package 'gt' was built under R version 4.3.1\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nSlides\nExercise\n\n\n\n\n1\nWed, Aug 30\nGetting started with spatial data using sf and the tidyverse\nüìñ\nüìù\n\n\n2\nWed, Sep 6\nVisualizing spatial data with ggplot2\nüìñ\nüìù\n\n\n3\nWed, Sep 13\nTransforming data with dplyr\nüìñ\nüìù\n\n\n4\nWed, Sep 20\nTransforming spatial data attributes\nüìñ\nüìù\n\n\n5\nWed, Sep 27\nApplying spatial transformations and geometric operations using sf\nüìñ\nüìù\n\n\n6\nWed, Oct 4\nTidying and joining spatial data\nüìñ\nüìù\n\n\n7\nWed, Oct 11\nBuilding functions in R and literate programming with Quarto\nüìñ\nüìù\n\n\n8\nWed, Oct 18\nDeveloping an exploratory data analysis with sf and the tidyverse\nüìñ\n‚Äî\n\n\n9\nWed, Oct 25\nEditing OpenStreetMap and exploring OpenStreetMap data with the osmdata package\nüìñ\n‚Äî\n\n\n10\nWed, Nov 1\nExploring American Community Survey data with the tidycensus package\n‚Äî\n‚Äî\n\n\n11\nWed, Nov 8\nReading and writing spatial data files and services\nüìñ\n‚Äî\n\n\n12\nWed, Nov 15\nCreating and managing spatial metadata\nüìñ\n‚Äî\n\n\n13\nWed, Nov 22\nProject check-in meetings (no class)\n‚Äî\n‚Äî\n\n\n14\nWed, Nov 29\nReview and work session\n‚Äî\n‚Äî\n\n\n15\nWed, Dec 6\nFinal project presentations\n‚Äî\n‚Äî\n\n\n‚Äî\nThu, Dec 14\nDue: Final project repository\n‚Äî\n‚Äî"
  },
  {
    "objectID": "slides/functions.html#functions",
    "href": "slides/functions.html#functions",
    "title": "Session 7: Working with scripts, functions, and Quarto",
    "section": "\n1 Functions",
    "text": "1 Functions"
  },
  {
    "objectID": "slides/spatial-data.html#overview",
    "href": "slides/spatial-data.html#overview",
    "title": "Session 1: Getting started with spatial data using sf and the tidyverse",
    "section": "1 Overview",
    "text": "1 Overview\n\nWhat is R?\nHow does R work with spatial data?\nTake a look at {sf} and tidyverse in action"
  },
  {
    "objectID": "slides/spatial-data.html#what-is-r",
    "href": "slides/spatial-data.html#what-is-r",
    "title": "Session 1: Getting started with spatial data using sf and the tidyverse",
    "section": "2 What is R?",
    "text": "2 What is R?\n\n\nR is best known for as a statistical programming language often used in data science and research.\nLike Python or C++, R is an object-oriented, functional programming language where the base set of features can be extended through open-source packages or libraries.\n\n\n\n\n\n\nA package is a bundle of code that a generous person has written, tested, and then given away. Most of the time packages are designed to solve a specific problem, so they to pull together functions related to a particular data science problem (e.g., data wrangling, visualisation, inference).\n\nFrom BasicBasics 2 (R-Ladies Sydney)"
  },
  {
    "objectID": "slides/spatial-data.html#how-does-r-work-with-spatial-data",
    "href": "slides/spatial-data.html#how-does-r-work-with-spatial-data",
    "title": "Session 1: Getting started with spatial data using sf and the tidyverse",
    "section": "3 How does R work with spatial data?",
    "text": "3 How does R work with spatial data?\n\n\nThe {sf} package, first published in 2016, is the most popular R package for spatial data.\n\nExtension packages include:\n\nlwgeom for selected liblwgeom/PostGIS functions\nstars for raster data, and raster or vector data cubes (spatial time series)\nsfnetworks for geospatial network data"
  },
  {
    "objectID": "slides/spatial-data.html#take-a-look-at-sf-and-the-tidyverse-in-action",
    "href": "slides/spatial-data.html#take-a-look-at-sf-and-the-tidyverse-in-action",
    "title": "Session 1: Getting started with spatial data using sf and the tidyverse",
    "section": "4 Take a look at {sf} and the tidyverse in action",
    "text": "4 Take a look at {sf} and the tidyverse in action\nPackages are simple to install:\n\ninstall.packages(c(\"sf\", \"ggplot2\", \"dplyr\"))\n\nAnd to load:\n\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "slides/spatial-data.html#related-resources",
    "href": "slides/spatial-data.html#related-resources",
    "title": "Session 1: Getting started with spatial data using sf and the tidyverse",
    "section": "5 Related resources",
    "text": "5 Related resources\n\nWeek 1 Required readings and Optional readings\nExercise 1"
  },
  {
    "objectID": "slides/coding-basics.html#week-1",
    "href": "slides/coding-basics.html#week-1",
    "title": "Coding basics",
    "section": "1 Week 1",
    "text": "1 Week 1"
  },
  {
    "objectID": "slides/spatial-data-io.html#spatial-data-is-everywhere",
    "href": "slides/spatial-data-io.html#spatial-data-is-everywhere",
    "title": "Reading and writing spatial data",
    "section": "1 Spatial data is everywhere",
    "text": "1 Spatial data is everywhere\n\nShapefiles, GeoJSON files, and other spatial data files\nSpatial data editing and hosting services, e.g.¬†ArcGIS Online or Felt)\nOpen data portals serving spatial and non-spatial data, e.g.¬†data.gov"
  },
  {
    "objectID": "slides/spatial-data-io.html#spatial-data-is-everywhere-1",
    "href": "slides/spatial-data-io.html#spatial-data-is-everywhere-1",
    "title": "Reading and writing spatial data",
    "section": "2 Spatial data is everywhere",
    "text": "2 Spatial data is everywhere\n\nGoogle Maps, Apple Maps, Waze, and navigation apps (on your phone or in your vehicle)\nBiking and running apps (Strava publishes a global user activity heatmap)\nWeb browsers on your phone and desktop application"
  },
  {
    "objectID": "slides/spatial-data-io.html#spatial-data-is-everywhere-2",
    "href": "slides/spatial-data-io.html#spatial-data-is-everywhere-2",
    "title": "Reading and writing spatial data",
    "section": "3 Spatial data is everywhere",
    "text": "3 Spatial data is everywhere\n\nPhone camera photos (stored in the EXIF metadata)\nCalendars (iCal), contacts (vCard), and emails (using IP address locations)"
  },
  {
    "objectID": "slides/spatial-data-io.html#creating-spatial-data-is-easy",
    "href": "slides/spatial-data-io.html#creating-spatial-data-is-easy",
    "title": "Reading and writing spatial data",
    "section": "4 Creating spatial data is ‚Äúeasy‚Äù",
    "text": "4 Creating spatial data is ‚Äúeasy‚Äù\n\nGIS Desktop applications, e.g.¬†QGIS\nWeb mapping applications (e.g.¬†geojson.io, Felt)\nSpreadsheet applications (e.g.¬†Google Sheets)\nDatabase builders (e.g.¬†Airtable or Microsoft Lists)"
  },
  {
    "objectID": "slides/spatial-data-io.html#what-can-we-do-with-it-all",
    "href": "slides/spatial-data-io.html#what-can-we-do-with-it-all",
    "title": "Reading and writing spatial data",
    "section": "5 What can we do with it all?",
    "text": "5 What can we do with it all?\n\nRead and write spatial data files\nRead and write related data files\nRead from and write to web services"
  },
  {
    "objectID": "slides/spatial-data-io.html#common-spatial-file-formats",
    "href": "slides/spatial-data-io.html#common-spatial-file-formats",
    "title": "Reading and writing spatial data",
    "section": "6 Common spatial file formats",
    "text": "6 Common spatial file formats\n\nShapefile (.shp)\nGeoJSON (.json, .geojson)\nGeoPackage (.gpkg)\nKML - Keyhole Markup Language (.kml)\nEsri File Geodatabase (.gdb)\n\n\n\nVector spatial: Shapefile, GeoJSON, KML\nRaster spatial: GeoTIFF,\nTabular data with geometry: CSV, Microsoft Excel, delimited text with coordinates or WKT (well known text)"
  },
  {
    "objectID": "slides/spatial-data-io.html#read-spatial-data-files-with-r",
    "href": "slides/spatial-data-io.html#read-spatial-data-files-with-r",
    "title": "Reading and writing spatial data",
    "section": "7 Read spatial data files with R",
    "text": "7 Read spatial data files with R\nThe dsn or data source name for sf::read_sf() can include:\n\na file name\na URL\na folder\nthe name and access credentials of a database\na character string with the contents of a GeoJSON file"
  },
  {
    "objectID": "slides/spatial-data-io.html#read-spatial-data-files-with-r-1",
    "href": "slides/spatial-data-io.html#read-spatial-data-files-with-r-1",
    "title": "Reading and writing spatial data",
    "section": "8 Read spatial data files with R",
    "text": "8 Read spatial data files with R\nYou can use the query parameter of sf::read_sf() to use a SQL query to select records from a file (or select a specific geographical extent)."
  },
  {
    "objectID": "slides/spatial-data-io.html#many-file-formats-can-include-spatial-data",
    "href": "slides/spatial-data-io.html#many-file-formats-can-include-spatial-data",
    "title": "Reading and writing spatial data",
    "section": "9 Many file formats can include spatial data",
    "text": "9 Many file formats can include spatial data\n\nExcel files (xlsx or xls)\n\nvCard or VCF (Virtual Contact File)\nEXIF metadata in a JPEG, HEIC, PNG, TIFF or other media file"
  },
  {
    "objectID": "slides/spatial-data-io.html#reading-data-into-r",
    "href": "slides/spatial-data-io.html#reading-data-into-r",
    "title": "Reading and writing spatial data",
    "section": "10 Reading data into R",
    "text": "10 Reading data into R\n\nRead data using {sf}\nRead data using a package that returns a sf object\nRead data and use {sf} to convert to a sf object"
  },
  {
    "objectID": "slides/spatial-data-io.html#writing-data-from-r",
    "href": "slides/spatial-data-io.html#writing-data-from-r",
    "title": "Reading and writing spatial data",
    "section": "11 Writing data from R",
    "text": "11 Writing data from R\n\nWrite data to a spatial file using {sf}\nWrite data a a non-spatial file using a different package\n\nWhen you write spatial data to a non-spatial format, you should drop the geometry or convert the geometry to coordinates or well-known text."
  },
  {
    "objectID": "slides/spatial-data-io.html#storing-and-creating-data",
    "href": "slides/spatial-data-io.html#storing-and-creating-data",
    "title": "Reading and writing spatial data",
    "section": "12 Storing and creating data",
    "text": "12 Storing and creating data\n\nTabular: CSV, Microsoft Excel, delimited text\nNested: JSON"
  },
  {
    "objectID": "slides/tidy-data.html#what-is-involved-in-tidying-messy-datasets",
    "href": "slides/tidy-data.html#what-is-involved-in-tidying-messy-datasets",
    "title": "Session 2: Tidying and joining data",
    "section": "\n1 What is involved in tidying messy datasets?",
    "text": "1 What is involved in tidying messy datasets?\n\nColumn headers are values, not variable names\nMultiple variables stored in one column\nVariables are stored in both rows and columns\nMultiple types in one table\nOne type in multiple tables\n\nfrom Tidy data vignette https://tidyr.tidyverse.org/articles/tidy-data.html"
  },
  {
    "objectID": "slides/tidy-data.html#pivoting",
    "href": "slides/tidy-data.html#pivoting",
    "title": "Session 2: Tidying and joining data",
    "section": "\n2 Pivoting",
    "text": "2 Pivoting"
  },
  {
    "objectID": "slides/tidy-data.html#how-would-this-look-if-we-turn-it-into-tidy-data",
    "href": "slides/tidy-data.html#how-would-this-look-if-we-turn-it-into-tidy-data",
    "title": "Session 2: Tidying and joining data",
    "section": "\n3 How would this look if we turn it into tidy data?",
    "text": "3 How would this look if we turn it into tidy data?\n\n\nCity\n2000\n2010\n2020\n\n\n\nBaltimore city, Maryland\n300000\n290000\n285000\n\n\nWashington, DC\n300000\n315000\n330000\n\n\nRichmond, Virginia\n200000\n202000\n210000"
  },
  {
    "objectID": "slides/tidy-data.html#tidying-messy-datasets",
    "href": "slides/tidy-data.html#tidying-messy-datasets",
    "title": "Session 2: Tidying and joining data",
    "section": "\n4 Tidying messy datasets",
    "text": "4 Tidying messy datasets\n\nColumn headers are values, not variable names\nMultiple variables stored in one column\nVariables are stored in both rows and columns\nMultiple types in one table\nOne type in multiple tables"
  },
  {
    "objectID": "slides/tidy-data.html#how-would-this-look-if-we-turn-it-into-tidy-data-1",
    "href": "slides/tidy-data.html#how-would-this-look-if-we-turn-it-into-tidy-data-1",
    "title": "Session 2: Tidying and joining data",
    "section": "\n5 How would this look if we turn it into tidy data?",
    "text": "5 How would this look if we turn it into tidy data?\n\n\nCity name\n2000\n2010\n2020\n\n\n\nBaltimore city, Maryland\n300000\n290000\n285000\n\n\nWashington, DC\n300000\n315000\n330000\n\n\nRichmond, Virginia\n200000\n202000\n210000"
  },
  {
    "objectID": "slides/tidy-data.html#data-organization-in-spreadsheets",
    "href": "slides/tidy-data.html#data-organization-in-spreadsheets",
    "title": "Session 2: Tidying and joining data",
    "section": "\n6 Data organization in spreadsheets",
    "text": "6 Data organization in spreadsheets"
  },
  {
    "objectID": "slides/data-visualization.html#why-do-we-visualize-spatial-data",
    "href": "slides/data-visualization.html#why-do-we-visualize-spatial-data",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n2.1 Why do we visualize spatial data?",
    "text": "2.1 Why do we visualize spatial data?\nWhy do we visualize spatial data?\n\nValidation\nExploration\nCommunication"
  },
  {
    "objectID": "slides/data-visualization.html#anscombes-quartet",
    "href": "slides/data-visualization.html#anscombes-quartet",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n2.2 Anscombe‚Äôs quartet",
    "text": "2.2 Anscombe‚Äôs quartet\nTo illustrate why visualization is essential, let‚Äôs look at the Anscombe‚Äôs Quartet data:\n\n\n\n\nThis data is from the Tmisc package but can be found in many places."
  },
  {
    "objectID": "slides/data-visualization.html#how-do-we-visualize-spatial-data",
    "href": "slides/data-visualization.html#how-do-we-visualize-spatial-data",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n2.3 How do we visualize spatial data?",
    "text": "2.3 How do we visualize spatial data?\n\n\nA map is a special type of data visualization for spatial data but it isn‚Äôt the only one.\nPlots and tables are two other common ways to visualize spatial data.\n\n\n\nKey for interpreting Sanborn fire insurance maps courtesy Library of Congress"
  },
  {
    "objectID": "slides/data-visualization.html#data",
    "href": "slides/data-visualization.html#data",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n3.1 Data",
    "text": "3.1 Data\n\nStructure and representation of data determines what you can and can‚Äôt do with it\nData is expected to be in a ‚Äútidy‚Äù format (also known as long format data)"
  },
  {
    "objectID": "slides/data-visualization.html#mapping",
    "href": "slides/data-visualization.html#mapping",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n3.2 Mapping",
    "text": "3.2 Mapping\n\n\nAllow data to be understood by the graphics system through:\n\nAesthetic mapping: variables -&gt; graphical properties in the geometry\nFacet mapping: variables -&gt; panels in layout"
  },
  {
    "objectID": "slides/data-visualization.html#statistics",
    "href": "slides/data-visualization.html#statistics",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n3.3 Statistics",
    "text": "3.3 Statistics\n\nData may not represent the displayed values\n\nStatistics transform input variables into displayed values, e.g.\n\nCounting the number of observations by category\nCalculating summary statistics for a boxplot\n\n\n\n\nStatistics can be used prior to plotting data or used by a plotting function directly."
  },
  {
    "objectID": "slides/data-visualization.html#scales",
    "href": "slides/data-visualization.html#scales",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n3.4 Scales",
    "text": "3.4 Scales\n\n\nScales translate between value ranges and graphical properties, e.g.\n\nCategories -&gt; Colors\nNumbers -&gt; Position\n\n\nScales use a specific type of interpolation, e.g.¬†discrete, continuous, etc., so not all scales work with all variables.\n\n\nIn the not too common case where data directly represents a graphical property, e.g.¬†a ‚Äúcolor‚Äù column, you can use a special type of scale called an ‚Äúidentity‚Äù scale."
  },
  {
    "objectID": "slides/data-visualization.html#geometries",
    "href": "slides/data-visualization.html#geometries",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n3.5 Geometries",
    "text": "3.5 Geometries\n\nHow translate aesthetics into graphical representations\nBasic geometries (e.g.¬†points, lines, polygons) can be combined into more complex geometries (e.g.¬†box plot, map)\nTypically, the geometries are the same as the ‚Äútype‚Äù of plot"
  },
  {
    "objectID": "slides/data-visualization.html#facets",
    "href": "slides/data-visualization.html#facets",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n3.6 Facets",
    "text": "3.6 Facets\n\nDefines how data is split across multiple panels"
  },
  {
    "objectID": "slides/data-visualization.html#coordinates",
    "href": "slides/data-visualization.html#coordinates",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n3.7 Coordinates",
    "text": "3.7 Coordinates\n\nPositional aesthetics must be interpreted by a coordinate system\nDefines the physical mapping of aesthetics to the paper\n\n\nWe usually think about the cartesian coordinate system‚Äîbut there are a lot of different kinds of coordinate systems."
  },
  {
    "objectID": "slides/data-visualization.html#theme",
    "href": "slides/data-visualization.html#theme",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n3.8 Theme",
    "text": "3.8 Theme\n\n\nEvery part of the graphic that isn‚Äôt linked to the data:\n\nFonts\nSpacing\nColors\nWeights\netc."
  },
  {
    "objectID": "slides/data-visualization.html#setup-packages",
    "href": "slides/data-visualization.html#setup-packages",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n5.1 Setup packages",
    "text": "5.1 Setup packages\nFor this session, we are going to use the ggplot2 and dplyr packages:\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(sf)"
  },
  {
    "objectID": "slides/data-visualization.html#setup-data",
    "href": "slides/data-visualization.html#setup-data",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n5.2 Setup data",
    "text": "5.2 Setup data\nWe are also going to use the storms data included with dplyr.\nTake a quick look at storms using glimpse():\n\nglimpse(storms)\n\n\n\n\n\nWhen we use storms, it is important to remember that each row is an observation of a storm, not a summary feature for an individual storm."
  },
  {
    "objectID": "slides/data-visualization.html#create-a-ggplot",
    "href": "slides/data-visualization.html#create-a-ggplot",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n5.3 Create a ggplot",
    "text": "5.3 Create a ggplot\nWe can start by using the function ggplot() to define a plot object. Set storm as the input data for ggplot():\n\n\nggplot(data = storms)\n\n\n\n\n\n\n\nWell, that doesn‚Äôt look like much. ü§î\nThis is the first step in creating a plot that we can add layers to. Parameters set with ggplot() can be ‚Äúinherited‚Äù by layers added later."
  },
  {
    "objectID": "slides/data-visualization.html#add-aesthetics-and-layers",
    "href": "slides/data-visualization.html#add-aesthetics-and-layers",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n5.4 Add aesthetics and layers",
    "text": "5.4 Add aesthetics and layers"
  },
  {
    "objectID": "slides/data-visualization.html#visualizing-distributions",
    "href": "slides/data-visualization.html#visualizing-distributions",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n6.1 Visualizing distributions",
    "text": "6.1 Visualizing distributions"
  },
  {
    "objectID": "slides/data-visualization.html#distribution-of-one-numeric-variable",
    "href": "slides/data-visualization.html#distribution-of-one-numeric-variable",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n6.2 Distribution of one numeric variable",
    "text": "6.2 Distribution of one numeric variable\n\n\nggplot(\n  data = storms,\n  mapping = aes(y = lat)\n) +\n  geom_histogram(bins = 90)"
  },
  {
    "objectID": "slides/data-visualization.html#distribution-of-one-numeric-variable-1",
    "href": "slides/data-visualization.html#distribution-of-one-numeric-variable-1",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n6.3 Distribution of one numeric variable",
    "text": "6.3 Distribution of one numeric variable\n\n\nggplot(\n  data = storms,\n  mapping = aes(x = lat)\n) +\n  geom_freqpoly(binwidth = 1)"
  },
  {
    "objectID": "slides/data-visualization.html#distribution-of-one-categorical-variable",
    "href": "slides/data-visualization.html#distribution-of-one-categorical-variable",
    "title": "Session 2: Visualizing spatial data with ggplot2",
    "section": "\n6.4 Distribution of one categorical variable",
    "text": "6.4 Distribution of one categorical variable\n\n\nggplot(\n  data = storms,\n  mapping = aes(y = category)\n) +\n  geom_bar()"
  },
  {
    "objectID": "course-schedule.html",
    "href": "course-schedule.html",
    "title": "Schedule overview",
    "section": "",
    "text": "Week 1\n\n\nGetting started with spatial data using {sf} and the tidyverse\n\n\n\n\n\nAug 30, 2023\n\n\n\n\n\n\n\nWeek 2\n\n\nVisualizing spatial data with {ggplot2}\n\n\n\n\n\nSep 6, 2023\n\n\n\n\n\n\n\nWeek 3\n\n\nTransforming data with {dplyr}\n\n\n\n\n\nSep 13, 2023\n\n\n\n\n\n\n\nWeek 4\n\n\nTransforming spatial data attributes\n\n\n\n\n\nSep 20, 2023\n\n\n\n\n\n\n\nWeek 5\n\n\nApplying spatial transformations and geometric operations using {sf}\n\n\n\n\n\nSep 27, 2023\n\n\n\n\n\n\n\nWeek 6\n\n\nTidying and joining spatial data\n\n\n\n\n\nOct 4, 2023\n\n\n\n\n\n\n\nWeek 7\n\n\nBuilding functions in R and literate programming with Quarto\n\n\n\n\n\nOct 11, 2023\n\n\n\n\n\n\n\nWeek 8\n\n\nDeveloping an exploratory data analysis with {sf} and the {tidyverse}\n\n\n\n\n\nOct 18, 2023\n\n\n\n\n\n\n\nWeek 9\n\n\nEditing OpenStreetMap and exploring OpenStreetMap data with {osmdata}\n\n\n\n\n\nOct 25, 2023\n\n\n\n\n\n\n\nWeek 10\n\n\nExploring American Community Survey data with {tidycensus}\n\n\n\n\n\nNov 1, 2023\n\n\n\n\n\n\n\nWeek 11\n\n\nReading and writing spatial data files and services\n\n\n\n\n\nNov 8, 2023\n\n\n\n\n\n\n\nWeek 12\n\n\nCreating and managing spatial metadata\n\n\n\n\n\nNov 15, 2023\n\n\n\n\n\n\n\nWeek 13\n\n\nProject check-in meetings\n\n\n\n\n\nNov 22, 2023\n\n\n\n\n\n\n\nWeek 14\n\n\nSpecial topics and project work session\n\n\n\n\n\nNov 29, 2023\n\n\n\n\n\n\n\nWeek 15\n\n\nFinal project presentations\n\n\n\n\n\nDec 6, 2023\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Weeks üóìÔ∏è",
      "Schedule overview"
    ]
  },
  {
    "objectID": "exercises/exercise_01.html",
    "href": "exercises/exercise_01.html",
    "title": "Exercise 01",
    "section": "",
    "text": "Exercise due on 2023-09-06\n‚ÑπÔ∏è See week 1 for related slides and readings",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 01"
    ]
  },
  {
    "objectID": "exercises/exercise_01.html#setup",
    "href": "exercises/exercise_01.html#setup",
    "title": "Exercise 01",
    "section": "1 Setup",
    "text": "1 Setup\nTo complete this exercise, you need to load two libraries that we already installed in class:\n\nlibrary(sf)\nlibrary(ggplot2)\n\nYou also need data from the {sf} package:\n\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package = \"sf\"), as_tibble = TRUE)\n\nReading layer `nc' from data source \n  `/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/sf/shape/nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\n\nYou will need the {mapview} and {spData} packages but don‚Äôt load them yet. If they aren‚Äôt installed, install them now using {pak} (a faster option than install.packages()).\nCopy the following lines (without the # character) into the console to install all three packages (don‚Äôt forget to restart your session afterwards):\n\n# install.packages(\"pak\")\n# pak::pkg_install(c(\"mapview\", \"spData\"))\n\nThis week‚Äôs exercise is mostly ‚Äúfill in the blank‚Äù questions and coding exercises. You can expect fewer hints and more freedom to experiment in future exercises!",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 01"
    ]
  },
  {
    "objectID": "exercises/exercise_01.html#exercises",
    "href": "exercises/exercise_01.html#exercises",
    "title": "Exercise 01",
    "section": "2 Exercises",
    "text": "2 Exercises\n\n2.1 Coding basics\nThe exercises in this section are from Ch. 3 Workflow: basics in R for Data Science (2e). If you have any trouble with the next couple exercises, please review the chapter before continuing to the next section.\nWhy does this code not work? ____\n\nmy_variable &lt;- 10\nmy_varƒ±able\n\n\nTweak each of the following R commands so that they run correctly:\n\nlibary(todyverse)\n\nggplot(dTA = mpg) + \n  geom_point(maping = aes(x = displ y = hwy)) +\n  geom_smooth(method = \"lm)\n\n\nPress ‚å• + ‚áß + K or ‚éá + ‚áß + K.\nWhat happens? ____\nHow can you get to the same place using the menus? ____\n\n\n\n2.2 Look up documentation\n? is an operator that you can use to pull up documentation on a function, dataset, or other topic in the Help tab pane of the RStudio IDE. For example, running the code: ?sf::st_read will pull up the documentation on a set of functions for read simple features or layers from a file or database.\nUse ? to access the documentation on sf::st_geometry() then look for the ‚ÄúValue‚Äù heading that provides information about the value returned by the function.\nWhat type of object does sf::st_geometry() return? ____\nWhat is one other function documented on the same page? ____\n\n\n\n\n\n\nTip\n\n\n\n\n\nReview Ch. 9 Workflow: getting help in R for Data Science (2e) for more information about getting help when you struggle with a package, function, or project.\n\n\n\n\n\n2.3 Explore sf and sfc objects\nEvery object in R has at least one class:\n\nclass(1)\n\n[1] \"numeric\"\n\nclass(\"A\")\n\n[1] \"character\"\n\nclass(TRUE)\n\n[1] \"logical\"\n\n\nVectors, lists, data frames, and other objects can also have names and attributes. This is a named character vector:\n\nnames(c(\"A\" = \"apple\"))\n\n[1] \"A\"\n\n\nA sf object is a data.frame but it also has a special sf class that is designed to implement the formal simple features standard in R:\n\nclass(nc)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nAs a data frame, a sf object has column names (which you can access with names() or colnames()):\n\ncolnames(nc)\n\n [1] \"AREA\"      \"PERIMETER\" \"CNTY_\"     \"CNTY_ID\"   \"NAME\"      \"FIPS\"     \n [7] \"FIPSNO\"    \"CRESS_ID\"  \"BIR74\"     \"SID74\"     \"NWBIR74\"   \"BIR79\"    \n[13] \"SID79\"     \"NWBIR79\"   \"geometry\" \n\n\n\nNext, we should run st_geometry() on nc:\n\nnc_geometry &lt;- st_geometry(nc)\n\nNow, use class() to find out what type of object st_geometry() returned:\n\n____\n\nThis object is a special type of list. You can subset one or more items from a list using a single or double set of square brackets like this:\n\nnc_geometry[1]\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -81.74107 ymin: 36.23436 xmax: -81.23989 ymax: 36.58965\nGeodetic CRS:  NAD27\n\n\nMULTIPOLYGON (((-81.47276 36.23436, -81.54084 3...\n\nnc_geometry[[1]]\n\nMULTIPOLYGON (((-81.47276 36.23436, -81.54084 36.27251, -81.56198 36.27359, -81.63306 36.34069, -81.74107 36.39178, -81.69828 36.47178, -81.7028 36.51934, -81.67 36.58965, -81.3453 36.57286, -81.34754 36.53791, -81.32478 36.51368, -81.31332 36.4807, -81.26624 36.43721, -81.26284 36.40504, -81.24069 36.37942, -81.23989 36.36536, -81.26424 36.35241, -81.32899 36.3635, -81.36137 36.35316, -81.36569 36.33905, -81.35413 36.29972, -81.36745 36.2787, -81.40639 36.28505, -81.41233 36.26729, -81.43104 36.26072, -81.45289 36.23959, -81.47276 36.23436)))\n\n\nTake a look at the attributes for this list using attributes():\n\n____(nc_geometry)\n\nNow, use class() one more time to find out what type of objects make up nc_geometry:\n\n____(nc_geometry[[1]])\n\n\nsummary() is another way to get information about names and attributes all at once. Try using summary() on nc_geometry:\n\nsummary(____)\n\nReview the results and try to answer the following:\n\nWhat is the geometry type? ____\nWhat is the coordinate reference system? ____\nHow many features? ____\n\n\n\n2.4 Visualize sf objects\nSome packages come with data we can use as soon as the package is loaded.\nLoad the {spData} packages using library() then make a plot of the us_states data:\n\nlibrary(____)\n\nplot(____)\n\nCan you use plot() to make a map of states color-coded by region?\n\nplot(____)\n\nCan you make a map of us_states using ggplot() and geom_sf()?\n\nggplot(data = ____) +\n  geom_sf()\n\nCan you make a map us_states you made with geom_sf() and have states are color-coded by total population in 2015?\n\nggplot(data = ____) +\n  geom_sf(aes(fill = ____))\n\nTake a look at the documentation for ggplot2::geom_sf() for examples if you get stuck. You can also use names() or summary() with us_states to find out the column names of the different attributes.",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 01"
    ]
  },
  {
    "objectID": "exercises/exercise_01.html#bonus-exercise",
    "href": "exercises/exercise_01.html#bonus-exercise",
    "title": "Exercise 01",
    "section": "3 Bonus exercise",
    "text": "3 Bonus exercise\n\n3.1 Interactive mapping\nFor the bonus exercise, we are using Maryland Transit Administration Bus Stops data from Maryland iMap portal. The data is published as an ArcGIS Feature Layer (a type of Web Map Service or WMS). The service allows us to access the data in a few different formats including as a GeoJSON file.\nI went ahead and pulled the URL to use for this exercise. {sf} is able to read the data using GDAL (the Geospatial Data Abstraction Library). GDAL has a feature known as the virtual file system that allows it to read from a URL (see ‚Äúvsicurl‚Äù for details).\n\ndsn &lt;- \"https://geodata.md.gov/imap/rest/services/Transportation/MD_Transit/FeatureServer/9/query?outFields=*&where=1%3D1&f=geojson\"\n\n\n\n\n\n\n\nAbout GDAL and other sf dependencies\n\n\n\n\n\nGDAL is one of the major open source projects that ‚Äúpowers‚Äù the {sf} package along with GEOS, PROJ, and udunits2. Geocomputation with R explains these dependencies:\n\nGDAL, for reading, writing and manipulating a wide range of geographic data formats,\nPROJ, a powerful library for coordinate system transformations\nGEOS, a planar geometry engine for operations such as calculating buffers and centroids on data with a projected CRS\nS2, a spherical geometry engine written in C++ developed by Google\n\n\n\n\n\nCombine st_read() and the assignment operator &lt;- to read the URL from dsn and create a new sf object:\n\nbus_stops ____ ____\n\n\n\n\n\n\n\n\nExercise Update (2023-09-04)\n\n\n\n\n\nWhile mapview() can display the bus_stop data interactively, I‚Äôve discovered that it won‚Äôt work when you render the Quarto document. To avoid confusion, I‚Äôve updated the last two code blocks to use the setting eval: false (turning off evaluation when the document is rendered). Execution options are a more advanced topic we cover later in this course.\n\n\n\nLoad the {mapview} library and then use the mapview() function to create an interactive map of the new bus_stops object:\n\n____\n\n____\n\nExplore the documentation for mapview() by running ?mapview::mapview in your console. Read the help page to see how you can customize your interactive map.\nIf you want a guided tour of the package, check out this recorded 2020 tutorial on YouTube with Tim Appelhans (who created mapview in 2016 with grant support from the R Consortium).\nCan you create another interactive map that is color-coded by one of the attributes in bus_stops?\n\n_____",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 01"
    ]
  },
  {
    "objectID": "exercises/exercise_02.html",
    "href": "exercises/exercise_02.html",
    "title": "Exercise 02",
    "section": "",
    "text": "Exercise due on 2023-09-11\n‚ÑπÔ∏è See week 2 for related slides and readings",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 02"
    ]
  },
  {
    "objectID": "exercises/exercise_02.html#overview",
    "href": "exercises/exercise_02.html#overview",
    "title": "Exercise 02",
    "section": "1 Overview",
    "text": "1 Overview\n\n\n\n\n\n\nPractice these skills\n\n\n\n\n\n\nBuild a layered plot using ggplot(), aes(), and different geom_ functions\nExplore the difference between discrete and continuous variables\nUse coord_sf() to modify a plot created with geom_sf()\n\n\n\n\n\n\n\n\n\n\nThink about these questions\n\n\n\n\n\n\nWhat makes a scale better or worse at visualizing data?\nHow do you write a clear and accurate title, legend, or caption?\nWhen is it appropriate to modify the geometry of your data when making a map?",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 02"
    ]
  },
  {
    "objectID": "exercises/exercise_02.html#setup",
    "href": "exercises/exercise_02.html#setup",
    "title": "Exercise 02",
    "section": "2 Setup",
    "text": "2 Setup\nThis exercises uses the {ggplot2} and {dplyr} packages (both from the tidyverse family of packages) and the {sf} package:\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(sf)\n\nFor this week‚Äôs exercise, we are also going to use data from the {rnaturalearth} package. Make sure to install those packages and re-start your session if these packages are not installed already:\n\n# pak::pkg_install(c(\"rnaturalearth\", \"rnaturalearthdata\"))\nlibrary(rnaturalearth)\n\nWe are going to use ne_download() to download the countries dataset and then use st_centroid() to make a version of this dataset where the features show the center of each country instead of the boundaries:\n\ncountries &lt;- ne_download(scale = \"medium\", type = \"countries\", returnclass = \"sf\")\n\ncountries &lt;- st_transform(countries, crs = 3857)\n\ncountries_center &lt;- st_centroid(countries)\n\nglimpse(countries)\n\nSome of the following exercises don‚Äôt require a sf object. You can also use the mpg or storms dataset we looked at during this week‚Äôs lecture:\n\nglimpse(mpg)\n\nglimpse(storms)\n\nOne advantage of using {ggplot2} over a map-making focused package like {tmap} is the wide variety of extension packages created by the large community of users and developers making data visualizations (including maps) with {ggplot2}.\nWe aren‚Äôt going to use some of these extension packages (and others) but we won‚Äôt load them yet. Run the following code to install (and don‚Äôt forget to restart your session afterwards):\n\npak::pkg_install(c(\"patchwork\", \"plotly\", \"smoothr\"))\n\nIf you finish this exercise but still want more practice, you can download this RMarkdown document with exercises shared by Thomas Lin Pedersen for his two-part 2020 online workshop on {ggplot2} (part 1 and part 2 are both available on YouTube).",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 02"
    ]
  },
  {
    "objectID": "exercises/exercise_02.html#exercises",
    "href": "exercises/exercise_02.html#exercises",
    "title": "Exercise 02",
    "section": "3 Exercises",
    "text": "3 Exercises\n\n3.1 Plotting a single variable\nFind a discrete variable in countries and then create a plot with geom_bar():\n\nggplot(data = countries) +\n  geom_bar(mapping = aes(x = ____))\n\nNext, find a continuous variable and make a plot with geom_histogram():\n\nggplot(data = countries) +\n  geom_histogram(mapping = aes(x = ____))\n\nNow, let‚Äôs make a map! Use countries_center and geom_sf() to make a map with a continuous variable mapped to size:\n\nggplot(data = countries_center) +\n  geom_sf(aes(size = ____))\n\n\nNext, make a map with geom_sf() with one discrete variable mapped to color:\n\nggplot(data = countries) +\n  geom_sf(aes(color = ____))\n\nIs that the map you expected? Try it again with the discrete variable mapped to fill:\n\nggplot(data = countries) +\n  geom_sf(aes(fill = ____))\n\n\nNow, make a plot using any geom function of your choice:\n\nggplot(data = countries) +\n  ____\n\nExplain in plain language. What does your map show? ____\n\n\n3.2 Plotting two variables\nFor this next section, you can continue to use countries as your dataset or load a different dataset using {rnaturaleath}. You can see what vector data is available using rnaturalearth::ne_find_vector_data() then find the function you need to load the data into a new object:\n\nrnaturalearth::ne_find_vector_data()\n\nFirst, find two continuous variables and create a scatter plot with geom_point():\n\nggplot(data = ____) +\n  geom_point(aes(____))\n\nNext, look in your data for one discrete and one continuous variable then use aes() to set those variables for geom_col(). The geom_col() function is similar to geom_bar() but you must provide both an x and a y variable:\n\nggplot(data = ____) +\n  geom_col(aes(____))\n\nNow, use geom_sf() mapping your continous variable to fill or color and your discrete variable to facet_wrap():\n\nggplot(data = ____) +\n  geom_sf(aes(____)) +\n  facet_wrap(~ ____)\n\nFinally, create a map using a different aesthetic that we haven‚Äôt tried yet. Options could include linewidth, size, alpha, or linetype:\n\nggplot(data = ____) +\n  geom_sf(aes(____ = ____))\n\nIs this aesthetic mapping an effective way of visualizing the variable? ____\nIf so, why do you think it works well? If not, why does it not work well? ____\n\n\n3.3 Using scales and colors\n{ggplot2} uses naming conventions to organize the scale functions. This isn‚Äôt the same for every function but they look something like: ‚Äúscale_‚Äù. So, scale_fill_viridis_d() applies the Viridis color scale to a discrete variable mapped to the fill aesthetic.\nUse the data to create a plot and take a look at the colors set when you use scale_color_viridis_c():\n\nggplot(____) +\n  geom_dotplot(aes(____, _____, color = ____)) +\n  scale_color_viridis_c()\n\nThe ColorBrewer scales are designed for use with thematic maps. Use ?scale_color_brewer() to pull up the documentation for this function and review the information on the type and palette parameters.\nNow, map a variable to the color aesthetic for geom_sf() and assign an appropriate type and palette value:\n\nggplot(____) +\n  geom_sf(aes(color = ____)) +\n  scale_color_brewer(type = ____, palette = ____)\n\nSwitching from color to fill, try it again with a different type and palette value:\n\nggplot(____) +\n  geom_sf(aes(fill = ____)) +\n  scale_fill_brewer(type = ____, palette = ____)\n\nOne last time, but we‚Äôre using scale_fill_distiller():\n\nggplot(____) +\n  geom_sf(aes(fill = ____)) +\n  scale_fill_distiller(type = ____, palette = ____)\n\nNote that this scale_fill_distiller() scale only works with continuous values. If you get an error, you may need to map a different variable to fill.\n\n\n3.4 Adding labels, legends, and themes\nSet the data for ggplot() and then use the labs() function to apply a title and caption that make sense:\n\nggplot(data = ____) +\n  geom_sf(color = \"black\", fill = NA) +\n  labs(\n    title = ____,\n    caption = ____\n  )\n\nNow, map fill to a variable in your data using aes() and then use labs() to assign a label for fill:\n\nggplot(data = ____) +\n  geom_sf(aes(fill = ____)) +\n  labs(\n    ____\n  )\n\nFinally, put all of these elements together with a theme function. theme_minimal() and theme_void() are good themes to use for maps but you can explore all of the options in the ggplot2 documentation:\n\nggplot(data = ____) +\n  geom_sf(mapping = aes(____)) +\n  labs(\n    title = ____,\n    caption = ____,\n    ____\n  ) +\n  ____\n\n\n\n3.5 Interactive plots with {plotly}\nWe aren‚Äôt doing much with interactivity in this class (or exercise) but I did want to give you a chance to try it out using the ggplotly() function from the {plotly} package:\n\np &lt;- ggplot(data = ____) +\n  geom____(aes(____))\n  \nplotly::ggplotly(\n  p = p\n)\n\nA directory of {ggplot2} extensions is available through the tidyverse website if you want to try more tools for animation or interactivity including {gganimate} or {ggiraph}.\n\n\n3.6 Map making with {ggplot2}\nBy default, any map created with geom_sf() will show the graticulates on the map and axis labels with the coordinate values. Add data to this map and then hide these graticules by adding theme_void():\n\nggplot(data = ____) +\n  geom_sf(color = \"black\", fill = NA) +\n  ____\n\nYou can also hide or change graticules by using theme(). Try setting the panel.grid argument to element_blank() to hide the grid:\n\nggplot(data = ____) +\n  geom_sf(color = \"black\", fill = NA) +\n  theme(\n    panel.grid = ____\n    )\n\nNow, try ‚Äúzooming‚Äù into a selected area of your map using the xlim and ylim arguments for coord_sf():\n\nggplot(data = ____) +\n  geom_sf(color = \"black\", fill = NA) +\n  coord_sf(\n    xlim = ____,\n    ylim = ____\n  )\n\nIf you have difficulty with this one, look back at our week 2 slides for an example showing how to use sf::st_bbox() to get xmin, xmax, ymin, and ymax values for the xlim and ylim parameter.\n\nUsing an inset map or ‚Äúlocator map‚Äù with a larger area and a zoomed in map showing a featured area is a common cartographic approach. You can use patchwork::inset_element() from the {patchwork} package to set this up:\n\narea_map &lt;- ggplot(data = ____) +\n  geom_sf(color = \"black\", fill = NA) +\n  coord_sf(\n    xlim = ____,\n    ylim = ____\n  )\n\ninset_map &lt;- ggplot(data = ____) +\n  geom_sf(color = \"black\", fill = NA)\n\narea_map +\n  patchwork::inset_element(\n    p = inset_map,\n    left = ____,\n    bottom = ____,\n    top = ____,\n    right = ____\n  )\n\nRemember, this format of calling functions (&lt;package name&gt;::&lt;function name&gt;) is just a shortcut for using functions from packages that are installed but not loaded into your environment. If you have any difficulty with this part of the exercise, make sure you have {patchwork} installed.\n\nThere are some cases when you need to modify the geometry of your data as part of the process of making a map. The st_simplify() function is one way to do that. Try setting dTolerance to a low value, e.g.¬†dTolerance = 10, and run the code block. Then try to run it again with dTolerance = 100000.\n\nusa &lt;- filter(countries, NAME == \"United States of America\")\n\nsimple_usa &lt;- st_simplify(x = usa, dTolerance = ____)\n\nggplot() +\n  geom_sf(\n    data = usa,\n    color = \"orange\"\n    ) +\n  geom_sf(\n    data = simple_usa,\n    color = \"purple\"\n  ) +\n  theme_void()\n\nWhat happens when you increase the value of dTolerance? ____\nNow, let‚Äôs try to same thing but smoothing features with smoothr::smooth() instead of simplifying with sf::st_simplify(). Start by setting smoothness to a small number, smoothness = 0.5, and then run again with higher and higher numbers:\n\nsmooth_usa &lt;- smoothr::smooth(x = usa, method = \"ksmooth\", smoothness = ____)\n\nggplot() +\n  geom_sf(\n    data = usa,\n    color = \"orange\"\n    ) +\n  geom_sf(\n    data = smooth_usa,\n    color = \"purple\"\n  ) +\n  theme_void()\n\nWhat happens when you increase the value of smoothness? ____\nCheck the documentation for st_simplify() or smoothr::smooth() for more information on how these functions work to modify the geometry.",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 02"
    ]
  },
  {
    "objectID": "exercises/exercise_02.html#bonus-exercise",
    "href": "exercises/exercise_02.html#bonus-exercise",
    "title": "Exercise 02",
    "section": "4 Bonus exercise",
    "text": "4 Bonus exercise\n\n4.1 Creating maps with {tmap}\nPick one of the maps you created in the prior questions of this exercise and create a similar version using the {tmap} package.\nYou can install {tmap} the same as any other package:\n\n# pak::pkg_install(\"tmap\")\n\nThen load the library:\n\nlibrary(tmap)\n\nAnd make a map using data from {rnaturalearth} or another source of your choice:\n\n____\n\nWhat is the same about making a map with {tmap} compared to {ggplot2}? ____\nWhat is different about making a map with {tmap} compared to {ggplot2}? ____\nDo you have any preference between the two? ____",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 02"
    ]
  },
  {
    "objectID": "exercises/exercise_07.html",
    "href": "exercises/exercise_07.html",
    "title": "Exercise 07",
    "section": "",
    "text": "Exercise due on 2023-10-20\n‚ÑπÔ∏è See week 7 for related slides and readings",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 07"
    ]
  },
  {
    "objectID": "exercises/exercise_07.html#setup",
    "href": "exercises/exercise_07.html#setup",
    "title": "Exercise 07",
    "section": "1 Setup",
    "text": "1 Setup\nTo start this week‚Äôs exercise, I have created a new folder named project in each of your class repositories (based on the new public project-template repository for our class). Sync your repository to make sure you have the latest files before you get started with the exercise.\nIn the folder you will find a new RStudio project file (.Rproj) named project.Rproj. Open the project and locate the file named example-functions.qmd.\nOpen example-functions.qmd and, in the editor pane of RStudio, click the ‚ÄúRender‚Äù button to turn the Quarto document into a rendered HTML document in the ‚ÄúPreview‚Äù pane.\nThis Quarto document is designed to review the topics we covered in last week‚Äôs class and to show some of the options for Quarto documents. You can review the document or, if you feel confident in the material, jump ahead to the exercise.",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 07"
    ]
  },
  {
    "objectID": "exercises/exercise_07.html#exercise",
    "href": "exercises/exercise_07.html#exercise",
    "title": "Exercise 07",
    "section": "2 Exercise",
    "text": "2 Exercise\nHere are the steps to complete this week‚Äôs exercise:\n\nUse the menu to create a new Quarto document (Go to File &gt; New File &gt; Quarto Document...). Fill in the title ‚ÄúExercise 7‚Äù and your name as the author. After the new document opens, notice how the title and author appear in the front matter for the new document.\n\n\n\nSave the Quarto document using the file name exercise_07.qmd.\nInsert a new code block and add code to read spatial data into R. You can use sf::read_sf() to read data from a URL or file path or you can use one of the data functions we‚Äôve tried in class, such as tigris::counties() or rnaturalearth::ne_countries(returnclass = \"sf\").\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nDon‚Äôt forget! If you are using a local file, the file size¬†must¬†be less than 50MB or your changes to the repository can‚Äôt be committed to GitHub. If your file is not a spatial data file (e.g.¬†a CSV file) you should convert the object into a sf object using¬†sf::st_as_sf().\n\n\n\n\nInsert a new code block and write a vector function (either a ‚Äúmutate‚Äù or ‚Äúsummary‚Äù style function) that can take one or more attributes from your data as an input. Include one or more examples of how the function works.\nInsert a new code block and write a vector function (either a ‚Äúmutate‚Äù or ‚Äúsummary‚Äù style function) that can take the feature geometry from your data as an input. This function should use one of the geometric unary or binary functions from the {sf} package. It doesn‚Äôt need to be complicated but take a look at the function reference or the sf cheatsheet and find a function that you are curious to try out. Include one or more examples of how the function works.\nInsert a new code block and write a mapping or plotting function. Remember, if you write a mapping function, it should probably include ggplot2::geom_sf() in the body of the function.\nFinally‚Äîrender the Quarto document and make sure it can be knit as an HTML page without error! You can also run quarto::quarto_preview() in the console to keep a live preview running in the background while you complete the exercise.\n\n\n\n\n\n\n\nUse verbs for function names\n\n\n\n\n\nFor each part of this exercise, make sure to use function names that help you and anyone using your code understand what the function does. Using verbs is an easy way to do that.\n\n\n\nBetween each code block, please include a brief explanation of what question you are trying to answer with the functions.\nFor example, you could write: ‚ÄúThis function takes data on storm observations and summarizes the average wind speed and air pressure by hurricane category so I can better understand the relationship between the continuous and categorical variables.‚Äù\nWhen you are done writing the functions (and examples!), there are just two steps left in this exercise to help you practice working with Quarto.\n\nAdd a link to your Exercise 7 document to the navigation menu of your Quarto website. Open the _quarto.yml project configuration file and look for the navbar section. Take a look at the Quarto guide to Website Navigation for more information.\nExplore the HTML theme options for your Quarto site. Try swapping the default cosmo theme for one of the other Bootswatch¬†themes.",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 07"
    ]
  },
  {
    "objectID": "exercises/exercise_07.html#bonus-exercise",
    "href": "exercises/exercise_07.html#bonus-exercise",
    "title": "Exercise 07",
    "section": "3 Bonus exercise",
    "text": "3 Bonus exercise\nRead in more data and try using your mapping or plotting function with a different dataset.\nDoes the function still work they way you expect? Why or why not?\nWrite a few sentences explaining what happens and, if the functions do not work, try writing a new version that works with both your original data and the new version.",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 07"
    ]
  },
  {
    "objectID": "exercises/exercise_04.html",
    "href": "exercises/exercise_04.html",
    "title": "Exercise 04",
    "section": "",
    "text": "Exercise due on 2023-10-03\n‚ÑπÔ∏è See week 4 for related slides and readings",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 04"
    ]
  },
  {
    "objectID": "exercises/exercise_04.html#overview",
    "href": "exercises/exercise_04.html#overview",
    "title": "Exercise 04",
    "section": "1 Overview",
    "text": "1 Overview\nThis week‚Äôs exercises are excerpted from Ch. 3, Ch. 4, and Ch. 5 in Geocomputation with R. These exercises build on our last exercise using {dplyr} and include some of the same skills including:\n\nFiltering rows or observations\nGrouping and summarizing data by variable\n\nNew skills you will practice with this exercise include:\n\nUsing non-spatial joins for data frames\nComputing geometric measurements\nUsing spatial filters\nUsing geometric operations on a simple feature geometry set\nUsing geometric operations on pairs of simple feature geometries",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 04"
    ]
  },
  {
    "objectID": "exercises/exercise_04.html#setup",
    "href": "exercises/exercise_04.html#setup",
    "title": "Exercise 04",
    "section": "2 Setup",
    "text": "2 Setup\nThis exercise uses the sf and tidyverse packages:\n\nlibrary(tidyverse)\nlibrary(sf)\n\nWe are also going to use the us_states and us_states_df data from the {spData} package:\n\nlibrary(spData)\n\nNote that the us_states loaded for this exercise is different than the us_states we created during class with the tigris::states() function. For this exercise, the bonus exercises are mixed in with the other questions but you are welcome to skip them if you do not want go for the bonus part of the exercise.",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 04"
    ]
  },
  {
    "objectID": "exercises/exercise_04.html#exercises",
    "href": "exercises/exercise_04.html#exercises",
    "title": "Exercise 04",
    "section": "3 Exercises",
    "text": "3 Exercises\n\n3.1 Filtering data\nFind all states that belong to the West region, have an area below 250,000 km2and in 2015 a population greater than 5,000,000 residents (Hint: you may need to use the function units::set_units() or as.numeric()).\n\nus_states |&gt; \n  ____\n\nFind all states that belong to the South region, had an area larger than 150,000 km2 or a total population in 2015 larger than 7,000,000 residents.\n\nus_states |&gt; \n  ____\n\n\n\n3.2 Joining and summarizing data\nWhat was the total population in 2015 in the us_states dataset? What was the minimum and maximum total population in 2015?\n\nus_states |&gt; \n  ____\n\nAdd variables from us_states_df to us_states, and create a new object called us_states_stats.\n\nWhat function did you use and why?\nWhich variable is the key in both datasets?\nWhat is the class of the new object?\n\nTip: we are covering joins in more detail next week‚Äîcheck out the R for Data Science chapter on Joins for more information.\n\nus_states_stats &lt;- us_states |&gt; \n  ____\n\nus_states_df has two more rows than us_states. How can you find them? Hint: try to use the dplyr::anti_join() function.\n\n____(us_states, us_states_df)\n\nHow much has population density changed between 2010 and 2015 in each state?\nCalculate the change in percentages and map them with plot() or geom_sf():\nCalculate the change in the number of residents living below the poverty level between 2010 and 2015 for each state. Hint: See ?us_states_df for documentation on the poverty level columns.\nBonus: Calculate the change in the percentage of residents living below the poverty level in each state.\nWhat was the minimum, average and maximum state‚Äôs number of people living below the poverty line in 2015 for each region?\nBonus: What is the region with the largest increase in people living below the poverty line?\n\n\n3.3 Spatial operations\nSection 4.2 (in Geocomputation with R) established that Canterbury was the region of New Zealand containing most of the 100 highest points in the country. How many of these high points does the Canterbury region contain?\n\ncanterbury &lt;- nz |&gt;\n  filter(Name == \"Canterbury\")\n\nnz_height |&gt; \n  ____\n\nBonus: plot the result using the ggplot2::geom_sf() function to show all of New Zealand, canterbury region highlighted in yellow, high points in Canterbury represented by red crosses (Hint: try using shape = 7) and high points in other parts of New Zealand represented by blue circles.\nSee the help page ?ggplot2::shape and run the examples to see an illustration of different shape values.\nWhich region has the second highest number of nz_height points, and how many does it have?\n\nnz_height |&gt; \n  ____\n\nGeneralizing the question to all regions: how many of New Zealand‚Äôs 16 regions contain points which belong to the top 100 highest points in the country? Which regions?\nBonus: create a table listing these regions in order of the number of points and their name. Hint: use dplyr::slice_max() and gt::gt().\nUsing st_buffer(), how many points in nz_height are within 100 km of Canterbury?\n\nnz_height |&gt; \n  st_buffer(____, dist = ____)\n\n\n\n3.4 Spatial predicates\nTest your knowledge of spatial predicates by finding out and plotting how US states relate to each other and other spatial objects.\nThe starting point of this part of the exercise is to create an object representing Maryland state in the USA using the filter() function and plot the resulting object in the context of US states.\n\nmaryland &lt;- filter(____, ____)\n\nggplot() +\n  geom_sf(data = us_states) +\n  geom_sf(data = ____)\n\nCreate a new object representing all the states that geographically intersect with Maryland and plot the result (hint: the most concise way to do this is with the subsetting method [ but you can also use sf::st_filter()).\n\nstates_intersecting_md &lt;- ____\n\nCreate another object representing all the objects that touch (have a shared boundary with) Maryland and plot the result (hint: remember you can use the argument op = st_intersects when subsetting with base R or .predicate = st_intersects when using st_filter()).\n\nstates_touching_md &lt;- ____\n\nBonus: create a straight line from the centroid of Maryland to the centroid of California near the West coast of the USA (hint: functions st_centroid(), st_union() and st_cast() described in Chapter 5 may help) and identify which states this long East-West line crosses.\nHow far is the geographic centroid of Maryland from the geographic centroid of Canterbury, New Zealand?\nCalculate the length of the boundary lines of US states in meters. Which state has the longest border and which has the shortest? Hint: The st_length function computes the length of a LINESTRING or MULTILINESTRING geometry.\n\nus_states |&gt; \n  ____",
    "crumbs": [
      "Exercises üõ†Ô∏è",
      "Exercise 04"
    ]
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\npresentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#timeline",
    "href": "project-description.html#timeline",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\npresentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Create an exploratory analysis based on OpenStreetMap or American Community Survey data. That is your final project.\nThe goal of the final project is for you to create an exploratory analysis using real world data. Students are encourages to use:\n\nOpenStreetMap data (using the {osmdata} package),\nAmerican Community Survey data (using the {tidycensus} package),\nor a combination of both sources.\n\nBoth data sources include varied types and topics so you can choose based on your interests or work you have done in other courses or research projects.\nThe goal of this project is for you to demonstrate your understanding of the skills we covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team‚Äôs project"
  }
]